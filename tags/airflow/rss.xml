<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Airflow on Data Science | DSChloe</title>
    <link>https://dschloe.github.io/tags/airflow/</link>
    <description>Recent content in Airflow on Data Science | DSChloe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 29 Oct 2022 14:00:47 +0900</lastBuildDate><atom:link href="https://dschloe.github.io/tags/airflow/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Docker Installation in Windows</title>
      <link>https://dschloe.github.io/settings/2022/10/docker_windows/</link>
      <pubDate>Sat, 29 Oct 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2022/10/docker_windows/</guid>
      <description>사전 준비  WSL2가 설치가 되어 있어야 한다.  참고 : https://dschloe.github.io/settings/wsl2_install_on_windows/    도커 설치  해당 싸이트에 접속한다. (참조 : https://www.docker.com/products/docker-desktop/)   관리자 권한으로 실행   설치가 완료가 되면 Close and Log Out 버튼이 나오면 클릭하면 윈도우 로그아웃이 진행되기 때문에, 다시 재 로그인을 하도록 한다. 아래 그림 메뉴 우측 상단에 Sign In 버튼을 클릭해 로그인을 한다.   도커 Settings 창에 들어가서 아래 그림처럼 변경후 Apply &amp;amp; Restart 버튼을 클릭한다.</description>
    </item>
    
    <item>
      <title>Airflow 데이터 파이프라인 구축 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json_sample/</link>
      <pubDate>Thu, 14 Apr 2022 21:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json_sample/</guid>
      <description>개요  이번에는 CSV-JSON으로 데이터를 변환하는 파이프라인을 구축하도록 한다.  Step 01. Dags 폴더 생성  프로젝트 Root 하단에 Dags 폴더를 만든다.  dags 폴더를 확인한다.    $ ls airflow.cfg airflow.db dags logs venv webserver_config.py Step 02. 가상의 데이터 생성  이번 테스트에서 사용할 라이브러리가 없다면 우선 설치한다.  $ pip3 install faker pandas  faker 라이브러리를 활용하여 가상의 데이터를 생성한다. (파일 경로 : data/step01_writecsv.py)  from faker import Faker import csv output=open(&amp;#39;data.</description>
    </item>
    
    <item>
      <title>Setting up Apache-Airflow in Windows using WSL2</title>
      <link>https://dschloe.github.io/settings/apache_airflow_using_wsl2/</link>
      <pubDate>Wed, 06 Apr 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/apache_airflow_using_wsl2/</guid>
      <description>개요  Windows WSL2에서 airflow를 설치한다.  Step 1. Install pip on WSL  airflow를 설치하기 위해 pip를 설치한다.  $ sudo apt install python3-pip [sudo] password for username: Step 2. Install virtualenv package  virtualenv 라이브러리를 설치한다.  $ sudo pip3 install virtualenv Step 3. Create a virtual environment  C드라이브에 airflow-test 폴더를 생성한다.  해당 디렉터리로 이동한다.   이제 가상환경을 생성한다.  $ virtualenv venv  가상환경에 접속을 한다.</description>
    </item>
    
    <item>
      <title>Airflow를 활용한 Data Cleansing 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch05_cleaning_transforming/data_cleaning_using_airflow/</link>
      <pubDate>Mon, 20 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch05_cleaning_transforming/data_cleaning_using_airflow/</guid>
      <description>강의 홍보  취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다.  스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다.   [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기   개요  Pandas와 Airflow를 활용하여 데이터를 정제하는 코드를 구성한다. 우선 데이터는 아래에서 CSV 파일을 다운로드 받고, Dags 파일 하단에 위치시킨다.  URL: https://github.com/PaulCrickard/escooter/blob/master/scooter.csv    Raw 데이터 확인  간단하게 Raw 데이터를 확인해보도록 한다.</description>
    </item>
    
    <item>
      <title>Airflow를 활용한 PostgreSQL에서 Elasticsearch로 데이터 마이그레이션 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch04_working_databases/airflow_postgresql_elasticsearch/</link>
      <pubDate>Sat, 18 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch04_working_databases/airflow_postgresql_elasticsearch/</guid>
      <description>강의 홍보  취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다.  스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다.   [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기   개요  Airflow를 활용하여 PostgreSQL에 저장된 데이터를 디스크로 다운로드 받고, 그리고 그 파일을 다시 읽어서 Elasticsearch에 저장하도록 한다. 전체적인 흐름은 getData from PostgreSQL &amp;gt;&amp;gt; insertData to Elasticsearch 로 저장할 수 있다.</description>
    </item>
    
    <item>
      <title>Apache Airflow를 활용한 CSV에서 JSON으로 변환하기</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json/</link>
      <pubDate>Thu, 09 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json/</guid>
      <description>강의 홍보  취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다.  스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다.   [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기   개요  Apache Airflow에서 가장 중요한 개념은 DAG(Directed Acyclic Graph)이다. DAG를 만들 시, Bash 스크립트 및 연산자(Operator)로 작업을 정의할 수 있다. 이 때, 파이썬 함수로 조직화 한다. Airflow 설치방법을 모른다면 다음 페이지에서 확인한다.</description>
    </item>
    
    <item>
      <title>Apache Airflow Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</link>
      <pubDate>Mon, 06 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</guid>
      <description>강의 홍보  취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다.  스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다.   [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기   개요  NiFi와 같은 용도의 소프트웨어이며, 현재 가장 인기 있는 오픈소스 데이터 파이프라인 도구라고 할 수 있다. 보통은 시스템에 경로를 설정한다. 그런데, 본 장에서는 가상환경 설정 후 진행하는 것으로 했다.</description>
    </item>
    
    <item>
      <title>AirFlow ch01. 개요</title>
      <link>https://dschloe.github.io/mlops/ch04_airflow/airflow_00_intro/</link>
      <pubDate>Fri, 09 Jul 2021 14:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch04_airflow/airflow_00_intro/</guid>
      <description>인프런 강의  취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다.  스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다.   [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기   공지  Airflow 2.0 원서 나온 것을 공부용으로 활용합니다.  Airflow Project  이 책에 나온 내용을 Chapter별로 요약하여 정리하려고 한다. 원서 구매 페이지는 아래와 같다. 구매 페이지: Data Pipelines with Apache Airflow  Chapter 1.</description>
    </item>
    
    <item>
      <title>AirFlow 설치 및 실행 with M1</title>
      <link>https://dschloe.github.io/mlops/ch04_airflow/airflow_01/</link>
      <pubDate>Thu, 08 Jul 2021 14:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch04_airflow/airflow_01/</guid>
      <description>인프런 강의  취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다.  스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다.   [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기   미니 프로젝트 개요  목적: Airflow와 빅쿼리를 활용하여 ETL 및 대시보드를 만들어보는 과정을 설계 환경: MacOS M1  Part I. Docker and Airflow   Docker와 Airflow를 설치 및 실행한다.</description>
    </item>
    
  </channel>
</rss>
