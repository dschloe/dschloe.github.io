<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Airflow on Data Science | DSChloe</title>
    <link>https://dschloe.github.io/categories/airflow/</link>
    <description>Recent content in Airflow on Data Science | DSChloe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 May 2025 01:40:47 +0900</lastBuildDate><atom:link href="https://dschloe.github.io/categories/airflow/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Airflow 활용한 API 크롤링 및 이미지 다운로드 (M1, MacOS)</title>
      <link>https://dschloe.github.io/python/2025/05/airflow_api_img_download/</link>
      <pubDate>Fri, 02 May 2025 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2025/05/airflow_api_img_download/</guid>
      <description>개요 Airflow 활용해서 이미지 다운로드 받기 예제 개발환경설정 MacOS, M1 Python uv 개발환경 설정 uv 설치 공식 싸이트 확인 링크 : https://docs.astral.sh/uv/getting-started/installation/#installation-methods curl -LsSf https://astral.sh/uv/install.sh | sh 가상환경 설정 다음과 같이 설정, 프로젝트 초기화 (Python 3.11 지정) $ uv venv -p 3.11 $ source .venv/bin/activate Python 버전 확인 $ python --version AIRFLOW_HOME 환경변수 지정 airflow는 환경변수에 예민하다. 프로젝트 디렉터리 경로에서 다음과 같이 추가 $ export AIRFLOW_HOME=$(pwd)/airflow $ echo $AIRFLOW_HOME /Users/evan/Desktop/your/project/directory/airflow 설치 스크립트 작성 파일명 : install_airflow.</description>
    </item>
    
    <item>
      <title>Docker Installation in Windows</title>
      <link>https://dschloe.github.io/settings/2022/10/docker_windows/</link>
      <pubDate>Sat, 29 Oct 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2022/10/docker_windows/</guid>
      <description>사전 준비 WSL2가 설치가 되어 있어야 한다. 참고 : https://dschloe.github.io/settings/wsl2_install_on_windows/ 도커 설치 해당 싸이트에 접속한다. (참조 : https://www.docker.com/products/docker-desktop/) 관리자 권한으로 실행 설치가 완료가 되면 Close and Log Out 버튼이 나오면 클릭하면 윈도우 로그아웃이 진행되기 때문에, 다시 재 로그인을 하도록 한다. 아래 그림 메뉴 우측 상단에 Sign In 버튼을 클릭해 로그인을 한다. 도커 Settings 창에 들어가서 아래 그림처럼 변경후 Apply &amp;amp; Restart 버튼을 클릭한다. 테스트 PowerShell에서 도커 명령어가 실행되는지 확인한다. PS C:\Users\h&amp;gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES PS C:\Users\h&amp;gt; docker --version Docker version 20.</description>
    </item>
    
    <item>
      <title>Airflow 데이터 파이프라인 구축 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json_sample/</link>
      <pubDate>Thu, 14 Apr 2022 21:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json_sample/</guid>
      <description>개요 이번에는 CSV-JSON으로 데이터를 변환하는 파이프라인을 구축하도록 한다. Step 01. Dags 폴더 생성 프로젝트 Root 하단에 Dags 폴더를 만든다. dags 폴더를 확인한다. $ ls airflow.cfg airflow.db dags logs venv webserver_config.py Step 02. 가상의 데이터 생성 이번 테스트에서 사용할 라이브러리가 없다면 우선 설치한다. $ pip3 install faker pandas faker 라이브러리를 활용하여 가상의 데이터를 생성한다. (파일 경로 : data/step01_writecsv.py) from faker import Faker import csv output=open(&amp;#39;data.csv&amp;#39;,&amp;#39;w&amp;#39;) fake=Faker() header=[&amp;#39;name&amp;#39;,&amp;#39;age&amp;#39;,&amp;#39;street&amp;#39;,&amp;#39;city&amp;#39;,&amp;#39;state&amp;#39;,&amp;#39;zip&amp;#39;,&amp;#39;lng&amp;#39;,&amp;#39;lat&amp;#39;] mywriter=csv.writer(output) mywriter.writerow(header) for r in range(1000): mywriter.</description>
    </item>
    
    <item>
      <title>Setting up Apache-Airflow in Windows using WSL2</title>
      <link>https://dschloe.github.io/settings/apache_airflow_using_wsl2/</link>
      <pubDate>Wed, 06 Apr 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/apache_airflow_using_wsl2/</guid>
      <description>개요 Windows WSL2에서 airflow를 설치한다. Step 1. Install pip on WSL airflow를 설치하기 위해 pip를 설치한다. $ sudo apt install python3-pip [sudo] password for username: Step 2. Install virtualenv package virtualenv 라이브러리를 설치한다. $ sudo pip3 install virtualenv Step 3. Create a virtual environment C드라이브에 airflow-test 폴더를 생성한다. 해당 디렉터리로 이동한다. 이제 가상환경을 생성한다. $ virtualenv venv 가상환경에 접속을 한다. $ source venv/bin/activate 이번에는 .bashrc 파일을 수정한다. $ vi ~/.bashrc 파일을 연 후, 다음과 같은 코드를 추가한다.</description>
    </item>
    
    <item>
      <title>Airflow를 활용한 Data Cleansing 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch05_cleaning_transforming/data_cleaning_using_airflow/</link>
      <pubDate>Mon, 20 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch05_cleaning_transforming/data_cleaning_using_airflow/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Pandas와 Airflow를 활용하여 데이터를 정제하는 코드를 구성한다. 우선 데이터는 아래에서 CSV 파일을 다운로드 받고, Dags 파일 하단에 위치시킨다. URL: https://github.com/PaulCrickard/escooter/blob/master/scooter.csv Raw 데이터 확인 간단하게 Raw 데이터를 확인해보도록 한다. import pandas as pd df = pd.</description>
    </item>
    
    <item>
      <title>Airflow를 활용한 PostgreSQL에서 Elasticsearch로 데이터 마이그레이션 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch04_working_databases/airflow_postgresql_elasticsearch/</link>
      <pubDate>Sat, 18 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch04_working_databases/airflow_postgresql_elasticsearch/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Airflow를 활용하여 PostgreSQL에 저장된 데이터를 디스크로 다운로드 받고, 그리고 그 파일을 다시 읽어서 Elasticsearch에 저장하도록 한다. 전체적인 흐름은 getData from PostgreSQL &amp;gt;&amp;gt; insertData to Elasticsearch 로 저장할 수 있다. 전체 코드 실행 우선 전체 코드를 실행하도록 한다.</description>
    </item>
    
    <item>
      <title>Apache Airflow를 활용한 CSV에서 JSON으로 변환하기</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json/</link>
      <pubDate>Thu, 09 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Apache Airflow에서 가장 중요한 개념은 DAG(Directed Acyclic Graph)이다. DAG를 만들 시, Bash 스크립트 및 연산자(Operator)로 작업을 정의할 수 있다. 이 때, 파이썬 함수로 조직화 한다. Airflow 설치방법을 모른다면 다음 페이지에서 확인한다. Apache Airflow Installation Step 01.</description>
    </item>
    
    <item>
      <title>Apache Airflow Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</link>
      <pubDate>Mon, 06 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 NiFi와 같은 용도의 소프트웨어이며, 현재 가장 인기 있는 오픈소스 데이터 파이프라인 도구라고 할 수 있다. 보통은 시스템에 경로를 설정한다. 그런데, 본 장에서는 가상환경 설정 후 진행하는 것으로 했다. 가상 환경은 virtualenv 를 통해서 진행한다.</description>
    </item>
    
    <item>
      <title>AirFlow ch01. 개요</title>
      <link>https://dschloe.github.io/mlops/ch04_airflow/airflow_00_intro/</link>
      <pubDate>Fri, 09 Jul 2021 14:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch04_airflow/airflow_00_intro/</guid>
      <description>인프런 강의 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 Airflow 2.0 원서 나온 것을 공부용으로 활용합니다. Airflow Project 이 책에 나온 내용을 Chapter별로 요약하여 정리하려고 한다. 원서 구매 페이지는 아래와 같다. 구매 페이지: Data Pipelines with Apache Airflow Chapter 1. Apache Airflow Introduction Figure 1.</description>
    </item>
    
    <item>
      <title>AirFlow 설치 및 실행 with M1</title>
      <link>https://dschloe.github.io/mlops/ch04_airflow/airflow_01/</link>
      <pubDate>Thu, 08 Jul 2021 14:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch04_airflow/airflow_01/</guid>
      <description>인프런 강의 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 미니 프로젝트 개요 목적: Airflow와 빅쿼리를 활용하여 ETL 및 대시보드를 만들어보는 과정을 설계 환경: MacOS M1 Part I. Docker and Airflow Docker와 Airflow를 설치 및 실행한다.
필자는 가상환경을 선정하고, 그 위에 도커를 추가로 설치하였다.</description>
    </item>
    
  </channel>
</rss>
