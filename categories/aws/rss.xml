<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS on Data Science | DSChloe</title>
    <link>https://dschloe.github.io/categories/aws/</link>
    <description>Recent content in AWS on Data Science | DSChloe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Mar 2025 01:00:47 +0900</lastBuildDate><atom:link href="https://dschloe.github.io/categories/aws/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AWS SageMaker 개발 환경 설정 on Windows 11 (feat. Anaconda)</title>
      <link>https://dschloe.github.io/settings/2025/03/anaconda_development_settings_2025_4_aws_sagemaker/</link>
      <pubDate>Tue, 11 Mar 2025 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2025/03/anaconda_development_settings_2025_4_aws_sagemaker/</guid>
      <description>개요 Anaconda 설치 (2025년 버전) Windows 11에서 설치 후 딥러닝 프레임워크 까지 개발환경 설정 다운로드 설치 파일 다운로드 : https://www.anaconda.com/download Skip Registration 버튼 선택 다음 화면에서 Download 버튼 클릭 설치파일 실행 필자는 관리자 권한으로 실행하는 것을 선호함 어떤 분은 Just Me 선택하기도 하지만, 필자는 All Users 선택 설치 경로 확인 기존에 Python이 설치가 되었더라도 Anaconda 파이썬 기준으로 테스트 할 예정이기 때문에 반드시 체크할 것 확인 버튼 클릭한다. Next 버튼 클릭 Launch Anaconda Navigator 체크박스 선택 후 Finish 버튼 선택 아래 화면이 나타나면 정상적으로 설치가 완료된 것이다.</description>
    </item>
    
    <item>
      <title>Amazon SageMaker ML on Local Machine via VS Code</title>
      <link>https://dschloe.github.io/aws/2025/03/amazon_sagemaker_vscode_example/</link>
      <pubDate>Mon, 10 Mar 2025 09:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/2025/03/amazon_sagemaker_vscode_example/</guid>
      <description>개요 AWS SageMaker 사용하여 ML 코드 생성 VS Code에서 코드 생성 S3 Bucket에서 모델 업로드 및 다운로드 응용하여 테스트 진행 코드 사전조건 SageMaker가 정상적으로 실행되려면 Docker가 필요할 수 있기, Docker를 먼저 설치하기를 바란다. AWS &amp;amp; SageMaker 연결 설정 I AM 에서 사용자에서 생성한다.
참고 : https://dschloe.github.io/aws/2025/03/connect2ec2viaawstoolkit/ Access Key까지 같이 생성한다.
사용자에 대한 I AM Role 도 생성한다.
awsMLDLRole 역할 이름을 부여했다.
Local PC 설정 Access Key와 Security Key 입력 $ aws configure AWS Access Key ID [****************BIGP]: AWS Secret Access Key [****************/5l8]: Default region name [us-east-1]: Default output format [json]: 만약 Default region name 변경을 원한다면 vi 편집기로 변경한다.</description>
    </item>
    
    <item>
      <title>Connect EC2 to VSCode using AWS Toolkit (2025 march)</title>
      <link>https://dschloe.github.io/aws/2025/03/connect2ec2viaawstoolkit/</link>
      <pubDate>Sun, 09 Mar 2025 12:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/2025/03/connect2ec2viaawstoolkit/</guid>
      <description>개요 Root 계정에서 사용자 그룹 만들기, I AM 정책 사용자 계정에서 정책과 역할 분배하기 VS Code에서 AWS Toolkit 이용해서 접속하기 사전조건 AWS 회원가입은 완료되어 있고, 로그인이 된 상태라 가정한다. VS Code에서 AWS Toolkit 설치가 되어 있다고 가정한다. Root 계정에서 I AM 계정 만들기 사용자 생성 I AM 검색 후 사용자 클릭, 사용자 생성 버튼을 클릭한다. 사용자 세부 정보에서 사용자 이름 선택 AWS Management Console에 대한 사용자 액세스 권한 제공 – 선택 사항 IAM 사용자를 생성하고 싶음 콘솔 암호 지정 A!</description>
    </item>
    
    <item>
      <title>AWS EC2 생성하기 (2025 march)</title>
      <link>https://dschloe.github.io/aws/2025/03/aws_ec2_created/</link>
      <pubDate>Sun, 09 Mar 2025 09:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/2025/03/aws_ec2_created/</guid>
      <description>개요 EC2 프리티어 생성하기 주요 개발환경 설정하기 (Ubuntu 기반) EC2 프리티어 생성 및 연결 계정 로그인 후, EC2 서비스 검색 후, EC2 클릭 인스턴스란, “구현된 컴퓨터”라고 생각한다. 인스턴스 시작 버튼을 클릭한다. 이제 본격적인 설계도를 하나 생성한다. 필자는 lectureServer01 이라고 명명했다. 다목적 개발이 목적이라면 Ubuntu(Linux)를 추천. 프리티어가 아닌 OS도 있으니 유의한다. 하드웨어 설정에서 보면 프리티어는 제가 알기로 t2.micro 하나다. 키 페어가 없어도 AWS가 만들어 놓은 대문(전용 Console)으로만 인스턴스에 접속할 수 있다. 하지만 인스턴스 열쇠(Key Pair)를 따로 발급받으면 전용 대문을 통하지 않고 제가 원하는 환경에서도 접속이 가능하다.</description>
    </item>
    
    <item>
      <title>Connect to AWS via VS Code (2025 버전)</title>
      <link>https://dschloe.github.io/settings/2025/03/connect2awsviavscode/</link>
      <pubDate>Thu, 06 Mar 2025 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2025/03/connect2awsviavscode/</guid>
      <description>개요 VS Code가 설치가 되어 있다고 가정한다. AWS 제품을 VS Code를 통해서 연결하도록 한다. Prerequisites VS Code requires a Windows, macOS, or Linux operating system. The AWS Toolkit for Visual Studio Code requires you to work from VS Code version 1.73.0 or a later version. AWS 회원가입 회원가입이 되어 있다면 이 부분은 생략한다. 회원가입을 진행한다. 주소 : https://signin.aws.amazon.com/signup?request_type=register 이메일 인증절차 진행 후, PW 등록한다. 연락처 정보를 입력한다. 결제 정보를 기재한다. 자격 증명 확인 Support 플랜 선택 여기서는 일단 무료로 시작한다.</description>
    </item>
    
    <item>
      <title>VS Code with AWS EC2 접속</title>
      <link>https://dschloe.github.io/aws/2023/09/vscode_aws_conn/</link>
      <pubDate>Mon, 11 Sep 2023 10:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/2023/09/vscode_aws_conn/</guid>
      <description>VSCode - Remote SSH 설치 putty 같은 SSH 툴로 vi 에디터 이용해서 수정 매우 불편함 vscode에서 직접 EC2에 접속하도록 한다. AWS Extension 확장팩 설치 아래와 같이 확장팩을 설치한다. Remote SSH Extension 확장팩 설치 Remote - SSH 확장팩을 아래와 같이 설치를 진행하도록 한다. 설치가 완료가 되면 SSH 연결할 호스트를 입력한다. ssh [계정]@[ip주소] ssh aa@1.1.1.1 /User/evan/.ssh/config 선택한다. 환경설정 config 파일을 연다. 설정 옵션 클릭 &amp;gt; ~/.ssh/config 클릭 config 파일이 열리는지 확인한다. config 파일 작성 / 수정 Host : 주소 이름 (띄어쓰기 금지) 변경 가능 HostName : IP/DNS 부여받은 IP를 입력 User : 계정 이름 Port : 연결할 포트 번호를 말하며, 기본포트는 22이다.</description>
    </item>
    
    <item>
      <title>AWS EC2 접속 (with pem &amp; ppk file)</title>
      <link>https://dschloe.github.io/aws/2023/09/aws_server_conn/</link>
      <pubDate>Sun, 10 Sep 2023 10:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/2023/09/aws_server_conn/</guid>
      <description>멀티캠퍼스 AWS 서버 관련 정리 실습용 서버 실행 https://console.aws.amazon.com/console/home 계정 ID(12자리) 또는 계정 별칭 : your account ID : your id / PW : your password 실습용 서버 사용자 정보 참조하여 로그인 (강의 때 공유)
비밀번호 변경
본인 비밀번호는 반드시 기억한다. (강사비번 : ****) Slack 강사 DM으로 남겨주세요. EC2 실행 우측 상단 리전 정보를 ‘오사카’로 변경 후 서비스 검색창에서 EC2 검색 변경된 상태에서 EC2 검색 위 서비스창에서 EC2 클릭 및 아래 화면에서 실행 표시된 인스턴스 실행 장비할당 관련 이름(Name) 순으로 정렬 후 할당된 서버 선택 (강의 때 참조) 필수 확인 서버의 경우 수업 시작 30분 전인 08:30부터 19시 까지 사용이 가능합니다.</description>
    </item>
    
    <item>
      <title>(AWS Project) BigData with Hadoop 05 - Hive Script 연습 예제</title>
      <link>https://dschloe.github.io/aws/02_bigdataplatform/step_5_run_hive_script/</link>
      <pubDate>Mon, 08 Jun 2020 15:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/02_bigdataplatform/step_5_run_hive_script/</guid>
      <description>I. Getting Started 처음 이 페이지를 방문했다면, 반드시 사전작업을 완료하기를 바란다. (AWS Project) BigData with Hadoop 02 - 사전작업 (AWS Project) BigData with Hadoop 03 - Amazon EMR Cluster 시작 (AWS Project) BigData with Hadoop 04 - Allow SSH Access II. What to do now Hive Script를 제출하는 방법에 대해 준비하였다. 를러스터를 생성할 때 단계를 지정하거나 마스터 노드에 연결하고 로컬 파일 시스템에서 스크립트를 생성하고 명렁어를 사용하여 실행할 수 있다. III.</description>
    </item>
    
    <item>
      <title>(AWS Project) BigData with Hadoop 04 - Allow SSH Access</title>
      <link>https://dschloe.github.io/aws/02_bigdataplatform/step_4_allow_ssh_access/</link>
      <pubDate>Sat, 06 Jun 2020 20:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/02_bigdataplatform/step_4_allow_ssh_access/</guid>
      <description>I. Getting Started 처음 이 페이지를 방문했다면, 반드시 사전작업을 완료하기를 바란다. (AWS Project) BigData with Hadoop 02 - 사전작업 (AWS Project) BigData with Hadoop 03 - Amazon EMR Cluster 시작 II. What to do now Client에서 SSH를 통해 클러스터에 접근하는 방법에 대해 다룬다. (1) Warning 보안 그룹은 클러스터에 대한 인바운드 및 아웃바운드 트래픽을 제어하는 가상 방화벽 역할을 한다. 첫 번째 클러스터를 생성하면 Amazon EMR은 마스터 인스턴스, ElasticMapReduce-master와 연결된 기본 Amazon EMR 관리 Security Group 및 핵심 노드 및 태스크 노드와 연결된 Security Group ElasticMapReduce-slave를 생성한다.</description>
    </item>
    
    <item>
      <title>(AWS Project) BigData with Hadoop 03 - Amazon EMR Cluster 시작</title>
      <link>https://dschloe.github.io/aws/02_bigdataplatform/step_3_launch_emr_cluster/</link>
      <pubDate>Wed, 03 Jun 2020 17:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/02_bigdataplatform/step_3_launch_emr_cluster/</guid>
      <description>I. Getting Started 처음 이 페이지를 방문했다면, 반드시 사전작업을 완료하기를 바란다. (AWS Project) BigData with Hadoop 02 - 사전작업 II. What to do now 이번 포스트에서는 비교적 간단하게 빅데이터 클러스터를 시작하는 과정을 진행한다. 막상 해보면 어려운 것은 아니지만, 언제나 그렇듯이 처음 할 때는 늘 시행착오를 겪게 마련이다. Amazon EMR console창에 있는 Quick Options을 사용한다. Quick Options에 있는 다양한 절차들에 대해 확인이 필요하면 Summary of Quick Options에서 확인해본다. III. Sample Cluster 시작 먼저 AWS에 있는 AWS Management Console을 클릭하여 실행하도록 한다.</description>
    </item>
    
    <item>
      <title>(AWS Project) BigData with Hadoop 02 - 사전작업</title>
      <link>https://dschloe.github.io/aws/02_bigdataplatform/step_2_setup/</link>
      <pubDate>Tue, 02 Jun 2020 16:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/02_bigdataplatform/step_2_setup/</guid>
      <description>I. Amazon S3 Bucket 생성 주요 요건 Hive 쿼리의 출력 데이터를 저장할 Amazon S3 버킷과 폴더를 지정한다. 자습서에서는 default log location을 사용하지만, 원하는 경우에는 custom location을 지정할 수 있다. 하둡의 요구사항 중, bucket과 folder names 다음과 같은 규칙을 적용한다. letters, numbers, periods(.), and hyphens(-) 등을 입력한다. 마지막 글자는 숫자로 끝맺음을 하지 않는다. 이러한 요구 사항을 충족하는 폴더에 이미 액세스할 수 있는 경우 이 튜토리얼에 해당 폴더를 사용하십시오. 출력 폴더는 비어 있어야 한다.</description>
    </item>
    
    <item>
      <title>(AWS Project) BigData with Hadoop 01 - Overview</title>
      <link>https://dschloe.github.io/aws/02_bigdataplatform/step_1_overview/</link>
      <pubDate>Tue, 02 Jun 2020 10:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/02_bigdataplatform/step_1_overview/</guid>
      <description>I. Overview Amazon EMR은 Apache 하둡과 Spark를 쉽고 빠르며 비용 효율적으로 실행하여 대량의 데이터를 처리할 수 있게 해주는 관리형 서비스입니다. Amazon EMR은 Presto, Hive, Pig, HBase 등과 같은 강력하고 입증된 하둡 도구를 지원한다. 이 프로젝트에서는 모든 기능이 작동하는 하둡 클러스터를 배포하여 몇 분 만에 로그 데이터를 분석할 준비를 갖추게 된다. 먼저 Amazon EMR 클러스터를 시작한 다음, HiveQL 스크립트를 사용하여 Amazon S3 버킷에 저장된 샘플 로그 데이터를 처리한다. HiveQL은 데이터 웨어하우징과 분석을 위한 SQL 유사 스크립트 언어이다.</description>
    </item>
    
    <item>
      <title>AWS - 회원가입 및 주요 서비스 간략 소개</title>
      <link>https://dschloe.github.io/aws/01_settings/register/</link>
      <pubDate>Sun, 31 May 2020 17:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/01_settings/register/</guid>
      <description>I. Overview 클라우드 서비스로써, AWS는 모든 IT 개발자에게 필수 Skill set과 같다. 데이터 분석가, 싸이언티스트에게도 AWS는 반드시 알아야 할 서비스이다. 매우 유명한 서비스이기에 자세한 내용은 다루지 않는다. 다만, 데이터 분석가라면 알아두어야 할 필수 서비스만 간단히 다루도록 할 예정이다. 간단하게 회원가입을 진행하도록 하자. II. Registration Step 1. 웹사이트 접속 및 계정 생성 웹사이트: https://aws.amazon.com/ko/ 우측 상단의 [AWS 계정 생성]을 클릭한다. Step 2. [계정 생성] 페이지에서 이메일 주소, 암호, AWS 계정 이름을 입력하고 [계속] 버튼을 클릭한다.</description>
    </item>
    
  </channel>
</rss>
