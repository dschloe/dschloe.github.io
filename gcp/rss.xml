<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GCPs on Data Science | DSChloe</title>
    <link>https://dschloe.github.io/gcp/</link>
    <description>Recent content in GCPs on Data Science | DSChloe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 21 Jun 2025 17:10:30 +0900</lastBuildDate><atom:link href="https://dschloe.github.io/gcp/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>GCP VM Connect to BigQuery using Streamlit (ver. 2025, 06)</title>
      <link>https://dschloe.github.io/gcp/2025/06/gce2bigquery_streamlit_202506/</link>
      <pubDate>Sat, 21 Jun 2025 17:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2025/06/gce2bigquery_streamlit_202506/</guid>
      <description>개요 VM 만들기 Web UI가 일부 변경됨 (추가 진행하기로 함) VM 생성 및 VS Code 연결 VM과 BigQuery 연결 VM 머신 생성 머신 구성 이름과 성능 체크 월별 예상 가격을 체크한다. OS 및 스토리지 Ubuntu - Ubuntu 24.04 LTS 방식으로 진행 (x86/64) 방식 선택 디스크 사이즈 : 25GB 암호화 : Google 관리 암호화 키 선택 데이터 보호 이 부분은 생략하고 넘어간다. 네트워킹 방화벽은 아래와 같이 HTTP &amp;amp; HTTPS 트래픽 허용 보안 액세스 범위 : 모든 Cloud API에 대한 전체 액세스 허용 VM 생성 다음과 같이 만들기 버튼 클릭 고정 IP 할당 VPC 네트워크 &amp;gt; IP 주소 클릭 오른쪽 끝 작업 하단 메뉴 선택 후 고정 IP 주소로 승급 선택 다음과 같이 임의의 이름 지정</description>
    </item>
    
    <item>
      <title>gcloud installation on Mac, SSH Connection with VSCode</title>
      <link>https://dschloe.github.io/gcp/2024/04/gcloud_mac_vscode/</link>
      <pubDate>Mon, 22 Apr 2024 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2024/04/gcloud_mac_vscode/</guid>
      <description>개요 gcloud를 Mac에서 설치를 하도록 한다. 참조 : https://cloud.google.com/sdk/docs/install-sdk?hl=ko 설치파일 다운로드 각 사용자 버전에 맞는 설치 파일을 다운로드 받는다. 필자는 M1 silicon 버전을 사용하기로 하였다. Desktop &amp;gt; gcloud_install 내부에 해당 파일을 다운로드 받았다. 압축을 풀면 아래와 같이 google-cloud-sdk 폴더 안애 install.sh 파일이 있다. 설치파일 실행 해당 폴더에 있는 파일에 접속해서 install.sh 파일을 실행한다. $ {your_location}/google-cloud-sdk/install.sh Welcome to the Google Cloud CLI! To help improve the quality of this product, we collect anonymized usage data and anonymized stacktraces when crashes are encountered; additional information is available at &amp;lt;https://cloud.</description>
    </item>
    
    <item>
      <title>gcloud Installation on Windows 11 - New Configuration</title>
      <link>https://dschloe.github.io/gcp/2024/04/gcloud_windows11_vscode/</link>
      <pubDate>Sun, 21 Apr 2024 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2024/04/gcloud_windows11_vscode/</guid>
      <description>개요 신규로 설치를 하는 것은 아래 링크를 참조한다. 링크 : https://dschloe.github.io/gcp/2023/09/gcloud_installation_windows11/ 기존에 설치 후, 재설치 할 때의 과정을 리뷰 한다. 재설치 재설치의 마지막 화면은 다음과 같다. Pick configuration to use, Section에서 2번을 선택한다. 이후 CMD 화면이 팝업화가 된다. Welcome to the Google Cloud CLI! Run &amp;#34;gcloud -h&amp;#34; to get the list of available commands. --- Welcome! This command will take you through the configuration of gcloud. Settings from your current configuration [default] are: accessibility: screen_reader: &amp;#39;True&amp;#39; compute: region: asia-northeast3 zone: asia-northeast3-a core: account: your_existing@gmail.</description>
    </item>
    
    <item>
      <title>Github Actions with GCE, SSH-Key 값 등록</title>
      <link>https://dschloe.github.io/gcp/2024/04/gce_githubactions_sshkey/</link>
      <pubDate>Fri, 19 Apr 2024 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2024/04/gce_githubactions_sshkey/</guid>
      <description>개요 Github Actions 강의 중, 애매한 부분을 정리하였다. Github Actions에 대한 전체 코드는 여기에서 다루지는 않는다. SSH-Key 값 설정 GCE에서 Github와 연동을 위해서는 Key값을 생성해야 한다. 본인의 구글클라우드 이메일을 추가하여 아래와 같이 코드를 실행한다. GCP의 ID와 Github의 이메일 주소가 다른 분들이 있다. 이럴 경우 문제가 발생할 수 있다. 주의 : Github 이메일 주소가 아님 $ ssh-keygen -t rsa -b 4096 -C &amp;#34;your@gmail.com&amp;#34; Github SSH Key값 생성 ssh의 public 키값을 복사한다. $ cat .</description>
    </item>
    
    <item>
      <title>BigQuery Connect to Google Analytics</title>
      <link>https://dschloe.github.io/gcp/2023/10/bigquery_to_ga4/</link>
      <pubDate>Thu, 26 Oct 2023 15:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/10/bigquery_to_ga4/</guid>
      <description>개요 BigQuery에서 Google Adwords 데이터와 Google Analytics를 불러올 수 있다. 전제조건 구글 클라우드 사용법은 어느정도 알고 있는 상태를 전제로 한다. Google Analytics를 이미 활용하고 있다는 것을 전제로 한다. Google Analytics 왼쪽 메뉴에서 관리 &amp;gt; 제품 링크를 확인한다. BigQuery 링크 클릭 &amp;gt; 연결 버튼을 클릭한다. BigQuery 프로젝트를 선택한다. 활성화중인 프로젝트를 선택한다. 데이터 위치를 지정한다. 본 프로젝트에서는 서울로 명명한다. 내보내기 유형은 매일로 선택한다. 사용자 데이터는 일별로 선택한다. 검토 후 제출 화면에서 특별한 이의사항이 없으면 보내기 버튼을 클릭한다.</description>
    </item>
    
    <item>
      <title>Streamlit App Deployment Compute Engine with Github Action in GCP</title>
      <link>https://dschloe.github.io/gcp/2023/10/streamlit_gcp_githubaction/</link>
      <pubDate>Wed, 25 Oct 2023 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/10/streamlit_gcp_githubaction/</guid>
      <description>개요 Google Compute Engine에서 Gihub Action을 구현하도록 한다. 프로젝트 생성 새 프로젝트 버튼을 클릭 후 프로젝트 명을 streamlit-gitaction으로 명명한다. Instance 생성 Compute Engine &amp;gt; VM Instance 선택 후, 새로운 인스턴스를 생성한다. 처음 사용하는 경우 사용 버튼을 클릭한다. 최초 작업에는 결제 필요 버튼이 나올 수 있다. 결제 사용 설정을 눌러 결제를 추가한다. 필자는 회사 계정을 사용한 것이므로 이렇게 나오지만, 일반 사용자는 화면이 다를 수 있다. VM 인스턴스를 생성한다. 인스턴스 이름과 리전과 영역은 다음과 같이 진행한다.</description>
    </item>
    
    <item>
      <title>Streamlit App Deployment with nohup in Google Compute Engine</title>
      <link>https://dschloe.github.io/gcp/2023/09/streamlit_nohup_on_gce/</link>
      <pubDate>Thu, 28 Sep 2023 16:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/streamlit_nohup_on_gce/</guid>
      <description>개요 Streamlit과 Bigquery를 연동하는 코드를 구현한다. 가상환경 설정 부터 VS Code 연동까지 준비가 안되어 있다면 이전 글을 참조하기를 바란다. 만약 GCP가 처음이신 분들은 이전 글을 순차적으로 읽어본다. Spark Installation with GCP (Sept. 2023) Compute Engine with Github in GCP Python Library Installation on Compute Engine in GCP GCP with VS Code SSH Connection gcloud Installation on Windows 11 Streamlit with Bigquery On Compute Engine 개요 Streamlit Sample 코드를 작성한 후 배포를 진행한다.</description>
    </item>
    
    <item>
      <title>Streamlit with Bigquery On Compute Engine</title>
      <link>https://dschloe.github.io/gcp/2023/09/streamlit_bigquery_gce/</link>
      <pubDate>Fri, 22 Sep 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/streamlit_bigquery_gce/</guid>
      <description>개요 Streamlit과 Bigquery를 연동하는 코드를 구현한다. 가상환경 설정 부터 VS Code 연동까지 준비가 안되어 있다면 이전 글을 참조하기를 바란다. 만약 GCP가 처음이신 분들은 이전 글을 순차적으로 읽어본다. Spark Installation with GCP (Sept. 2023) Compute Engine with Github in GCP Python Library Installation on Compute Engine in GCP GCP with VS Code SSH Connection gcloud Installation on Windows 11 인스턴스 시작 인스턴스가 중지가 되어 있다면 다시 시작을 한다. BigQuery Client 라이브러리 설치 클라이언트 라이브러리를 설치한다.</description>
    </item>
    
    <item>
      <title>gcloud Installation on Windows 11</title>
      <link>https://dschloe.github.io/gcp/2023/09/gcloud_installation_windows11/</link>
      <pubDate>Thu, 21 Sep 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/gcloud_installation_windows11/</guid>
      <description>개요 Windows 11에서 gcloud 설치를 진행한다. 참조 문서 : https://cloud.google.com/sdk/docs/install-sdk?hl=ko gcloud CLI 최신 버전(445.0.0) 설치 [Google Cloud CLI 설치 프로그램] (https://dl.google.com/dl/cloudsdk/channels/rapid/GoogleCloudSDKInstaller.exe?hl=ko) 다운로드 한다. 또는 PowerShell 터미널을 열고 다음 PowerShell 명령어를 실행한다. 여기에서는 설치 프로그램을 다운로드 받아서 설치한다. Finish 버튼을 클릭하면 설치는 완료가 된 것이다. gcloud 연동 위 Finish 버튼과 함께 로그인을 진행한다. 인증절차가 시작완료되면 웹 페이지가 변경되고 터미널 환경도 변경된다. 현재 필자의 프로젝트는 3번에 해당되기 때문에 3번을 클릭한다. default Region and Zone이 나오면 Y를 선택한다.</description>
    </item>
    
    <item>
      <title>GCP with VS Code SSH Connection</title>
      <link>https://dschloe.github.io/gcp/2023/09/gcp_with_vscode/</link>
      <pubDate>Wed, 20 Sep 2023 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/gcp_with_vscode/</guid>
      <description>개요 SSH Key를 이용하여 로컬에서 원격으로 GCP 프로젝트에 접속을 한다. 만약 GCP가 처음이신 분들은 이전 글을 순차적으로 읽어본다. Spark Installation with GCP (Sept. 2023) Compute Engine with Github in GCP Python Library Installation on Compute Engine in GCP SSH Key 생성하기 puTTYgen에서 public / private key 값을 생성한다. Generate 버튼을 클릭한다. Private Key를 OpenSSH 방식으로 Export 한다. Key Comment에 구글 계정을 입력한다. password도 입력한다. Public Key는 모두 복사한다. GCP 메타데이터 등록 Compute Engine &amp;gt; 메타데이터 접속하여 SSH 키에 붙여 넣는다.</description>
    </item>
    
    <item>
      <title>Python Library Installation on Compute Engine in GCP</title>
      <link>https://dschloe.github.io/gcp/2023/09/python_library_installation/</link>
      <pubDate>Tue, 19 Sep 2023 15:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/python_library_installation/</guid>
      <description>개요 기 설치된 Compute Engine에 라이브러리를 설치하고 간단하게 Streamlit 배포를 진행한다. 만약 GCP가 처음이신 분들은 이전 글을 순차적으로 읽어본다. Spark Installation with GCP (Sept. 2023) Compute Engine with Github in GCP requirements.txt Github Repo에서 Add file &amp;gt; Create new file을 클릭 후, 아래 주요 라이브러리를 입력한다. 파일명 : requirements.txt 라이브러리명은 다음과 같다. 입력 후, Commit Changes 버튼을 클릭한다. pyspark==3.1.1 pandas streamlit matplotlib 현재 파일 목록은 아래와 같다. 이제 GCP 터미널에서 requirements.</description>
    </item>
    
    <item>
      <title>Compute Engine with Github in GCP</title>
      <link>https://dschloe.github.io/gcp/2023/09/compute_engine_github/</link>
      <pubDate>Tue, 19 Sep 2023 14:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/compute_engine_github/</guid>
      <description>개요 Google Cloud Project에서 Github 계정을 연동하는 과정을 보여준다. 처음 GCP를 사용하는 독자분들은 이전 글을 참조해서 설정을 먼저 진행한다. 참조 : https://dschloe.github.io/gcp/2023/09/spark_installation_gcp/ 터미널 열기 기존 인스턴스는 중지를 시켰기 때문에 이를 다시 시작/재개 버튼을 눌러 활성화 한다. 시작 버튼 클릭과 함께 오늘도 비용을 지불해본다. 브라우저 창에서 열기를 진행한다. Git 설치 터미널에 Git을 설치하는 방법은 다음 명령어를 순차적으로 입력한다. (base) ~$ sudo apt-get update -y (base) ~$ sudo apt-get upgrade -y (base) ~$ sudo apt install git (base) ~$ git --version Git Repo 생성 Github에서 Repo를 만든다.</description>
    </item>
    
    <item>
      <title>Spark Installation with GCP (Sept. 2023)</title>
      <link>https://dschloe.github.io/gcp/2023/09/spark_installation_gcp/</link>
      <pubDate>Tue, 19 Sep 2023 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/spark_installation_gcp/</guid>
      <description>개요 Spark를 구글 클라우드에 설치하도록 한다. 프로젝트 시작부터 진행한다. 프로젝트 시작 본 화면에서 새로운 프로젝트를 시작한다. 프로젝트명 : mulcampFP VM 시작하기 VM 만들기를 클릭한다. 활성 결제 계정이 없으면 결제계정을 등록한다. 결제계정이 등록되면 다음과 같이 화면이 나오면 VM 설정이 가능하다. 결제계정까지 완료가 되었으면 다음과 같이 Compute Engine API를 사용 버튼을 클릭해준다. 이름은 mulcamp-gcp 지역은 서울로 했다. 비용에 따라 성능을 선택할 수 있다. 호스트 유지보수 시, VM 인스턴스는 마이그레이션을 권장한다. 부팅 디스크는 Ubuntu로 변경했다.</description>
    </item>
    
    <item>
      <title>Google Apps Script 기본문법 - 2</title>
      <link>https://dschloe.github.io/gcp/2023/09/google_apps_script2/</link>
      <pubDate>Tue, 05 Sep 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/google_apps_script2/</guid>
      <description>조건문 if 조건문 코드는 아래와 같음 여러개의 조건문은 &amp;amp;&amp;amp; 연산자 또는 || 연산자를 사용한다. function myFunction_01() { let number=9; if(number &amp;gt; 10) { console.log(&amp;#34;큰 수입니다!&amp;#34;) } else { console.log(&amp;#34;작은 수입니다.&amp;#34;) } } function myFunction_02() { var currentTemperature = 25; var isWeekend = true; var thresholdTemperature = 35; if (currentTemperature &amp;gt; thresholdTemperature &amp;amp;&amp;amp; !isWeekend) { console.log(&amp;#34;집에 계세요!&amp;#34;) } else if (currentTemperature &amp;gt; thresholdTemperature || isWeekend) { console.log(&amp;#34;외출하세요!&amp;#34;) } else { console.log(&amp;#34;판단을 보류합니다!</description>
    </item>
    
    <item>
      <title>Google Apps Script 기본문법 - 1</title>
      <link>https://dschloe.github.io/gcp/2023/09/google_apps_script_1/</link>
      <pubDate>Mon, 04 Sep 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/google_apps_script_1/</guid>
      <description>개요 Google Apps Script의 기본문법을 배우도록 한다. 변수와 상수, 배열, 객체등을 테스트 한다. 자바스크립트 기초 기초 문법을 배우도록 한다. 아래와 같이 코드 생성 후 실행을 한다. function myFunction() { Logger.log(&amp;#34;Hello World&amp;#34;); } 여러 함수를 만들고 선택적으로 실행이 가능하다. 주석 처리는 크게 // /* */ 으로 할 수 있다. function myFunction01_1() { Logger.log(&amp;#34;Hello World&amp;#34;); } function myFunction01_2() { console.log(&amp;#34;Hello GAS!&amp;#34;) // 주석 입력 /* 여러 행에 걸쳐 주석을 입력한다. */ } 스크립트 편집기에서는 [Ctrl] + [/] 를 이용하면 주석처리가 가능하다.</description>
    </item>
    
    <item>
      <title>Streamlit와 BigQuery 활용한 배포 (API)</title>
      <link>https://dschloe.github.io/gcp/2023/05/streamlit_bigquery/</link>
      <pubDate>Thu, 18 May 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/05/streamlit_bigquery/</guid>
      <description>사전학습 이 글을 읽기전에 한번 Streamlit 라이브러리를 활용한 배포 - BigQuery 사용 을 읽고 오기를 바란다. 실습 순서 서울시 부동산 실거래가를 API 크롤링으로 가져온다. JSON 형태의 데이터를 pandas 데이터프레임으로 변환한다. 데이터프레임을 BigQuery에 전체 데이터를 저장한다. 저장된 데이터프레임을 BigQuery에서 일부 컬럼만 불러온다. 실습 1 - API 크롤링에서 빅쿼리로 데이터 저장 .streamlit/secrets.toml 을 열고 아래와 같이 설정한다. seoul_api_key는 서울 열린데이터 광장을 의미한다. gcp_service_account 아래 내용은 api key를 json 파일로 열면 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>Google Clound &amp; WSL2 Ubuntu 20.04 개발환경 설정</title>
      <link>https://dschloe.github.io/gcp/2023/02/gcp_wsl2_settings/</link>
      <pubDate>Sun, 26 Feb 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/02/gcp_wsl2_settings/</guid>
      <description>개요 GCP에서 개발환경을 설정하도록 한다. Local PC에서 GCP로 접속을 하도록 한다. 사전준비 WSL2 Ubuntu 설치 과정은 여기에서 다루지 않는다. 개발환경 설치 Python3 설치한다. (본인에게 맞는 언어를 선택한다) sudo apt update sudo apt install -y python3 python3-pip python3 최신 버전(417.0.1) gcloud CLI 설치 참고자료 : https://cloud.google.com/sdk/docs/install-sdk?hl=ko gcloud CLI를 설치하기 전 운영체제가 다음 요구사항을 충족하는지 확인합니다. $ sudo apt-get install apt-transport-https ca-certificates gnupg 패키지 소스로 gcloud CLI 배포 URI를 추가합니다. 배포판에서 서명 옵션을 지원하는 경우 다음 명령어를 실행합니다.</description>
    </item>
    
    <item>
      <title>BigQuery ML을 사용한 펭귄 체중 예측</title>
      <link>https://dschloe.github.io/gcp/bigquery/04_bigqueryml/bigquery_ml_penguins_20220121/</link>
      <pubDate>Fri, 21 Jan 2022 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/04_bigqueryml/bigquery_ml_penguins_20220121/</guid>
      <description>개요 BigQuery ML을 소개한다. BigQuery ML을 사용하면, 머신러닝 모델을 만들고 또한 실행할 수 있다. 목표 BigQuery ML에서 CREATE MODEL 문을 사용하여 선형회귀 모델 만들기 ML.EVALUATE 함수를 사용하여 ML 모델 평가 ML.PREDICT 함수를 사용하여 ML 모델 예측 주의 사항 BigQuery 비용 관련된 문서는 다음과 같다. BigQuery 가격 책정: https://cloud.google.com/bigquery/pricing BigQuery 가격 책정**:** https://cloud.google.com/bigquery-ml/pricing 1단계: 데이터 세트 만들기 데이터 세트 ID에 bqml_practice 입력 데이터 위치로 미국 US 선택 나머지는 모두 Default로 설정한다. 2단계: 모델 만들기 데이터 소개 먼저 데이터를 소개한다.</description>
    </item>
    
    <item>
      <title>GCP Settings 2022 ver</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/gcp_settings_20220118/</link>
      <pubDate>Tue, 18 Jan 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/gcp_settings_20220118/</guid>
      <description>개요 GCP 빅쿼리를 연동하는 예제를 구현한다. 먼저 빅쿼리를 통해 데이터를 적재하는 예제를 확인한다. 구글 코랩에서 빅쿼리 데이터를 불러온다. 데이터 스튜디오에서 빅쿼리 데이터를 불러온다. 소개 빅쿼리를 소개하는 영상은 유투브에서 검색하면 매우 쉽게 확인할 수 있다. 영상 참조: 데이터 웨어하우스 끝판왕 BigQuery 어디까지 알고 계신가요 Google Cloud 회원가입 준비물 Google 계정 신용카드나 체크카드 (개인적으로 돈이 없는 체크카드 사용 권장) 구글 클라우드 사이트 접속 싸이트: https://cloud.google.com/ 무료 서버 받으려면 아래 화면에서 TRY IT FREE 를 클릭한다.</description>
    </item>
    
    <item>
      <title>Training Data Split in BigQuery</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/random_sampling/</link>
      <pubDate>Tue, 04 May 2021 22:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/random_sampling/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>(SQL-Tutorial) 데이터 분석을 위한 SQL 레시피와 빅쿼리 사용</title>
      <link>https://dschloe.github.io/gcp/bigquery/03_sql_recipe/01_sql_tutorial_intro/</link>
      <pubDate>Thu, 22 Apr 2021 09:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/03_sql_recipe/01_sql_tutorial_intro/</guid>
      <description>1줄 요약 데이터 분석을 위한 SQL 레시피 교재를 빅쿼리에서 활용해본다.
책 소개 블로그 글 중 잘 정리된 글이 있어 소개합니다. 빅데이터책: 데이터 분석을 위한 SQL 레시피 읽어보았습니다. 실습 준비 도서의 부록/예제소스를 다운로드 하세요.
예제 소스 코드를 열어봅니다. sql 소스코드로 구성이 되어 있는 것을 확인할 수 있습니다.
저자가 말하는 샘플 데이터 내용은 아래와 같습니다. 이번에는 임의의 SQL 파일을 열어서 확인하도록 합니다.
위 이미지에서 보면, Table을 생성하는 형태로 구성이 되어 있는 것을 알 수 있습니다.</description>
    </item>
    
    <item>
      <title>Kaggle-Python-Bigquery 연동 예제</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/python_bigquery/</link>
      <pubDate>Fri, 16 Apr 2021 15:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/python_bigquery/</guid>
      <description>1줄 요약 캐글 데이터를 빅쿼리에 넣어보 캐글 데이터 다운로드 캐글 데이터를 다운로드 받습니다. !pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: six&amp;gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1) Requirement already satisfied: tqdm in /usr/local/lib/python3.</description>
    </item>
    
    <item>
      <title>Ch07_data_upload</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch07_data_load_from_local/</link>
      <pubDate>Fri, 08 Jan 2021 15:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch07_data_load_from_local/</guid>
      <description>공지 구글 빅쿼리 책 Chapter 4장 학습 참고 교재는 아래와 같다. 개요 로컬에서 데이터를 업로드 해본다. 데이터 다운로드 깃허브에서 데이터를 다운로드 받는다. $ git clone https://github.com/onlybooks/bigquery.git ch04 폴더로 이동한 뒤, 실제 압축된 파일의 내용을 페이지 단위로 확인해본다. 먼저 ch04 폴더로 이동한다. zlees 명령으로 데이터를 확인해본다. $ cd bigquery/ch04 $ zless college_scorecard.csv.gz 명령을 실행한 후 스페이스 이용하여 페이지 단위로 데이터 확인 후, 종료하려면 q키를 누른다. zless는 .gz과 같은 파일을 풀지 않고 Preview 형식으로 볼 수 있도록 도와준다.</description>
    </item>
    
    <item>
      <title>Ch06_gcloud_projects</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch06_gcloud_projects/</link>
      <pubDate>Thu, 07 Jan 2021 17:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch06_gcloud_projects/</guid>
      <description>개요 MacOS m1, Big Sur에서 gcloud 환경 세팅을 해본다. 목표는 gcloud를 설치 한 뒤, 신규 프로젝트를 설치하도록 한다. gcloud projects list 현재 active project를 실행하여 보여주는 명령어를 실행하여 확인한다. 프로젝트는 각 계정마다 조금씩 다를 수 있다. $ gcloud projects list PROJECT_ID NAME PROJECT_NUMBER biggquerysample biggquerysample 826877287968 New gcloud projects 이제 새로운 프로젝트를 만들어본다. $ gcloud projects create bigquerysample2 Create in progress for [https://cloudresourcemanager.googleapis.com/v1/projects/your_project_name]. Waiting for [your_number_will_be_created] to finish...done. Enabling service [cloudapis.</description>
    </item>
    
    <item>
      <title>Ch05_gcloud_settings</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch05_gcloud_settings/</link>
      <pubDate>Thu, 07 Jan 2021 11:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch05_gcloud_settings/</guid>
      <description>개요 MacOS m1, Big Sur에서 gcloud 환경 세팅을 해본다. 목표는 gcloud를 설치 한 뒤, 신규 프로젝트를 설치하도록 한다. Cloud SDK 시작 전 MacOS에서는 Python이 필요하다. 지원되는 버전은 Python3(권장, 3.5 ~ 3.8) 및 Python 2 (2.7.9) 이상이다. 만약 Python이 설치되지 않았다면 추가로 설치를 진행해야 한다. https://www.python.org/ Cloud SDK 시작 필요한 파일 및 설치 참고 자료는 공식홈페이지: 빠른 시작: Cloud SDK 시작하기 에서 확인한다. 압축 파일을 풀고 해당 경로로 이동한다. 이 때, 환경문제가 발생할 수 있으니, 가급적 .</description>
    </item>
    
    <item>
      <title>구글 텐서플로우 공인 자격증 취득 방법</title>
      <link>https://dschloe.github.io/gcp/certification/tensorflow_certification/</link>
      <pubDate>Mon, 15 Jun 2020 17:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/certification/tensorflow_certification/</guid>
      <description>I. Python 개발환경 (2020.06.20) 기준 텐서플로 자격증 시험은 PyCharm에서 실행된다. 텐서플로 버전 2.x을 사용하고, (1.x) 사용하지 않는다. 파이썬 버전은 3.7을 사용한다. 만약 현재 다른 버전을 사용한다면, 별도로 선정해야 하는 번거로움이 있다. 추가 확인 사항 우선, 인터넷 환경이 안정적이어야 한다. PyCharm 기반 구성에 대해 익숙해져야 한다. 작성 중&amp;hellip;</description>
    </item>
    
    <item>
      <title>Ch22 Cleaner Null Handling with Coalesce</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch22_cleaner_null_handling_with_coalesce/</link>
      <pubDate>Sun, 14 Jun 2020 22:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch22_cleaner_null_handling_with_coalesce/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch21 Conditional Expressions</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch21_conditional_expressions/</link>
      <pubDate>Thu, 28 May 2020 12:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch21_conditional_expressions/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch20 Logical Operations</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch20_logical_operations/</link>
      <pubDate>Wed, 27 May 2020 20:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch20_logical_operations/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch19 Comparisons Decimal Calculations</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch19_comparisons_decimal_calculations/</link>
      <pubDate>Tue, 26 May 2020 18:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch19_comparisons_decimal_calculations/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch18 Mathematical Functions</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch18_mathematical_functions/</link>
      <pubDate>Mon, 25 May 2020 07:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch18_mathematical_functions/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다.</description>
    </item>
    
    <item>
      <title>Ch17 Types of Functions</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch17_types_of_functions/</link>
      <pubDate>Fri, 22 May 2020 17:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch17_types_of_functions/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch16 Data Types - Numeric types</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch16_data_types_numeric_types/</link>
      <pubDate>Thu, 21 May 2020 07:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch16_data_types_numeric_types/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch15 Outer Join</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch15_outer_join/</link>
      <pubDate>Tue, 19 May 2020 07:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch15_outer_join/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch14 Cross Join</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch14_cross_join/</link>
      <pubDate>Fri, 15 May 2020 17:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch14_cross_join/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch13 Inner Join</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch13_inner_join/</link>
      <pubDate>Fri, 08 May 2020 14:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch13_inner_join/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch12 Join Explained</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch12_join_explained/</link>
      <pubDate>Thu, 07 May 2020 14:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch12_join_explained/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch11 Powerful SQL Pattern</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch11_powerful_sql_pattern/</link>
      <pubDate>Sun, 03 May 2020 13:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch11_powerful_sql_pattern/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch10 UNNEST an Array</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch10_unnest_an_array/</link>
      <pubDate>Sat, 02 May 2020 19:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch10_unnest_an_array/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch09 Struct, Tuple</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch09_struct_and_tuple/</link>
      <pubDate>Thu, 30 Apr 2020 15:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch09_struct_and_tuple/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch08_Creating_Arrays_with_Array_AGG</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch08_creating_arrays_with_array_agg/</link>
      <pubDate>Wed, 29 Apr 2020 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch08_creating_arrays_with_array_agg/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch07 Arrays &amp; Structs</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch07_split_unnest/</link>
      <pubDate>Mon, 27 Apr 2020 20:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch07_split_unnest/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch06 SQL Aggregates</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch06_sql_aggregates/</link>
      <pubDate>Sun, 26 Apr 2020 11:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch06_sql_aggregates/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch05 Query Essentials(3)</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials3/</link>
      <pubDate>Sat, 25 Apr 2020 16:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials3/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch05 Query Essentials(2)</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials2/</link>
      <pubDate>Fri, 24 Apr 2020 13:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials2/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch05 Query Essentials(1)</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials1/</link>
      <pubDate>Thu, 23 Apr 2020 18:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials1/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch04_bigquery_with_R</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch04_bigquery_with_r/</link>
      <pubDate>Tue, 21 Apr 2020 11:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch04_bigquery_with_r/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, R과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch03_bigquery_with_python</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch03_bigquery_with_python/</link>
      <pubDate>Sun, 19 Apr 2020 20:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch03_bigquery_with_python/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch02 Working with BigQuery</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch02_working_with_bigquery/</link>
      <pubDate>Sun, 19 Apr 2020 00:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch02_working_with_bigquery/</guid>
      <description>I. Get Started 일단 시작해보자. https://console.cloud.google.com/bigquery
뉴욕주의 자전거 렌탈이 비가 올때와 그렇지 않을 때 수치를 비교하고자 않다. 어떻게 해야할까? 일단, 필요한 데이터는 두가지가 될 것이다. 첫번째는 자전거 렌탈 데이터가 필요하고, 두번째는 뉴욕주의 날씨와 관련된 데이터이다. 두개의 데이터를 조인(join)한 후 수치를 구해야 할 것이다.
위 화면에서 아래 소스코드를 입력한다.
WITH bicycle_rentals AS ( SELECT COUNT(starttime) as num_trips, EXTRACT(DATE from starttime) as trip_date FROM `bigquery-public-data.new_york_citibike.citibike_trips` GROUP BY trip_date ), rainy_days AS ( SELECT date, (MAX(prcp) &amp;gt; 5) AS rainy FROM ( SELECT wx.</description>
    </item>
    
    <item>
      <title>Ch01 BigQuery getstarted</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch01_bigquery_getstarted/</link>
      <pubDate>Thu, 16 Apr 2020 11:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch01_bigquery_getstarted/</guid>
      <description>I. 자료 정리를 하며.. 데이터 분석가에게 또는 싸이언티스트들에게 SQL문법은 매우 중요하다. 지금도 어딘가에는 데이터는 쌓이고 있고, 문제는 쌓여 있는 데이터를 활용해서 어떤 비즈니스 문제를 해결할지가 가장 큰 이슈이기 때문이다.
그동안 SQL은 MySQL과 RDB 문법, MongoDB와 NoSQL과 같은 문법으로 나누어서 볼 수 있다. 강사가 과거 프로젝트에서 사용했던 SQL은 MySQL, MSSQL, MongoDB가 있었는데, 각각의 문법이 다르다는 측면이 있어서 조금 애를 많이 먹었다. 특히 MongoDB문법은 JSON 형태로 되어 있기 때문에, 별도의 문법이라 보는게 더 낫다.</description>
    </item>
    
  </channel>
</rss>
