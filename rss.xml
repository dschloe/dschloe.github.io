<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science | DSChloe</title>
    <link>https://dschloe.github.io/</link>
    <description>Recent content on Data Science | DSChloe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 08 Feb 2025 01:00:47 +0900</lastBuildDate><atom:link href="https://dschloe.github.io/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>OpenAI Whisper 사용 위한 ffmpeg 설치</title>
      <link>https://dschloe.github.io/settings/2025/02/ffmpeg_install/</link>
      <pubDate>Sat, 08 Feb 2025 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2025/02/ffmpeg_install/</guid>
      <description>개요 OpenAI의 Whisper 사용을 위해 필수적으로 설치해야 할 ffmpeg 설치 예제 각 OS별 설치 명령어 확인 Windows에서 패키지 관리자가 없을 경우 설치 방법 안내 OS별 설치 명령어 # Windows (chocolatey 사용) choco install ffmpeg # Windows (scoop 사용) scoop install ffmpeg # macOS (homebrew 사용) brew install ffmpeg # Ubuntu/Debian sudo apt update sudo apt install ffmpeg # CentOS/RHEL sudo yum install epel-release sudo yum install ffmpeg ffmpeg-devel # Fedora sudo dnf install ffmpeg ffmpeg-devel 패키지 관리자가 없을 경우 공식 웹사이트 방문 : https://ffmpeg.</description>
    </item>
    
    <item>
      <title>Google Colab &amp; Jupyter Notebook에서 dotenv 사용법</title>
      <link>https://dschloe.github.io/settings/2025/02/google_colab_jupyter_lab_dotenv/</link>
      <pubDate>Sun, 02 Feb 2025 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2025/02/google_colab_jupyter_lab_dotenv/</guid>
      <description>개요 환경 변수를 코드 내에 직접 작성하는 것은 보안상 위험할 수 있다. 이를 방지하기 위해 .env 파일을 사용하여 환경 변수를 저장하고, dotenv 라이브러리를 활용해 이를 불러올 수 있다.
이번 글에서는 Google Colab 및 Jupyter Notebook에서 dotenv 사용법을 다룬다.
1. dotenv란? dotenv는 .env 파일에 저장된 환경 변수를 쉽게 로드할 수 있도록 도와주는 라이브러리이다. 이를 활용하면 API 키, 데이터베이스 접속 정보 등을 안전하게 관리할 수 있다.
Python에서는 python-dotenv을 사용한다.
2. dotenv 설치하기 Jupyter Notebook 또는 Google Colab에서 설치 !</description>
    </item>
    
    <item>
      <title>OS별 환경변수 설정 (Linux &amp; macOS / Windows)</title>
      <link>https://dschloe.github.io/settings/2025/02/environment_variables/</link>
      <pubDate>Sat, 01 Feb 2025 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2025/02/environment_variables/</guid>
      <description>1. Linux &amp;amp; macOS 1.1 임시 환경변수 설정 (현재 세션에서만 유효) export 변수명=값 예)
export PATH=$PATH:/usr/local/bin export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home 위 설정은 현재 터미널 세션에서만 유효하며, 터미널을 닫으면 사라진다.
1.2 영구 환경변수 설정 (1) Bash Shell (bash 사용 시) ~/.bashrc 또는 **~/.bash_profile*에 추가
export 변수명=값 예)
export PATH=$PATH:/usr/local/bin export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home 적용:
source ~/.bashrc # 또는 source ~/.bash_profile (2) Zsh Shell (macOS 기본 Shell) ~/.zshrc 파일 수정:
export 변수명=값 예)
export PATH=$PATH:/usr/local/bin export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-17.</description>
    </item>
    
    <item>
      <title>대한민국 최신 행정구역(SHP) 다운로드 (2025 version)</title>
      <link>https://dschloe.github.io/python/2025/01/gisdeveloper_2025/</link>
      <pubDate>Tue, 21 Jan 2025 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2025/01/gisdeveloper_2025/</guid>
      <description>개요 2023년 12월 이후의 최신 행정구역(SHP) 데이터 다운로드 방법 변경 사이트 : http://www.gisdeveloper.co.kr/?p=2332 지오서비스웹(GEOSERVICE-WEB)의 아카이브 통해서 다운로드 관련 영상 원하는 지역에 대한 최신 행정구역 데이터(SHP 파일) 추출해서 다운로드 받기 위한 내용 상세히 설명한 영상 (링크 : https://www.youtube.com/watch?v=1vkI5tmIlgI) https://www.youtube.com/watch?v=1vkI5tmIlgI
회원가입 - 지오서비스웹(GEOSERVICE-WEB) 사이트 : https://www.geoservice.co.kr/ 회원가입 서비스 계정 약관 닉네임 / 실명 입력 닉네임 : jjh430 실명 : 정지훈 비밀번호 입력 : tkfkdgo486! 이메일 / 휴대폰 입력 인증코드 확인 본인 인증 완료 및 로그인 GEOSERVICE 화면 메인 화면은 아래와 같음 원하는 지역 최신 행정구역 데이터 추출 왼쪽 상단의 아카이브 선택 검색창에 ‘gizmo’ 입력 최신행정구역도 선택 여기에서 시군구만 선택해서 다운로드 무제한 다운로드를 방지하기 위해 지오코인 제도를 도입함 QGIS 설치 지도 경계 작업을 수행할 QGIS 파일을 다운로드 받는다.</description>
    </item>
    
    <item>
      <title>Flutter on Cursor AI on M1</title>
      <link>https://dschloe.github.io/flutter/2025/01/flutter_usage_on_cursorai/</link>
      <pubDate>Fri, 03 Jan 2025 01:03:28 +0900</pubDate>
      
      <guid>https://dschloe.github.io/flutter/2025/01/flutter_usage_on_cursorai/</guid>
      <description>개요 Cursor AI 에서 Flutter 설치를 해본다. 사전에 VS Code, Flutter 설치가 되어 있다고 가정한다. Flutter 설치 먼저 Curosr AI에 접속한다. Command + Shift + X를 선택한다. 검색창에서 flutter 검색 후, Install 버튼을 클릭한다. 설치 확인 Command + Shift + P 선택 후, Flutter: Run Flutter Doctor 선택한다. Flutter 프로젝트 실시 Command + Shift + P 선택 후, New Project 선택한다. Application을 선택한다. 정상적으로 실행이 되면 다음과 같은 소스코드 파일이 나타날 것임</description>
    </item>
    
    <item>
      <title>HuggingFace Login on Google Colab</title>
      <link>https://dschloe.github.io/settings/2025/01/googlecolab_huggingface_login/</link>
      <pubDate>Fri, 03 Jan 2025 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2025/01/googlecolab_huggingface_login/</guid>
      <description>Google Colab에서 허깅페이스 로그인 개요 Google Colab에서 허깅페이스 로그인 하는 방법 기재 허깅페이스 회원가입은 이미 되어 있는 것으로 가정 허깅페이스 토큰값 가져오기 프로필 클릭 &amp;gt; Settings &amp;gt; Access Tokens &amp;gt; Create New Token 선택 Token name에 이름 입력 후, 스크롤 하단에서 Create Token 버튼 선택 토큰값 획득을 한다. Google Colab에서 허깅페이스 로그인 다음 코드 입력 후 실행 from huggingface_hub import notebook_login notebook_login() </description>
    </item>
    
    <item>
      <title>Android Studio 설치, MacOS</title>
      <link>https://dschloe.github.io/settings/2024/12/android_studio_macos/</link>
      <pubDate>Mon, 30 Dec 2024 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/12/android_studio_macos/</guid>
      <description>개요 Android Studio를 MacOS에서 설치를 하도록 한다. 사이트 접속 사이트 : https://developer.android.com/studio 화면 중간에 Download 버튼을 클릭 후 다운로드를 진행한다.
아래 화면에서 본인 환경에 맞는 Mac을 설치한다. 필자는 Mac with Apple Chip 을 선택했다.
아래와 같은 화면에서 Android Studio를 Applications 폴더로 이동 시킨다.
Android Studio 설정 Android Studio 프로그램을 실행하면 아래와 같이 설정 부분이 나온다. Next 버튼을 누른다. 아래 화면에서 Next 버튼을 누른다. 아래 화면에서 Next 버튼을 누른다. Accept 버튼을 클릭하고 Finish 버튼을 클릭한다.</description>
    </item>
    
    <item>
      <title>Flutter 플러터 설치, MacOS M1</title>
      <link>https://dschloe.github.io/settings/2024/12/flutter_install_macos/</link>
      <pubDate>Sun, 29 Dec 2024 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/12/flutter_install_macos/</guid>
      <description>개요 MacOS에서 Flutter를 설치한다. 사이트 접속 사이트 : Flutter https://flutter.dev/ 오른쪽 상단의 Get Started 를 선택한다. MacOS를 선택한다. 필자는 Android App 개발을 하고 싶기 때문에, Android를 선택하였다. 추가로 다음 명령어를 실행한다. sudo softwareupdate --install-rosetta --agree-to-license 스크롤을 내리면 Download and install 를 선택한다. 그리고 본인의 OS에 맞는 것을 선택한다. 필자는 M1이기 때문에 Apple Silicon 을 선택하였다. 압축받은 폴더는 압축을 푼다. 경로설정 폴더 구성은 Macintosh HD &amp;gt; 사용자 &amp;gt; 사용자명 &amp;gt; development &amp;gt; flutter로 될 것이다.</description>
    </item>
    
    <item>
      <title>Nasdaq Data Link를 활용한 데이터 수집</title>
      <link>https://dschloe.github.io/settings/2024/12/nasdaq_get_data_sample/</link>
      <pubDate>Mon, 16 Dec 2024 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/12/nasdaq_get_data_sample/</guid>
      <description>개요 Nasdaq Data Link은 금융 및 경제 데이터를 제공하는 플랫폼으로, 특히 투자자, 연구자, 그리고 데이터 애널리스트들에게 유용 기존 quandl에서 2018년에 Nasdaq에 인수되었으며, 주식, 채권, 선물, 외환, 경제 지표 등 다양한 데이터를 제공 그러나 Free 데이터에서 유의미한 데이터를 찾기에는 부족함을 느낌 Nasdaq Data Link의 주요 기능 데이터 제공 금융 시장 데이터 (주식, 상품, 금리 등) 경제 데이터 (GDP, 실업률, 소비자 물가 지수 등) 대체 데이터 (소셜미디어 트렌드, 위성 이미지 분석, 물류 데이터 등) API 기반 접근 Python, R, Excel 등 다양한 도구에서 API를 사용해 데이터를 불러올 수 있음.</description>
    </item>
    
    <item>
      <title>Kaggle ML Submission 클래스 만들기</title>
      <link>https://dschloe.github.io/settings/2024/12/kaggle_submission_class_sample/</link>
      <pubDate>Sun, 15 Dec 2024 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/12/kaggle_submission_class_sample/</guid>
      <description>개요 취업 준비생 들에게 필요한 캐글 연습 코드 클래스로 구현함 학습에서 제출까지 자동화하는 것에 목적을 둠 클래스에 대한 기본적인 이해가 있다는 전제하에 작성 전체 코드는 다음과 같다. import numpy as np import pandas as pd import shap import matplotlib.pyplot as plt # 데이터 처리 및 모델링 라이브러리 from sklearn.model_selection import train_test_split, cross_val_score from sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder from sklearn.impute import SimpleImputer from sklearn.metrics import ( mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error ) from sklearn.</description>
    </item>
    
    <item>
      <title>Windows Microsoft C&#43;&#43; Build Tools 설정</title>
      <link>https://dschloe.github.io/settings/2024/12/windows_ms_c/</link>
      <pubDate>Tue, 10 Dec 2024 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/12/windows_ms_c/</guid>
      <description>개요 Python 라이브러리 설치 시, 가끔 C++ 라이브러리 설치가 필요할 수 있다. 위와 같이 에러가 발생할 때 C++ 라이브러리를 설치를 한다. 설치방법 사이트 : https://visualstudio.microsoft.com/ko/visual-cpp-build-tools/ Build Tools 다운로드 버튼 클릭 후 관리자 권한으로 실행 아래와 같이 C++를 사용한 데스크톱 개발 선택 후, 설치 설치하는 데 다소 시간이 필요함 설치가 완료되면 재부팅을 한다. 파이썬 라이브러리 다시 설치 중간에 보면 cp312가 보이는데, C++을 활용해서 설치가 되었다는 것을 의미한다. </description>
    </item>
    
    <item>
      <title>Cursor AI 소개 및 설치</title>
      <link>https://dschloe.github.io/settings/2024/11/cursor_ai_installation/</link>
      <pubDate>Sun, 24 Nov 2024 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/11/cursor_ai_installation/</guid>
      <description>웹사이트 https://www.cursor.com/ 회원가입 Settings 가격정책(Pricing) 프로그램 설치 (Windows) 기존에 Visual Studio Code가 설치가 되어 있어야 한다. 실행 또는 (관리자 권한)으로 실행 Continue 버튼 선택 Use Extensions 선택 Data Preferences는 독자 취향에 맞게 선택한다. 필자는 Help Improve Cursor를 선택한다. Login 개인 계정 확인 후, Yes, Log in 버튼 클릭 Visual Studio Code 확인 이제 Visual Studio Code에 Cursor AI가 업데이트가 되었는지 확인해본다. 그러기 위해서는, 먼저 Github에서 새로운 Repository를 하나 생성한다. 필자는 cursor_ai_project로 명명했다.</description>
    </item>
    
    <item>
      <title>Crontab으로 Git Commit Automation with sh 파일 on M1</title>
      <link>https://dschloe.github.io/settings/2024/09/m1_crontab_git_commit_automation/</link>
      <pubDate>Sat, 28 Sep 2024 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/09/m1_crontab_git_commit_automation/</guid>
      <description>개요 Mac Crontab으로 SH 파일을 실행하도록 한다. SH 파일 작성 주요 내용은 아래와 같이 작성한다. (파일명 : deploy.sh) #!/bin/bash echo &amp;#34;Git Push Starting...&amp;#34; cd /Users/evan/Desktop/alphaco_test # Check out repo git add -A git commit -m &amp;#34;Automated commit on $(date &amp;#39;+%Y-%m-%d %H:%M:%S&amp;#39;)&amp;#34; git push 수동 업로드 수동으로 업로드 하기 위해 파일 권한을 열어준다. 777은 소유자, 그룹, 다른 모든 사용자에게 읽기, 쓰기, 실행 권한 부여하는 명령어를 말한다. chmod 777 deploy.sh 실행 해당 파일이 있는 경로에서 deploy.</description>
    </item>
    
    <item>
      <title>Deep Learning Loss Function</title>
      <link>https://dschloe.github.io/mlops/2024/08/deeplearning_lossfunction/</link>
      <pubDate>Fri, 16 Aug 2024 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/2024/08/deeplearning_lossfunction/</guid>
      <description>딥러닝 손실 함수 (Loss Function) 개요 딥러닝에서 손실 함수는 모델의 예측과 실제 값 사이의 차이를 측정하는 중요한 요소. 다양한 종류의 손실 함수가 있으며, 문제의 특성에 따라 적절한 함수를 선택해야 함.
주요 손실 함수 설명 평균 제곱 오차 (Mean Squared Error, MSE) 유형 : 회귀
공식 :
$$ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 $$
설명:
$y_i$ : 실제 값 $\hat{y}_i$ : 예측 값 $n$ : 데이터 포인트의 수 사용 용도</description>
    </item>
    
    <item>
      <title>Docker-Compose와 Dockerfile을 활용한 Flask-MySQL 연동 예제</title>
      <link>https://dschloe.github.io/mlops/2024/07/docker_compose_dockerfile_flask_mysql/</link>
      <pubDate>Tue, 02 Jul 2024 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/2024/07/docker_compose_dockerfile_flask_mysql/</guid>
      <description>개요 Docker-Compose와 Dockerfile의 주요 기능을 이해한다. 각 파일의 위치와 주요 기능을 이해한다. 전체 프로젝트 파일 디렉터리 본 프로젝트의 전체 코드는 다음과 같다. 실제 코드 작성을 해야하는 곳은 다음과 같다. app.py requirements.txt init.sql docker-compose.yml Dockerfile docker_kubernetes_flask/ ├── app/ │ ├── __init__.py │ ├── app.py │ └── requirements.txt ├── db/ │ ├── init.sql │ └── data/ (This will be created by Docker) ├── docker-compose.yml └── Dockerfile 사전준비 사전에 Docker는 Desktop 설치가 되어 있다고 가정한다.</description>
    </item>
    
    <item>
      <title>Streamlit on Google Colab</title>
      <link>https://dschloe.github.io/python/2024/06/streamlit_on_google_colab/</link>
      <pubDate>Thu, 20 Jun 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/06/streamlit_on_google_colab/</guid>
      <description>개요 개발환경설정이 어려운 환경에서 Google Colab 상에서 Streamlit 설치 및 실행을 익히고자 한다. 주로 강의 목적으로 사용하기를 바란다. Streamlit 라이브러리 설치 아래 코드를 활용하여 streamlit 라이브러리 설치 !pip install -q streamlit Streamlit 코드 작성 샘플 아래와 같이 코드를 작성 후, app.py로 내보내기를 한다. magics from Jupyter : [Jupyter’s magics page](https://nbviewer.org/github/ipython/ipython/blob/1.x/examples/notebooks/Cell Magics.ipynb) %%writefile app.py import streamlit as st import plotly.graph_objs as go from plotly.subplots import make_subplots import seaborn as sns @st.cache_data def load_data(): df = sns.</description>
    </item>
    
    <item>
      <title>Oracle VM Box 양방향 복사 붙이기</title>
      <link>https://dschloe.github.io/settings/2024/05/oracle_vm_box_ubuntu_bidirect_copy/</link>
      <pubDate>Thu, 23 May 2024 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/05/oracle_vm_box_ubuntu_bidirect_copy/</guid>
      <description>개요 VirtualBox를 통해 복사 붙이기 등을 하려고 함 사전작업 1 - 우분투 패키지 업그레이드 터미널을 열고 아래 코드를 순차적으로 입력 sudo apt update 업그레이 명령어 입력 sudo apt upgrade 사전작업 2 - 게스트 확장 설치 우선 주요 라이브러리 설치 진행 sudo apt install gcc make perl 게스트 확장 CD 이미지 삽입 메뉴 클릭 해당 디렉터리를 열고, 마우스 우클릭 &amp;gt; 터미널에서 열기 실행 ls 명령어 실행 VBoxLinuxAdditions.run 파일이 있는지 확인 ls 파일 있는 지 확인하였다면 해당 파일 실행 sudo apt install bzip2 sudo .</description>
    </item>
    
    <item>
      <title>Ubuntu install on M1</title>
      <link>https://dschloe.github.io/settings/2024/05/ubuntu_install_m1/</link>
      <pubDate>Tue, 21 May 2024 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/05/ubuntu_install_m1/</guid>
      <description>개요 M1에서 Ubuntu를 설치하는 방법에 대해 기술한다. Ubuntu 24.04 LTS 다운로드 Ubuntu Download를 진행한다. 다운로드 받을 시, arm으로 다운로드 받아야 한다. 다른 아키텍처로 다운로드 받을 시 리눅스가 활성화가 되지 않는다. 사이트 : https://ubuntu.com/download/server/arm 최신버전의 경우 잘 되지 않을수도 있다. 따라서 22.04.04 버전으로 변경하였다. 사이트 : https://cdimage.ubuntu.com/releases/22.04.4/release/ UTM 다운로드 사이트 : https://mac.getutm.app/ UTM 가상머신 생성 UTM을 실행하면 아래와 같은 화면이 나온다. Create a New Virtual Machine을 선택한다. 아래화면에서 Virtualize를 선택한다. 아래화면에서 Linux를 선택한다.</description>
    </item>
    
    <item>
      <title>gcloud installation on Mac, SSH Connection with VSCode</title>
      <link>https://dschloe.github.io/gcp/2024/04/gcloud_mac_vscode/</link>
      <pubDate>Mon, 22 Apr 2024 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2024/04/gcloud_mac_vscode/</guid>
      <description>개요 gcloud를 Mac에서 설치를 하도록 한다. 참조 : https://cloud.google.com/sdk/docs/install-sdk?hl=ko 설치파일 다운로드 각 사용자 버전에 맞는 설치 파일을 다운로드 받는다. 필자는 M1 silicon 버전을 사용하기로 하였다. Desktop &amp;gt; gcloud_install 내부에 해당 파일을 다운로드 받았다. 압축을 풀면 아래와 같이 google-cloud-sdk 폴더 안애 install.sh 파일이 있다. 설치파일 실행 해당 폴더에 있는 파일에 접속해서 install.sh 파일을 실행한다. $ {your_location}/google-cloud-sdk/install.sh Welcome to the Google Cloud CLI! To help improve the quality of this product, we collect anonymized usage data and anonymized stacktraces when crashes are encountered; additional information is available at &amp;lt;https://cloud.</description>
    </item>
    
    <item>
      <title>gcloud Installation on Windows 11 - New Configuration</title>
      <link>https://dschloe.github.io/gcp/2024/04/gcloud_windows11_vscode/</link>
      <pubDate>Sun, 21 Apr 2024 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2024/04/gcloud_windows11_vscode/</guid>
      <description>개요 신규로 설치를 하는 것은 아래 링크를 참조한다. 링크 : https://dschloe.github.io/gcp/2023/09/gcloud_installation_windows11/ 기존에 설치 후, 재설치 할 때의 과정을 리뷰 한다. 재설치 재설치의 마지막 화면은 다음과 같다. Pick configuration to use, Section에서 2번을 선택한다. 이후 CMD 화면이 팝업화가 된다. Welcome to the Google Cloud CLI! Run &amp;#34;gcloud -h&amp;#34; to get the list of available commands. --- Welcome! This command will take you through the configuration of gcloud. Settings from your current configuration [default] are: accessibility: screen_reader: &amp;#39;True&amp;#39; compute: region: asia-northeast3 zone: asia-northeast3-a core: account: your_existing@gmail.</description>
    </item>
    
    <item>
      <title>Github Actions with GCE, SSH-Key 값 등록</title>
      <link>https://dschloe.github.io/gcp/2024/04/gce_githubactions_sshkey/</link>
      <pubDate>Fri, 19 Apr 2024 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2024/04/gce_githubactions_sshkey/</guid>
      <description>개요 Github Actions 강의 중, 애매한 부분을 정리하였다. Github Actions에 대한 전체 코드는 여기에서 다루지는 않는다. SSH-Key 값 설정 GCE에서 Github와 연동을 위해서는 Key값을 생성해야 한다. 본인의 구글클라우드 이메일을 추가하여 아래와 같이 코드를 실행한다. GCP의 ID와 Github의 이메일 주소가 다른 분들이 있다. 이럴 경우 문제가 발생할 수 있다. 주의 : Github 이메일 주소가 아님 $ ssh-keygen -t rsa -b 4096 -C &amp;#34;your@gmail.com&amp;#34; Github SSH Key값 생성 ssh의 public 키값을 복사한다. $ cat .</description>
    </item>
    
    <item>
      <title>django-web on GCE</title>
      <link>https://dschloe.github.io/python/2024/04/djangoweb_on_gce/</link>
      <pubDate>Thu, 18 Apr 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/04/djangoweb_on_gce/</guid>
      <description>개요 django-web을 GCE에 설치 및 배포를 간단하게 진행하도록 한다. 사전준비 Google Cloud Platform 회원가입은 미리 진행했고, GCE 인스턴스를 생성할 줄 아는 상태임을 전제로 한다. Miniconda 설치가 끝난 상황임을 가정한다. Miniconda Linux 설치 : https://docs.anaconda.com/free/miniconda/ Miniconda 설치 mkdir -p ~/miniconda3 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3 rm -rf ~/miniconda3/miniconda.sh 설치 후, 새로 설치한 미니콘다를 초기화합니다. 다음 명령은 bash 및 zsh 셸을 초기화 ~/miniconda3/bin/conda init bash ~/miniconda3/bin/conda init zsh django on GCE GCE Shell에서 django를 설치한다.</description>
    </item>
    
    <item>
      <title>Spark Code 실행 예제</title>
      <link>https://dschloe.github.io/python/2024/04/spark_code_tutorial/</link>
      <pubDate>Thu, 11 Apr 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/04/spark_code_tutorial/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 개요 현재 러닝 스파크 교재를 배우고 있다. 해당 교재는 주로 00.py에서 실행하는 방법으로 안내하고 있지만, Google Colab에서 어떻게 변환하는지 확인해보고자 한다. Spark 설정 Spark 설치 버전은 아래 링크에서 확인한다. 주소 : https://spark.apache.org/downloads.html Download 버튼을 클릭하면 아래와 같은 화면이 나온다. 주소를 복사한다. https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz Java 설치 아래 코드를 실행한다. !apt-get install openjdk-8-jdk-headless Spark 설치 아래 코드를 실행한다. !wget -q https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz !tar -zxf spark-3.</description>
    </item>
    
    <item>
      <title>Pandas DataFrame to MySQL Database using iris Data</title>
      <link>https://dschloe.github.io/sql/2024/04/pandas_2_mysql/</link>
      <pubDate>Fri, 05 Apr 2024 16:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2024/04/pandas_2_mysql/</guid>
      <description>개요 이전 강의에 이어서 진행한다. (MySQL Select Clause via Python) 임의의 Pandas 데이터 프레임에서 MySQL DB로 추가하는 코드를 작성한다. 주요 라이브러리 설치 아래와 같이 주요 라이브러리를 설치한다. MySQL과 관련된 주요 Python 라이브러리를 설치한다. pip install mysql-connector mysql-connector-python pymysql SQLAlchemy seaborn pandas 코드 작성(mysql-connector) 아래와 같이 코드를 작성한다. # 파일명 : db.py import mysql.connector import pandas as pd import seaborn as sns mydb = mysql.connector.connect( host = &amp;#34;localhost&amp;#34;, user = &amp;#34;root&amp;#34;, passwd = &amp;#34;evan&amp;#34;, database = &amp;#34;muldb&amp;#34; ) print(mydb) iris_df = sns.</description>
    </item>
    
    <item>
      <title>MySQL Select Clause via Python</title>
      <link>https://dschloe.github.io/sql/2024/04/mysql_select_via_python/</link>
      <pubDate>Thu, 04 Apr 2024 20:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2024/04/mysql_select_via_python/</guid>
      <description>개요 이전 강의에서 출발한다. MySQL Table Creation and Insert Data via Python 데이터 조회 다음 코드를 작성한다. import mysql.connector mydb = mysql.connector.connect( host = &amp;#34;localhost&amp;#34;, user = &amp;#34;root&amp;#34;, passwd = &amp;#34;evan&amp;#34;, database = &amp;#34;mulcampdb&amp;#34; ) print(mydb) my_cursor = mydb.cursor() query = &amp;#34;&amp;#34;&amp;#34; SELECT * FROM users; &amp;#34;&amp;#34;&amp;#34; my_cursor.execute(query) result = my_cursor.fetchall() for row in result: print(row) print(&amp;#34;완료&amp;#34;) 파일을 실행한다. $ python database.py &amp;lt;mysql.connector.connection_cext.CMySQLConnection object at 0x000001FE5A985F10&amp;gt; (&amp;#39;Evan&amp;#39;, &amp;#39;Evan@gmail.com&amp;#39;, 30, 1) (&amp;#39;Evan&amp;#39;, &amp;#39;Evan@gmail.</description>
    </item>
    
    <item>
      <title>MySQL Table Creation and Insert Data via Python</title>
      <link>https://dschloe.github.io/sql/2024/04/mysql_data_insert_via_python/</link>
      <pubDate>Thu, 04 Apr 2024 18:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2024/04/mysql_data_insert_via_python/</guid>
      <description>개요 이전 강의에서 출발한다. Connect To Database in Python 테이블 생성 아래 코드를 작성하면 테이블이 생성된다. import mysql.connector mydb = mysql.connector.connect( host = &amp;#34;localhost&amp;#34;, user = &amp;#34;root&amp;#34;, passwd = &amp;#34;evan&amp;#34;, database = &amp;#34;mulcampdb&amp;#34; ) print(mydb) my_cursor = mydb.cursor() query = &amp;#34;&amp;#34;&amp;#34; CREATE TABLE users ( name VARCHAR(255) , email VARCHAR(255) , age INTEGER(10) , user_id INTEGER AUTO_INCREMENT PRIMARY KEY ); &amp;#34;&amp;#34;&amp;#34; my_cursor.execute(query) my_cursor.execute(&amp;#34;SHOW TABLES;&amp;#34;) for table in my_cursor: print(table[0]) 파일을 실행한다.</description>
    </item>
    
    <item>
      <title>Connect To Database in Python</title>
      <link>https://dschloe.github.io/sql/2024/04/conn_db_2_python/</link>
      <pubDate>Thu, 04 Apr 2024 10:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2024/04/conn_db_2_python/</guid>
      <description>개요 Python과 MySQL을 연동하도록 한다. 프로젝트 폴더에 가상환경이 설치가 되어 있는 것으로 가정한다. MySQL은 기 설치가 되어 있는 것으로 가정한다. 라이브러리 설치 Python과 MySQL을 연동해주는 라이브러리 종류는 다양하게 있다. $ pip install mysql-connector mysql-connector-python 파일 작성 간단하게 파일을 작성한다. import mysql.connector mydb = mysql.connector.connect( host = &amp;#34;localhost&amp;#34;, user = &amp;#34;root&amp;#34;, passwd = &amp;#34;evan&amp;#34; ) print(mydb) 파일을 실행한다. $ python database.py &amp;lt;mysql.connector.connection_cext.CMySQLConnection object at 0x000002BF4E606090&amp;gt; (venv) Python 코드 활용하여 DB 생성 이번에는 코드를 활용하여 Schema를 생성한다.</description>
    </item>
    
    <item>
      <title>MySQL 삭제, 재설치 가이드 on M1</title>
      <link>https://dschloe.github.io/sql/2024/04/mysql_delete_reinstall/</link>
      <pubDate>Tue, 02 Apr 2024 10:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2024/04/mysql_delete_reinstall/</guid>
      <description>개요 M1에서 MySQL을 설치 하고 Workbench에 접속하는 과정을 설명한다. 데이터 로드 시, ASCII 에러 과정 해결하는 방법도 살펴본다. (임시방편) 사전학습 brew 명령어를 알고 있는 분에 한해 작성을 하였다. 주의 아래 코드 복사할 시, $ 는 제외 후 복사한다. MySQL 실행 확인 후 프로세스 Kill 먼저 MySQL이 실행중인지를 확인한다. $ brew services list Name Status User File mysql started evan ~/Library/LaunchAgents/homebrew.mxcl.mysql.plist 서비스를 강제 종료한다. $ brew services stop mysql Stopping `mysql`... (might take a while) ==&amp;gt; Successfully stopped `mysql` (label: homebrew.</description>
    </item>
    
    <item>
      <title>Github Actions Hello World From Python Script</title>
      <link>https://dschloe.github.io/python/2024/03/github_actions_python/</link>
      <pubDate>Wed, 13 Mar 2024 03:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/03/github_actions_python/</guid>
      <description>개요 Python Script를 활용하여 Hell World를 출력한다. 강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 이전 게시글 링크 확인 : Github Actions Hello World main.py 작성 간단하게 아래 코드를 작성한다. 코드 작성은 Github에서도 가능하다. import sys print(sys.version) print(&amp;#34;Hello, World&amp;#34;) Add file &amp;gt; Create new file 버튼을 클릭한다. Python-hello.yml 파일 변경 기존 코드에서 다음 코드를 추가한다. # This is a basic workflow to help you get started with Actions name: Python-CI .</description>
    </item>
    
    <item>
      <title>Github Actions Hello World</title>
      <link>https://dschloe.github.io/python/2024/03/github_actions_hello_world/</link>
      <pubDate>Wed, 13 Mar 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/03/github_actions_hello_world/</guid>
      <description>개요 Github Actions 에서 Hello World를 출력하도록 한다. 강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 사전준비 Github에 적당한 Repo를 준비한다. 메뉴선택 아래 그림에서 Actions 메뉴를 선택한다. 아래 그림에서 set up a workflow yourself 선택 YAML 파일 수정 .github/workflows/main.yaml 파일 선택 후 수정 소스코드는 다음과 같이 지정한다. # This is a basic workflow to help you get started with Actions name: CI # Controls when the workflow will run on: # Triggers the workflow on push or pull request events but only for the &amp;#34;main&amp;#34; branch push: branches: [ &amp;#34;main&amp;#34; ] pull_request: branches: [ &amp;#34;main&amp;#34; ] # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # A workflow run is made up of one or more jobs that can run sequentially or in parallel jobs: # This workflow contains a single job called &amp;#34;build&amp;#34; build: # The type of runner that the job will run on runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v3 # Runs a single command using the runners shell - name: Run a one-line script run: echo Hello, world!</description>
    </item>
    
    <item>
      <title>Streamlit ML Multiclass Classification Model Prediction Sample (feat. Pipeline)</title>
      <link>https://dschloe.github.io/python/2024/03/streamlit_model_prediction_obesity/</link>
      <pubDate>Wed, 06 Mar 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/03/streamlit_model_prediction_obesity/</guid>
      <description>개요 Kaggle 데이터셋을 활용하여 Streamlit ML Multiclass Classification Model을 배포한다. 각 코드에 대한 자세한 설명은 여기에서는 생략한다. 데이터 수집 이번에 활용하는 캐글 데이터 수집은 아래 대회에서 train 데이터만 가져왔다. Multi-Class Prediction of Obesity Risk : https://www.kaggle.com/competitions/playground-series-s4e2 Dataset Description은 아래에서 확인하도록 한다. 링크 : https://www.kaggle.com/competitions/playground-series-s4e2/data train.csv 파일만 다운로드 받았다. 모델 개발 다음 코드는 모델을 개발하는 코드이다. 주어진 데이터셋에서 종속변수 NObeyesdad을 예측하는 모델을 구성했다. 파일명 : model.py import pandas as pd from sklearn.</description>
    </item>
    
    <item>
      <title>Streamlit ML Model Prediction Sample (feat. Pipeline)</title>
      <link>https://dschloe.github.io/python/2024/03/streamlit_model_prediction_tip/</link>
      <pubDate>Tue, 05 Mar 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/03/streamlit_model_prediction_tip/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 개요 tips 데이터셋을 활용하여 Streamlit ML Model을 배포한다. 각 코드에 대한 자세한 설명은 여기에서는 생략한다. 모델 개발 다음 코드는 모델을 개발하는 코드이다. 주어진 데이터셋에서 tip을 예측하는 모델을 구성했다. 파일명 : model.py import streamlit as st import pandas as pd import seaborn as sns from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression from sklearn.compose import ColumnTransformer from sklearn.pipeline import Pipeline from sklearn.</description>
    </item>
    
    <item>
      <title>openAI API, Text &amp; Image 생성 예제</title>
      <link>https://dschloe.github.io/python/2024/03/openai_api_text_image_generation/</link>
      <pubDate>Fri, 01 Mar 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/03/openai_api_text_image_generation/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 소스 참조 후루카와 히데카즈 저/트랜스메이트 역. (2023). GPT-4, ChatGPT, 라마인덱스, 랭체인을 활용한 인공지능 프로그래밍 한권으로 끝내는 OpenAI API 기반 LLM 애플리케이션 구축. 위키북스, 판매처 : https://www.yes24.com/Product/Goods/122533123 라이브러리 설치 openai 패키지를 설치한다. !pip install openai Collecting openai Obtaining dependency information for openai from https://files.pythonhosted.org/packages/26/a1/75474477af2a1dae3a25f80b72bbaf20e8296191ece7fff2f67984206f33/openai-1.12.0-py3-none-any.whl.metadata Downloading openai-1.12.0-py3-none-any.whl.metadata (18 kB) . . . [notice] A new release of pip is available: 23.2.1 -&amp;gt; 24.</description>
    </item>
    
    <item>
      <title>st-pages 라이브러리 소개</title>
      <link>https://dschloe.github.io/python/2024/02/st_pages_library/</link>
      <pubDate>Wed, 28 Feb 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/02/st_pages_library/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 개요 Streamlit 생태계에 기반한 Components를 살펴본다. st-pages 라이브러리를 확인한다. Components Components는 Streamlit Community와 Creators가 직접 개발한 Streamlit 관련 라이브러리를 말한다. 참고 : https://streamlit.io/components 여기에는 다양한 라이브러리들이 존재한다. 활용법 주의 이러한 라이브러리들을 활용할 때는 Github의 최근 개발 이력을 살펴볼 필요가 있다. 예: spacy-streamlit, https://github.com/explosion/spacy-streamlit 확인해야 하는 것은 최근 Releases 날짜다. Release 날짜가 최근 날짜에서 멀면 멀수록 관리가 안되고 있다는 것이며, 이 부분은 향후 프로젝트 유지보수할 때 어려움을 겪을 수도 있다.</description>
    </item>
    
    <item>
      <title>OpenAI API 인증키 발급</title>
      <link>https://dschloe.github.io/python/2024/02/openai_api_key/</link>
      <pubDate>Tue, 27 Feb 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/02/openai_api_key/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 개요 OpenAI API 인증키 발급 OpenAI 회원가입을 이미 한 것으로 전제 인증키 발급 다음 사이트에서 로그인을 한다. https://openai.com/blog/openai-api API를 선택한다. 왼쪽 메뉴에서 API Keys를 선택한다. API Key 획득을 위해 Create New Secret Key 버튼을 클릭한다. 인증키 확인 후, 별도로 저장해야 함 </description>
    </item>
    
    <item>
      <title>creating multipages in streamlit web using official docs</title>
      <link>https://dschloe.github.io/python/2024/02/streamlit_multipages_01/</link>
      <pubDate>Sun, 25 Feb 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/02/streamlit_multipages_01/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 개요 streamli을 활용한 멀티페이지 개념 및 구현에 대한 내용을 다룬다. 공식문서 참고 : Create a multipage app : https://docs.streamlit.io/get-started/tutorials/create-a-multipage-app Multipage apps : https://docs.streamlit.io/library/advanced-features/multipage-apps Streamlit에서 multipage란 무엇인가? 앱의 크기가 커질수록 다중 페이지 구성은 관리와 탐색의 용이성을 제공함. Streamlit은 이를 쉽게 가능하게 하며, 클릭 한 번으로 해당 페이지에 빠르게 이동할 수 있다. 폴더 및 파일 구조 Home.py 파일을 만든 후에는 엔트리포인트 파일과 관련된 pages/about.</description>
    </item>
    
    <item>
      <title>취업준비생을 위한 Github 포트폴리오 정리</title>
      <link>https://dschloe.github.io/ds-projects/2024/02/github_portfolio/</link>
      <pubDate>Mon, 05 Feb 2024 00:01:28 +0900</pubDate>
      
      <guid>https://dschloe.github.io/ds-projects/2024/02/github_portfolio/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 개요 Github에서 포트폴리오 정리하는 방법에 대해 기술합니다. 취업준비생들의 취업을 진심으로 응원합니다. 취업준비생들에게 개발이란 Github에 배포를 하겠다는 뜻은 앞으로 계속적으로 발전 시키겠다는 것을 의미합니다. 그런데, 개발은 혼자 할 수 없기 때문에 다른 사람들의 참여를 독려하겠다는 것과 같습니다. 가장 좋은 시나리오는 간단하게 배포를 진행하고 프로젝트의 전반적인 취지를 설명한 후 함께 발전시켜 나갈 동료를 구하는 것입니다. 이러한 기본적인 관점에서 Github 포트폴리오를 구성하는 것이 좋습니다.</description>
    </item>
    
    <item>
      <title>출간 기념, Streamlit으로 프로젝트 한방에 끝내기 with 파이썬 개정판 (2024, Sara &amp; Evan)</title>
      <link>https://dschloe.github.io/ds-projects/2024/01/book_intro/</link>
      <pubDate>Sun, 04 Feb 2024 00:01:28 +0900</pubDate>
      
      <guid>https://dschloe.github.io/ds-projects/2024/01/book_intro/</guid>
      <description>개정판 책을 출간하였습니다. Streamlit이란 Streamlit은 데이터 분석가가 간단한 코드 몇줄로 빠르게 웹앱을 만들어 줄 수 있는 Python 라이브러리입니다. 웹사이트 : https://streamlit.io/ 누가 읽어야 할까요? 데이터 분석가 : 웹개발은 모르지만 대시보드를 만들어야 하는 분 국비교육 수강중인 비전공자 : Java 웹개발로 머신러닝 플랫폼을 만들어야 하는 분 개별적인 포트폴리오가 필요한 취업준비생 : ML/DL 알고리즘 익히는 것도 어려운데, 웹개발은 언제 배우죠? 데모 페이지 기초문법 포함 2달이면 충분히 아래 데모 페이지와 같이 만들 수 있습니다.</description>
    </item>
    
    <item>
      <title>django tutorial - pyburger 3</title>
      <link>https://dschloe.github.io/python/2024/01/django_pyburger_3/</link>
      <pubDate>Wed, 24 Jan 2024 04:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/01/django_pyburger_3/</guid>
      <description>공지 멀티캠퍼스 수업 보조자료로 활용하기 위해 아래 교재 내용을 발췌하였음을 알립니다. 판매처 : https://product.kyobobook.co.kr/detail/S000201056504 Github에서 프로젝트 내려받기 다음 경로에서 프로젝트를 내려 받는다. 사이트 : https://github.com/dschloe/pyburger Download Zip을 선택하여 프로젝트를 내려 받는다. 다음 명령어를 실행하여 Local의 적당한 곳에서 다운로드 받는다. 폴더 수정 .DS_Store 파일은 삭제한다 폴더명은 pyburger로 변경한다. VS Code로 폴더 열기 아래와 같이 VS Code로 pyburger 폴더를 연다. 프로젝트 설정 가상환경을 설정하고 django를 설치한다. $ virtualenv venv $ source venv/Scripts/activate (venv) $ pip install &amp;#39;django&amp;lt;5&amp;#39; 첫번째 확인사항 runserver를 실행하여 정상적으로 작동하는지 확인한다.</description>
    </item>
    
    <item>
      <title>django tutorial - pyburger 2</title>
      <link>https://dschloe.github.io/python/2024/01/django_pyburger_2/</link>
      <pubDate>Wed, 24 Jan 2024 03:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/01/django_pyburger_2/</guid>
      <description>공지 멀티캠퍼스 수업 보조자료로 활용하기 위해 아래 교재 내용을 발췌하였음을 알립니다. 판매처 : https://product.kyobobook.co.kr/detail/S000201056504 별도의 app 추가 application을 생성하는 명령어를 활용하여 app을 생성한다. python manage.py startapp burgers 트리 구조는 다음과 같다. $ tree -L 2 . |-- burgers | |-- __init__.py | |-- admin.py | |-- apps.py | |-- migrations | |-- models.py | |-- tests.py | `-- views.py |-- config | |-- __init__.py | |-- __pycache__ | |-- asgi.py | |-- settings.</description>
    </item>
    
    <item>
      <title>django tutorial - pyburger 1</title>
      <link>https://dschloe.github.io/python/2024/01/django_pyburger_1/</link>
      <pubDate>Wed, 24 Jan 2024 02:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/01/django_pyburger_1/</guid>
      <description>Django Pyburger - 1, 맛보기 공지 멀티캠퍼스 수업 보조자료로 활용하기 위해 아래 교재 내용을 발췌하였음을 알립니다. 판매처 : https://product.kyobobook.co.kr/detail/S000201056504 Django 설치 터미널에서 django를 설치한다. pip install &amp;#39;django&amp;lt;5&amp;#39; Django 버전 확인 터미널에서 Django의 버전을 확인한다. django-admin --version 4.2.9 Django 프로젝트 생성 다음 명령어를 실행하여 django 프로젝트를 생성한다. djang-admin은 터미널에서 실행할 수 있는 프로그램이며, django 프로젝트를 관리하는 여러 기능들을 가지고 있음 startproject는 django 프로젝트의 기반 구조를 만드는 기능 django-admin startproject config . 생성된 파일 목록을 확인한다.</description>
    </item>
    
    <item>
      <title>SQLitebroswer 설치 (M1, Mac)</title>
      <link>https://dschloe.github.io/settings/2024/01/sqlitebroswer_install_m1_mac/</link>
      <pubDate>Wed, 24 Jan 2024 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/01/sqlitebroswer_install_m1_mac/</guid>
      <description>SQLitebroswer 설치 (M1, Mac) 개요 SQLitebroswer 설치를 진행해본다. 설치 주소 : https://sqlitebrowser.org/ Download 버튼을 클릭한다. 자신의 OS에 맞는 버전을 선택해 다운로드 후 설치 필자는 Apple Silicon 버전을 선택했다. 아래 그림과 같이 추가하면 된다. </description>
    </item>
    
    <item>
      <title>SQLitebroswer 설치 (Windows 11)</title>
      <link>https://dschloe.github.io/settings/2024/01/sqlitebroswer_install_windows/</link>
      <pubDate>Wed, 24 Jan 2024 00:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2024/01/sqlitebroswer_install_windows/</guid>
      <description>개요 SQLitebroswer 설치를 진행해본다. 설치 주소 : https://sqlitebrowser.org/ Download 버튼을 클릭한다. 자신의 OS에 맞는 버전을 선택해 다운로드 후 설치 필자는 Standard installer for 64-bit Windows 다운로드 받았다. 설치 프로그램을 실행한 후, 아래와 같이 순차적으로 실행한다. 끝.</description>
    </item>
    
    <item>
      <title>kaggle 한글폰트 적용</title>
      <link>https://dschloe.github.io/kaggle/2024/01/kaggle_korean_font/</link>
      <pubDate>Mon, 15 Jan 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/2024/01/kaggle_korean_font/</guid>
      <description>개요 캐글에서 한글폰트를 적용하는 방법에 대해 알아본다. 가장 간편한 방법은 폰트를 업로드 한 뒤 업데이트 하는 방식이다. 폰트 확인 폰트는 아래 사이트에서 다운로드 받는다. 사이트 : https://hangeul.naver.com/font 여기에서 나눔글꼴을 다운로드 받았다. 폰트 압축풀기 다운로드 폰트를 압축 풀기 하면 매우 다양한 폰트가 확인이 된다. 여기에서 나눔스퀘어 &amp;gt; NanumFontSetup_TTF_SQUARE 파일에서 폰트 목록을 확인한다. 폰트 업로드 이제 현재 사용하는 캐글 노트북에 추가한다. 임의의 font 폴더명을 입력했다. Create 버튼을 클릭한다. 업로드 이후에 폴더에 폰트가 들어간 것을 확인한다.</description>
    </item>
    
    <item>
      <title>statsmodels를 활용한 회귀분석 (feat. 범주형 데이터)</title>
      <link>https://dschloe.github.io/python/2024/01/statsmodels_category_variable_regression/</link>
      <pubDate>Fri, 12 Jan 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/01/statsmodels_category_variable_regression/</guid>
      <description>개요 statsmodels를 활용하여 범주형 데이터가 포함된 회귀식을 산정해본다. 범주형 데이터의 특정 값을 변동하는 방법을 배운다. 더불어서 R로 간단한 회귀식도 만들어보자! 강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 라이브러리 확인 statsmodels의 라이브러리는 현재 0.14.1 버전이다. 라이브러리 참조 : https://www.statsmodels.org/stable/index.html import statsmodels import seaborn as sns import pandas as pd print(statsmodels.__version__) print(sns.__version__) print(pd.__version__) 0.14.1 0.12.2 1.5.3 데이터 불러오기 seaborn에서 tips 데이터를 불러온다. tips = sns.load_dataset(&amp;#39;tips&amp;#39;) tips.head() 회귀모형 적합 및 확인 (첫번째 방식) - 이제 회귀모형을 적합해본다.</description>
    </item>
    
    <item>
      <title>conda vs virtualenv 라이브러리 관리 비교</title>
      <link>https://dschloe.github.io/python/2024/01/conda_virtualenv_package_manager/</link>
      <pubDate>Thu, 04 Jan 2024 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2024/01/conda_virtualenv_package_manager/</guid>
      <description>개요 파이썬에는 가상환경이 다양하게 존재한다. 이 중, conda와 virtualenv 가상환경에서 라이브러리 관리를 어떻게 하는지 비교를 해보도록 한다. 프로젝트 폴더 생성 폴더명은 virtualTest로 명명했다. Conda 먼저 가상환경을 만들어본다. conda create -n virtualTest python=3.10 conda 가상환경에 접속하는 방법은 다음과 같다. conda activate virtualTest environment.yml 라이브러리 관리를 위해 아래와 같이 샘플 코드를 생성한다. name: virtualTest channels: - defaults dependencies: - python=3.10 - numpy - pandas - pip: - streamlit 실행 코드는 아래와 같다. conda env create -f environment.</description>
    </item>
    
    <item>
      <title>(여행) 인천공항 1T Sky Hub Lounge</title>
      <link>https://dschloe.github.io/trip/2023/12/skyhublounge/</link>
      <pubDate>Sun, 10 Dec 2023 00:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/trip/2023/12/skyhublounge/</guid>
      <description>베트남 나트랑으로 떠나며 7월 유럽여행을 다녀온 이후, 쉴새없이 후반기를 달려왔습니다. 첫번째 멀티캠퍼스에서 강의를 마친 후, 중간 중간 저녁강의 및 토요일 강의를 병행하면서, 어떤 날은 일주일에 70시간 가깝게 소화한 날도 있었습니다. 그래서 약간의 휴가를 줄겸 하던차에 나트랑 여행을 떠나기로 하였습니다. (12월 8일까지 강의를 계속 했지요!). 그러던 찰나에 제가 가진 카드 중 라운지 연 2회 무료 이용권이 있음을 알게 되었습니다. 그래서 가족 여행을 떠나면서 라운지를 꼭 이용하고자 다짐했습니다. 보통 일요일에는 교회를 갑니다. 교회 근처에서 간단한 점심을 먹는데, 이번에는 교회에서 간단한 샌드위치와 아이스 아메리카노만 먹고 공항으로 출발했습니다.</description>
    </item>
    
    <item>
      <title>Matplotlib &amp; Seaborn with bar chart</title>
      <link>https://dschloe.github.io/python/2023/12/matplotlib_seaborn_barchart/</link>
      <pubDate>Sun, 03 Dec 2023 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/12/matplotlib_seaborn_barchart/</guid>
      <description>개요 본 코드는 다음 유투브 영상에서 다룬 내용 중 다루지 못한 내용을 추가한 블로그입니다. Youtube 유투브 영상은 다음과 같습니다. 전체 강의자료 및 데이터셋은 udemy 또는 inflern에서 확인 가능합니다. 가상의 데이터셋 생성 먼저 라이브러리를 불러온 후, 가상의 데이터셋을 만듭니다. import matplotlib.pyplot as plt import pandas as pd import numpy as np years = [2007, 2008] months = [&amp;#39;1&amp;#39;, &amp;#39;2&amp;#39;, &amp;#39;3&amp;#39;, &amp;#39;4&amp;#39;, &amp;#39;5&amp;#39;, &amp;#39;6&amp;#39;, &amp;#39;7&amp;#39;, &amp;#39;8&amp;#39;, &amp;#39;9&amp;#39;, &amp;#39;10&amp;#39;, &amp;#39;11&amp;#39;, &amp;#39;12&amp;#39;] np.random.seed(0) # For reproducibility data = { &amp;#39;year&amp;#39;: np.</description>
    </item>
    
    <item>
      <title>Exploring Unique Values in DataFrame Object Columns</title>
      <link>https://dschloe.github.io/python/2023/11/unique_values_df/</link>
      <pubDate>Sun, 26 Nov 2023 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/11/unique_values_df/</guid>
      <description>개요 pandas 데이터프레임의 여러 개체 유형(문자열) 열에서 고유 값을 조사하려면 해당 열을 선택한 다음 unique()를 적용하여 고유 값을 추출한다. 이를 위한 단계별 접근 방식은 다음과 같다. 1단계 : 여러 컬럼 중에서 문자열 컬럼만 추출한다. 2단계 : unique() 함수를 활용하여 unique()값만 가져온다. 3단계 : 결괏값은 dictionary 형태로 담는다. 가상 데이터 생성 임의의 가상 데이터를 생성한다. import pandas as pd data = { &amp;#39;Name&amp;#39;: [&amp;#39;Evan&amp;#39;, &amp;#39;Bob&amp;#39;, &amp;#39;Evan&amp;#39;, &amp;#39;Bob&amp;#39;], &amp;#39;City&amp;#39;: [&amp;#39;New York&amp;#39;, &amp;#39;Los Angeles&amp;#39;, &amp;#39;New York&amp;#39;, &amp;#39;SF&amp;#39;], &amp;#39;Job&amp;#39;: [&amp;#39;Engineer&amp;#39;, &amp;#39;Engineer&amp;#39;, &amp;#39;Engineer&amp;#39;, &amp;#39;Artist&amp;#39;], &amp;#39;num1&amp;#39; : [1, 2, 3, 4] } df = pd.</description>
    </item>
    
    <item>
      <title>빅데이터 분석기사 실기 준비 (작업 제2유형) 준비</title>
      <link>https://dschloe.github.io/python/2023/11/ds_certificate_type2/</link>
      <pubDate>Sun, 26 Nov 2023 00:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/11/ds_certificate_type2/</guid>
      <description>개요 작업 2유형(머신러닝)을 보다 쉽게 대비할 수 있도록 튜토리얼을 준비했습니다. 핵심 키워드 : Python 머신러닝은 pipeline 코드로 기억하자 본 코드는 구글 코랩에서 작성하였습니다. 유투브 유투브에서 강의 영상을 시청할 수 있습니다. (구독과 좋아요) 데이터 출처 본 데이터는 K-Data에서 가져왔습니다. 구글 드라이브 연동 데이터를 가져오기 위해 구글 드라이브와 연동합니다. from google.colab import drive drive.mount(&amp;#34;/content/drive&amp;#34;) Mounted at /content/drive 라이브러리 불러오기 아래 라이브러리들을 모두 암기하시기를 바랍니다. import pandas as pd import numpy as np from sklearn.</description>
    </item>
    
    <item>
      <title>Python 설치 Windows 11</title>
      <link>https://dschloe.github.io/python/2023/11/python_install/</link>
      <pubDate>Fri, 24 Nov 2023 00:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/11/python_install/</guid>
      <description>개요 Python 설치 과정을 유투브로 정리하였습니다. 본 튜토리얼은 Streamlit으로 프로젝트 한방에 끝내기 with 파이썬(2023, Sara &amp;amp; Evan) 교재를 동영상으로 변환하는 작업의 일환입니다. 유투브 </description>
    </item>
    
    <item>
      <title>BigQuery Connect to Google Analytics</title>
      <link>https://dschloe.github.io/gcp/2023/10/bigquery_to_ga4/</link>
      <pubDate>Thu, 26 Oct 2023 15:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/10/bigquery_to_ga4/</guid>
      <description>개요 BigQuery에서 Google Adwords 데이터와 Google Analytics를 불러올 수 있다. 전제조건 구글 클라우드 사용법은 어느정도 알고 있는 상태를 전제로 한다. Google Analytics를 이미 활용하고 있다는 것을 전제로 한다. Google Analytics 왼쪽 메뉴에서 관리 &amp;gt; 제품 링크를 확인한다. BigQuery 링크 클릭 &amp;gt; 연결 버튼을 클릭한다. BigQuery 프로젝트를 선택한다. 활성화중인 프로젝트를 선택한다. 데이터 위치를 지정한다. 본 프로젝트에서는 서울로 명명한다. 내보내기 유형은 매일로 선택한다. 사용자 데이터는 일별로 선택한다. 검토 후 제출 화면에서 특별한 이의사항이 없으면 보내기 버튼을 클릭한다.</description>
    </item>
    
    <item>
      <title>Streamlit App Deployment Compute Engine with Github Action in GCP</title>
      <link>https://dschloe.github.io/gcp/2023/10/streamlit_gcp_githubaction/</link>
      <pubDate>Wed, 25 Oct 2023 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/10/streamlit_gcp_githubaction/</guid>
      <description>개요 Google Compute Engine에서 Gihub Action을 구현하도록 한다. 프로젝트 생성 새 프로젝트 버튼을 클릭 후 프로젝트 명을 streamlit-gitaction으로 명명한다. Instance 생성 Compute Engine &amp;gt; VM Instance 선택 후, 새로운 인스턴스를 생성한다. 처음 사용하는 경우 사용 버튼을 클릭한다. 최초 작업에는 결제 필요 버튼이 나올 수 있다. 결제 사용 설정을 눌러 결제를 추가한다. 필자는 회사 계정을 사용한 것이므로 이렇게 나오지만, 일반 사용자는 화면이 다를 수 있다. VM 인스턴스를 생성한다. 인스턴스 이름과 리전과 영역은 다음과 같이 진행한다.</description>
    </item>
    
    <item>
      <title>MySQL Workbench File Import Error in Mac</title>
      <link>https://dschloe.github.io/sql/2023/10/mysql_import_error_mac/</link>
      <pubDate>Wed, 04 Oct 2023 10:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2023/10/mysql_import_error_mac/</guid>
      <description>개요 MySQL Workbench에서 File을 불러올 때 에러가 발생했을 때 대처 요령을 소개한다. Workbench에서 File을 불러올 때 가끔 아래와 같은 아래가 발생하곤 한다. 해결방법은 MySQL Shell Script에서 직접 파일을 불러오는 방식이다. MySQL 재접속 기존에 Workbench에 접속해 있었다면 우선 종료를 한다. 재접속 전 Edit Connection 버튼을 클릭한다.
Advanced Tab을 클릭한다.
Others 메뉴에서 OPT_LOCAL_INFILE=1 을 입력한다. Test Connection 버튼을 클릭하여 정상적으로 접속이 되는지 재 확인한다. 이제 재 접속을 하면 Workbench의 설정은 완료가 되었다. Schema 및 Table 생성 마우스 우클릭 후 스키마를 생성한다.</description>
    </item>
    
    <item>
      <title>Streamlit App Deployment with nohup in Google Compute Engine</title>
      <link>https://dschloe.github.io/gcp/2023/09/streamlit_nohup_on_gce/</link>
      <pubDate>Thu, 28 Sep 2023 16:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/streamlit_nohup_on_gce/</guid>
      <description>개요 Streamlit과 Bigquery를 연동하는 코드를 구현한다. 가상환경 설정 부터 VS Code 연동까지 준비가 안되어 있다면 이전 글을 참조하기를 바란다. 만약 GCP가 처음이신 분들은 이전 글을 순차적으로 읽어본다. Spark Installation with GCP (Sept. 2023) Compute Engine with Github in GCP Python Library Installation on Compute Engine in GCP GCP with VS Code SSH Connection gcloud Installation on Windows 11 Streamlit with Bigquery On Compute Engine 개요 Streamlit Sample 코드를 작성한 후 배포를 진행한다.</description>
    </item>
    
    <item>
      <title>Streamlit with Bigquery On Compute Engine</title>
      <link>https://dschloe.github.io/gcp/2023/09/streamlit_bigquery_gce/</link>
      <pubDate>Fri, 22 Sep 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/streamlit_bigquery_gce/</guid>
      <description>개요 Streamlit과 Bigquery를 연동하는 코드를 구현한다. 가상환경 설정 부터 VS Code 연동까지 준비가 안되어 있다면 이전 글을 참조하기를 바란다. 만약 GCP가 처음이신 분들은 이전 글을 순차적으로 읽어본다. Spark Installation with GCP (Sept. 2023) Compute Engine with Github in GCP Python Library Installation on Compute Engine in GCP GCP with VS Code SSH Connection gcloud Installation on Windows 11 인스턴스 시작 인스턴스가 중지가 되어 있다면 다시 시작을 한다. BigQuery Client 라이브러리 설치 클라이언트 라이브러리를 설치한다.</description>
    </item>
    
    <item>
      <title>gcloud Installation on Windows 11</title>
      <link>https://dschloe.github.io/gcp/2023/09/gcloud_installation_windows11/</link>
      <pubDate>Thu, 21 Sep 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/gcloud_installation_windows11/</guid>
      <description>개요 Windows 11에서 gcloud 설치를 진행한다. 참조 문서 : https://cloud.google.com/sdk/docs/install-sdk?hl=ko gcloud CLI 최신 버전(445.0.0) 설치 [Google Cloud CLI 설치 프로그램] (https://dl.google.com/dl/cloudsdk/channels/rapid/GoogleCloudSDKInstaller.exe?hl=ko) 다운로드 한다. 또는 PowerShell 터미널을 열고 다음 PowerShell 명령어를 실행한다. 여기에서는 설치 프로그램을 다운로드 받아서 설치한다. Finish 버튼을 클릭하면 설치는 완료가 된 것이다. gcloud 연동 위 Finish 버튼과 함께 로그인을 진행한다. 인증절차가 시작완료되면 웹 페이지가 변경되고 터미널 환경도 변경된다. 현재 필자의 프로젝트는 3번에 해당되기 때문에 3번을 클릭한다. default Region and Zone이 나오면 Y를 선택한다.</description>
    </item>
    
    <item>
      <title>GCP with VS Code SSH Connection</title>
      <link>https://dschloe.github.io/gcp/2023/09/gcp_with_vscode/</link>
      <pubDate>Wed, 20 Sep 2023 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/gcp_with_vscode/</guid>
      <description>개요 SSH Key를 이용하여 로컬에서 원격으로 GCP 프로젝트에 접속을 한다. 만약 GCP가 처음이신 분들은 이전 글을 순차적으로 읽어본다. Spark Installation with GCP (Sept. 2023) Compute Engine with Github in GCP Python Library Installation on Compute Engine in GCP SSH Key 생성하기 puTTYgen에서 public / private key 값을 생성한다. Generate 버튼을 클릭한다. Private Key를 OpenSSH 방식으로 Export 한다. Key Comment에 구글 계정을 입력한다. password도 입력한다. Public Key는 모두 복사한다. GCP 메타데이터 등록 Compute Engine &amp;gt; 메타데이터 접속하여 SSH 키에 붙여 넣는다.</description>
    </item>
    
    <item>
      <title>Python Library Installation on Compute Engine in GCP</title>
      <link>https://dschloe.github.io/gcp/2023/09/python_library_installation/</link>
      <pubDate>Tue, 19 Sep 2023 15:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/python_library_installation/</guid>
      <description>개요 기 설치된 Compute Engine에 라이브러리를 설치하고 간단하게 Streamlit 배포를 진행한다. 만약 GCP가 처음이신 분들은 이전 글을 순차적으로 읽어본다. Spark Installation with GCP (Sept. 2023) Compute Engine with Github in GCP requirements.txt Github Repo에서 Add file &amp;gt; Create new file을 클릭 후, 아래 주요 라이브러리를 입력한다. 파일명 : requirements.txt 라이브러리명은 다음과 같다. 입력 후, Commit Changes 버튼을 클릭한다. pyspark==3.1.1 pandas streamlit matplotlib 현재 파일 목록은 아래와 같다. 이제 GCP 터미널에서 requirements.</description>
    </item>
    
    <item>
      <title>Compute Engine with Github in GCP</title>
      <link>https://dschloe.github.io/gcp/2023/09/compute_engine_github/</link>
      <pubDate>Tue, 19 Sep 2023 14:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/compute_engine_github/</guid>
      <description>개요 Google Cloud Project에서 Github 계정을 연동하는 과정을 보여준다. 처음 GCP를 사용하는 독자분들은 이전 글을 참조해서 설정을 먼저 진행한다. 참조 : https://dschloe.github.io/gcp/2023/09/spark_installation_gcp/ 터미널 열기 기존 인스턴스는 중지를 시켰기 때문에 이를 다시 시작/재개 버튼을 눌러 활성화 한다. 시작 버튼 클릭과 함께 오늘도 비용을 지불해본다. 브라우저 창에서 열기를 진행한다. Git 설치 터미널에 Git을 설치하는 방법은 다음 명령어를 순차적으로 입력한다. (base) ~$ sudo apt-get update -y (base) ~$ sudo apt-get upgrade -y (base) ~$ sudo apt install git (base) ~$ git --version Git Repo 생성 Github에서 Repo를 만든다.</description>
    </item>
    
    <item>
      <title>Spark Installation with GCP (Sept. 2023)</title>
      <link>https://dschloe.github.io/gcp/2023/09/spark_installation_gcp/</link>
      <pubDate>Tue, 19 Sep 2023 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/spark_installation_gcp/</guid>
      <description>개요 Spark를 구글 클라우드에 설치하도록 한다. 프로젝트 시작부터 진행한다. 프로젝트 시작 본 화면에서 새로운 프로젝트를 시작한다. 프로젝트명 : mulcampFP VM 시작하기 VM 만들기를 클릭한다. 활성 결제 계정이 없으면 결제계정을 등록한다. 결제계정이 등록되면 다음과 같이 화면이 나오면 VM 설정이 가능하다. 결제계정까지 완료가 되었으면 다음과 같이 Compute Engine API를 사용 버튼을 클릭해준다. 이름은 mulcamp-gcp 지역은 서울로 했다. 비용에 따라 성능을 선택할 수 있다. 호스트 유지보수 시, VM 인스턴스는 마이그레이션을 권장한다. 부팅 디스크는 Ubuntu로 변경했다.</description>
    </item>
    
    <item>
      <title>MySQL Workbench ERD - 1</title>
      <link>https://dschloe.github.io/sql/2023/09/mysql_workbench_erd/</link>
      <pubDate>Fri, 15 Sep 2023 11:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2023/09/mysql_workbench_erd/</guid>
      <description>개요 MySQL Workbench를 통해 ERD 작업을 수행하도록 한다. Step 1 - 메뉴 선택 상단 메뉴에서 Database &amp;gt; Reverse Engineer 를 선택한다. Step 2 - Reverse Engineer Database Next 버튼을 클릭한다. Step 3 - Connect to MySQL Server 팝업창에서 root 또는 사용자 비밀번호 입력 후, 확인 버튼을 누르면 아래와 같이 연결이 될 것이다. Step 4 - Schema 선택 classicmodels 스키마를 선택한다. Step 4 - Connect to MySQL Server 비밀번호를 입력한다. Step 5 - 순차적으로 버튼 선택 Next 버튼을 클릭한다.</description>
    </item>
    
    <item>
      <title>MySQL Error Code 1175 해결</title>
      <link>https://dschloe.github.io/sql/2023/09/mysql_error_code_1175/</link>
      <pubDate>Thu, 14 Sep 2023 17:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2023/09/mysql_error_code_1175/</guid>
      <description>개요 Delete 문법을 진행하는데, 아래와 같은 에러가 발생하였다. 옵션 설정을 변경하여 코드를 재실행한다. Safe Mode 끄기 아래 코드를 실행한다. SET SQL_SAFE_UPDATES = 0; Edit &amp;gt; Preferences &amp;gt; SQL Editor &amp;gt; Other 에서 Safe Updates 체크되어 있는 것을 삭제한다. 코드 재 실행 Delete 코드를 재 실행한다. DELETE FROM tasks WHERE start_date = DATE(&amp;#39;2023-09-14&amp;#39;); 정상적으로 Delete 코드가 실행된 것을 확인할 수 있다. </description>
    </item>
    
    <item>
      <title>MySQL 실습 데이터 추가</title>
      <link>https://dschloe.github.io/sql/2023/09/mysql_data_insert/</link>
      <pubDate>Thu, 14 Sep 2023 10:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2023/09/mysql_data_insert/</guid>
      <description>개요 강의를 위한 CSV 파일을 Workbench를 통해 업로드를 하도록 한다. 교재 판매처 : https://www.yes24.com/Product/Goods/86544423 Workbench 접속 Local instance MySQL을 클릭한다. 최초 설치 진행시 진행한 password를 입력한다. 로그인한 화면은 아래와 같다. Sample 데이터 다운로드 사이트 : https://www.mysqltutorial.org/mysql-sample-database.aspx Download MySQL Sample Database를 클릭하여 다운로드 받는다. 압축파일을 풀면 아래와 같이 mysqlsampledatabase.sql 파일을 확인하다. 쿼리 불러오기 MySQL Workbench을 열고 File &amp;gt; Open SQL Script를 클릭한다. mysqlsampledatabase.sql 파일을 연다. 번개 모양의 아이콘을 클릭하면 쿼리가 실행된다. 좌측 메뉴바에서 Schemas 탭을 클릭 후, 새로고침을 한다.</description>
    </item>
    
    <item>
      <title>MySQL 설치 (윈도우 11 기반)</title>
      <link>https://dschloe.github.io/sql/2023/09/my_sql_install_windows11/</link>
      <pubDate>Wed, 13 Sep 2023 11:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2023/09/my_sql_install_windows11/</guid>
      <description>개요 MySQL 설치를 진행한다. MySQL 다운로드 사이트 : https://dev.mysql.com/downloads/windows/installer/8.0.html 위 화면에서 2번째를 선택한다. 선택 시, 로그인을 해야 하는 상황이 올수도 있다. 회원 가입 후, 재 진행 한다. 다음 화면에서 Download Now버튼을 클릭한다. MySQL 설치 다운로드 설치 프로그램을 실행한다. 아래 메뉴에서 선택적으로 설치가 가능하다. 여기에서는 Full 을 선택하고 설치를 진행하도록 한다. Execute 버튼을 클릭하여 설치를 진행한다. Next 버튼을 클릭한다. 포트 번호 (3306)를 기억한다. 간단하게 접속을 진행하기 위해 두번째 메뉴 선택 후, Next 버튼을 클릭한다.</description>
    </item>
    
    <item>
      <title>MySQL 완전 삭제 (윈도우 11 기반)</title>
      <link>https://dschloe.github.io/sql/2023/09/mysql_delete_windows11/</link>
      <pubDate>Wed, 13 Sep 2023 11:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2023/09/mysql_delete_windows11/</guid>
      <description>개요 기 설치된 MySQL을 완전 삭제하도록 한다. MySQL은 제어판 및 프로그램 제거를 통해서 삭제가 되지 않고, 이런 상태에서 제거할 경우, 재 설치 시 에러가 발생할 가능성이 높음 프로그램 추가 / 제거 MySQL과 관련된 모든 프로그램을 삭제한다. appdata에서 MySQL 폴더 삭제 window 버튼 + R을 누른 후, 아래와 같이 %appdata% 입력 후 확인 버튼을 클릭한다. MySQL 폴더를 삭제한다. ProgramData에서 MySQL 관련 폴더 삭제 Windows + R 실행 후, %ProgramData% 입력 후 확인 버튼을 누른다.</description>
    </item>
    
    <item>
      <title>VS Code with AWS EC2 접속</title>
      <link>https://dschloe.github.io/aws/2023/09/vscode_aws_conn/</link>
      <pubDate>Mon, 11 Sep 2023 10:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/2023/09/vscode_aws_conn/</guid>
      <description>VSCode - Remote SSH 설치 putty 같은 SSH 툴로 vi 에디터 이용해서 수정 매우 불편함 vscode에서 직접 EC2에 접속하도록 한다. AWS Extension 확장팩 설치 아래와 같이 확장팩을 설치한다. Remote SSH Extension 확장팩 설치 Remote - SSH 확장팩을 아래와 같이 설치를 진행하도록 한다. 설치가 완료가 되면 SSH 연결할 호스트를 입력한다. ssh [계정]@[ip주소] ssh aa@1.1.1.1 /User/evan/.ssh/config 선택한다. 환경설정 config 파일을 연다. 설정 옵션 클릭 &amp;gt; ~/.ssh/config 클릭 config 파일이 열리는지 확인한다. config 파일 작성 / 수정 Host : 주소 이름 (띄어쓰기 금지) 변경 가능 HostName : IP/DNS 부여받은 IP를 입력 User : 계정 이름 Port : 연결할 포트 번호를 말하며, 기본포트는 22이다.</description>
    </item>
    
    <item>
      <title>AWS EC2 접속 (with pem &amp; ppk file)</title>
      <link>https://dschloe.github.io/aws/2023/09/aws_server_conn/</link>
      <pubDate>Sun, 10 Sep 2023 10:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/2023/09/aws_server_conn/</guid>
      <description>멀티캠퍼스 AWS 서버 관련 정리 실습용 서버 실행 https://console.aws.amazon.com/console/home 계정 ID(12자리) 또는 계정 별칭 : your account ID : your id / PW : your password 실습용 서버 사용자 정보 참조하여 로그인 (강의 때 공유)
비밀번호 변경
본인 비밀번호는 반드시 기억한다. (강사비번 : ****) Slack 강사 DM으로 남겨주세요. EC2 실행 우측 상단 리전 정보를 ‘오사카’로 변경 후 서비스 검색창에서 EC2 검색 변경된 상태에서 EC2 검색 위 서비스창에서 EC2 클릭 및 아래 화면에서 실행 표시된 인스턴스 실행 장비할당 관련 이름(Name) 순으로 정렬 후 할당된 서버 선택 (강의 때 참조) 필수 확인 서버의 경우 수업 시작 30분 전인 08:30부터 19시 까지 사용이 가능합니다.</description>
    </item>
    
    <item>
      <title>Google Apps Script 기본문법 - 2</title>
      <link>https://dschloe.github.io/gcp/2023/09/google_apps_script2/</link>
      <pubDate>Tue, 05 Sep 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/google_apps_script2/</guid>
      <description>조건문 if 조건문 코드는 아래와 같음 여러개의 조건문은 &amp;amp;&amp;amp; 연산자 또는 || 연산자를 사용한다. function myFunction_01() { let number=9; if(number &amp;gt; 10) { console.log(&amp;#34;큰 수입니다!&amp;#34;) } else { console.log(&amp;#34;작은 수입니다.&amp;#34;) } } function myFunction_02() { var currentTemperature = 25; var isWeekend = true; var thresholdTemperature = 35; if (currentTemperature &amp;gt; thresholdTemperature &amp;amp;&amp;amp; !isWeekend) { console.log(&amp;#34;집에 계세요!&amp;#34;) } else if (currentTemperature &amp;gt; thresholdTemperature || isWeekend) { console.log(&amp;#34;외출하세요!&amp;#34;) } else { console.log(&amp;#34;판단을 보류합니다!</description>
    </item>
    
    <item>
      <title>Google Apps Script 기본문법 - 1</title>
      <link>https://dschloe.github.io/gcp/2023/09/google_apps_script_1/</link>
      <pubDate>Mon, 04 Sep 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/09/google_apps_script_1/</guid>
      <description>개요 Google Apps Script의 기본문법을 배우도록 한다. 변수와 상수, 배열, 객체등을 테스트 한다. 자바스크립트 기초 기초 문법을 배우도록 한다. 아래와 같이 코드 생성 후 실행을 한다. function myFunction() { Logger.log(&amp;#34;Hello World&amp;#34;); } 여러 함수를 만들고 선택적으로 실행이 가능하다. 주석 처리는 크게 // /* */ 으로 할 수 있다. function myFunction01_1() { Logger.log(&amp;#34;Hello World&amp;#34;); } function myFunction01_2() { console.log(&amp;#34;Hello GAS!&amp;#34;) // 주석 입력 /* 여러 행에 걸쳐 주석을 입력한다. */ } 스크립트 편집기에서는 [Ctrl] + [/] 를 이용하면 주석처리가 가능하다.</description>
    </item>
    
    <item>
      <title>M1 환경설정 XGBoost &amp; LightGBM with Streamlit in Python</title>
      <link>https://dschloe.github.io/python/2023/09/m1_settings_xgboost_lightgbm/</link>
      <pubDate>Fri, 01 Sep 2023 11:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/09/m1_settings_xgboost_lightgbm/</guid>
      <description>개요 M1에서 Python 환경설정을 해본다. XGBoost &amp;amp; LightGBM 및 Streamlit 설치를 진행한다. 아나콘다 설치 m1 버전의 아나콘다를 설치한다. 깃헙 레포 생성 먼저 github repo를 생성한다. Conda 가상환경 설정 git clone 명령어를 통해 repo를 로컬로 다운로드 한다. evan$ git clone https://github.com/yourname/m1_streamlit.git Cloning into &amp;#39;m1_streamlit&amp;#39;... remote: Enumerating objects: 4, done. remote: Counting objects: 100% (4/4), done. remote: Compressing objects: 100% (3/3), done. remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0 Receiving objects: 100% (4/4), done.</description>
    </item>
    
    <item>
      <title>Kaggle - Colab API 연동</title>
      <link>https://dschloe.github.io/kaggle/2023/08/kaggle_colab_api_connect/</link>
      <pubDate>Sun, 27 Aug 2023 11:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/2023/08/kaggle_colab_api_connect/</guid>
      <description>개요 API 토큰을 내려받은 후, 구글 코랩에서 데이터를 다운로드 받도록 한다. API 토큰 발급 Kaggle Profile - Settings - API를 순차적으로 클릭 후, Create New Token 버튼을 클릭한다. 아래 화면처럼 다운로드를 받을 수 있다. Google Colab API 코드 업로드 이제 해당 파일을 바탕화면 등 적당한 곳에 위치시킨 후 아래 코드를 실행한다. # kaggle.json 파일을 업로드하세요. from google.colab import files files.upload() 마지막으로 ~/.kaggle 폴더를 만들고 키 파일을 복사한 후, 보안을 위해 현재 사용자만 이 파일을 읽을 수 있도록 하는 명령어(chmod 600)를 실행한다.</description>
    </item>
    
    <item>
      <title>Google Colab Plotly Graph 안 보일 때</title>
      <link>https://dschloe.github.io/python/2023/08/google_colab_plotly_not_showing/</link>
      <pubDate>Thu, 10 Aug 2023 07:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/08/google_colab_plotly_not_showing/</guid>
      <description>현상 plotly 라이브러리를 활용하여 Google Colab에서 시각화를 할 때 그래프가 보이지 않는 현상이 존재함 여러 방법론이 등장하지만, 공식문서에 따라서 어떻게 활용하는지 확인하도록 함 Google Colab 먼저 구글 코랩에서 간단한 시각화 코드를 작성하고 코드를 실행한다. import plotly plotly.__version__ # 5.13.1 샘플 코드는 아래와 같음 import plotly.graph_objects as go import pandas as pd temp = pd.DataFrame({ &amp;#34;Fruit&amp;#34;: [&amp;#34;Apples&amp;#34;, &amp;#34;Oranges&amp;#34;, &amp;#34;Bananas&amp;#34;, &amp;#34;Apples&amp;#34;, &amp;#34;Oranges&amp;#34;, &amp;#34;Bananas&amp;#34;], &amp;#34;Contestant&amp;#34;: [&amp;#34;Alex&amp;#34;, &amp;#34;Alex&amp;#34;, &amp;#34;Alex&amp;#34;, &amp;#34;Jordan&amp;#34;, &amp;#34;Jordan&amp;#34;, &amp;#34;Jordan&amp;#34;], &amp;#34;Number Eaten&amp;#34;: [2, 1, 3, 1, 3, 2], }) fig = go.</description>
    </item>
    
    <item>
      <title>Scrapy Tutorial - 다중페이지 크롤링</title>
      <link>https://dschloe.github.io/python/2023/08/multipage_crawling_scrapy/</link>
      <pubDate>Tue, 08 Aug 2023 07:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/08/multipage_crawling_scrapy/</guid>
      <description>개요 이번에는 Scrapy를 통해서 다중 페이지를 크롤링 하도록 한다. Target 페이지 타겟 웹사이트 : https://www.audible.com/search 프로젝트 시작 프로젝트 시작은 다음과 같이 할 수 있다. $ scrapy startproject multiCam_tutorial New Scrapy project &amp;#39;multiCam_tutorial&amp;#39;, using template directory &amp;#39;C:\Users\j2hoo\OneDrive\Desktop\your_project_folder\venv\Lib\site-packages\scrapy\templates\project&amp;#39;, created in: C:\Users\j2hoo\OneDrive\Desktop\your_path\multiCam_tutorial You can start your first spider with: cd multiCam_tutorial scrapy genspider example example.com 해당 multiCam_tutorial 경로에서 다음 명령어를 실행하여 타겟 사이트를 설정한다. $ scrapy genspider audible www.audible.com/search Created spider &amp;#39;audible&amp;#39; using template &amp;#39;basic&amp;#39; in module: multiCam_tutorial.</description>
    </item>
    
    <item>
      <title>Scrapy Tutorial - 기본편</title>
      <link>https://dschloe.github.io/python/2023/08/scrapy_tutorial_1/</link>
      <pubDate>Tue, 08 Aug 2023 06:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/08/scrapy_tutorial_1/</guid>
      <description>개요 Scrapy Tutorial 설치 과정 및 기본 크롤링 과정을 살펴본다. 라이브러리 설치 라이브러리 설치는 다음과 같다. pip install scrapy 프로젝트 시작 Django와 비슷하게 터미널 명령어는 startproject라고 입력한다. $ scrapy startproject multiCam_tutorial New Scrapy project &amp;#39;multiCam_tutorial&amp;#39;, using template directory &amp;#39;C:\Users\j2hoo\OneDrive\Desktop\your_project_folder\venv\Lib\site-packages\scrapy\templates\project&amp;#39;, created in: C:\Users\j2hoo\OneDrive\Desktop\your_path\multiCam_tutorial You can start your first spider with: cd multiCam_tutorial scrapy genspider example example.com 파일 구조는 아래와 같이 여러개의 파일로 구성되었다. 타겟 주소는 아래와 같다. 주소 : https://www.worldometers.info/world-population/population-by-country/ $ scrapy genspider worldometer www.</description>
    </item>
    
    <item>
      <title>Django - ExcelCalCulator_7</title>
      <link>https://dschloe.github.io/python/2023/08/django_excel_calculator_7/</link>
      <pubDate>Thu, 03 Aug 2023 06:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/08/django_excel_calculator_7/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 이전 글 1편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_1/ 2편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_2/ 3편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_3/ 4편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_4/ 5편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_5/ 6편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_6/ Step 02 - 프로젝트 완성하기 지금까지 구현한 기능과 미완료된 기능을 확인한다. Step 03 - 로그인 실패 시 보이는 화면을 구현 우선 사용자가 로그인 실패 시, 보이는 화면으로 구현한다.</description>
    </item>
    
    <item>
      <title>Django - ExcelCalCulator_6</title>
      <link>https://dschloe.github.io/python/2023/08/django_excel_calculator_6/</link>
      <pubDate>Thu, 03 Aug 2023 05:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/08/django_excel_calculator_6/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 이전 글 1편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_1/ 2편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_2/ 3편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_3/ 4편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_4/ 5편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_5/ Step 02 - 프로젝트 완성하기 지금까지 구현한 기능과 미완료된 기능을 확인한다. Step 03 - 엑셀 결과 화면 출력 위한 세션값 저장 우선 calculate 함수의 마지막에 엑셀 결과 화면으로 데이터와 함께 url을 이동시켜본다.</description>
    </item>
    
    <item>
      <title>Django - ExcelCalCulator_5</title>
      <link>https://dschloe.github.io/python/2023/08/django_excel_calculator_5/</link>
      <pubDate>Thu, 03 Aug 2023 04:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/08/django_excel_calculator_5/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 이전 글 1편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_1/ 2편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_2/ 3편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_3/ 4편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_4/ Step 02 - 파일 업로드 하기 로그인을 통해 메인 화면으로 왔다면, 파일 업로드 기능 구현 Step 03 - 파일 업로드 기능 구현 check - 1 : index.</description>
    </item>
    
    <item>
      <title>Django - ExcelCalCulator_4</title>
      <link>https://dschloe.github.io/python/2023/08/django_excel_calculator_4/</link>
      <pubDate>Thu, 03 Aug 2023 03:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/08/django_excel_calculator_4/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 이전 글 1편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_1/ 2편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_2/ 3편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_3/ Step 02 - 로그인 기능 구현 로그인된 사용자만 이용할 수 있도록 구현 이 때, 현재 사용자가 로그인된 사용자인지 판단하려고 세션 사용 회원 가입 통한 과정 이외에도 정상적인 로그인 과정에서도 세션 처리 진행 Step 03 - 로그인 처리 구현 check - 1 : signin.</description>
    </item>
    
    <item>
      <title>Django - ExcelCalCulator_3</title>
      <link>https://dschloe.github.io/python/2023/08/django_excel_calculator_3/</link>
      <pubDate>Thu, 03 Aug 2023 02:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/08/django_excel_calculator_3/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 이전 글 1편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_1/ 2편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_2/ Step 02 - 인증하기 구현 자신의 이메일로 발송된 인증 코드를 입력한 후, “인증하기” 버튼을 누르면, main app 의 [views.py](http://views.py) 파일에 만들어 놓은 verify 함수로 오도록 설정한다. verifyCode.html url을 설정한다.</description>
    </item>
    
    <item>
      <title>Django - ExcelCalCulator_2</title>
      <link>https://dschloe.github.io/python/2023/08/django_excel_calculator_2/</link>
      <pubDate>Thu, 03 Aug 2023 01:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/08/django_excel_calculator_2/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 이전 글 1편 : https://dschloe.github.io/python/2023/08/django_excel_calculator_1/ Step 02 - 이메일 인증으로 회원 가입 절차는 다음과 같다. 회원 가입 화면에서 개인정보 입력 후 회원 가입하기 버튼 클릭 때 해당 정보로 유저 데이터 생성 및 DB에 저장, 이 때 인증되지 않은 유저로 등록 DB에 저장 후, 입력한 이메일로 인증 코드 발송 발송된 인증 코드는 유저 이름과 함께 쿠키로 저장 후 인증 코드 입력 화면으로 전환 인증 코드 입력 화면에서 인증 코드 입력 후 인증하기 버튼 클릭 때 입력된 코드와 쿠키에 저장된 인증 코드 비교 후 회원 성공/실패 처리 성공 때는 회원의 인증 값을 true 로 설정, 실패 때 해당 회원정보 삭제 Step 03 - DB 설정 사용자 정보를 저장할 수 있는 모델을 만들어야 한다.</description>
    </item>
    
    <item>
      <title>Django - ExcelCalCulator_1</title>
      <link>https://dschloe.github.io/python/2023/08/django_excel_calculator_1/</link>
      <pubDate>Thu, 03 Aug 2023 00:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/08/django_excel_calculator_1/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - Github Repo 생성 아래와 같이 Github Repo를 생성한다. Step 02 - 가상환경 생성 및 라이브러리 설치 virtualenv 명령어를 활용하여 가상환경을 설치한다. 실행 경로 : ExcelCalculate-with-Django $ virtualenv venv created virtual environment CPython3.9.13.final.0-64 in 2305ms creator CPython3Windows(dest=C:\Users\j2hoo\OneDrive\Desktop\ExcelCalculate-with-Django\venv, clear=False, no_vcs_ignore=False, global=False) seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=C:\Users\j2hoo\AppData\Local\pypa\virtualenv) added seed packages: pip==23.</description>
    </item>
    
    <item>
      <title>네이버 API 사용 신청 (2023 Aug)</title>
      <link>https://dschloe.github.io/settings/2023/8/naver_api/</link>
      <pubDate>Wed, 02 Aug 2023 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2023/8/naver_api/</guid>
      <description>개요 크롤링을 위해 네이버 API 사용을 신청해본다. Step 01 - 사이트 접속 네이버 개발자센터 사이트에 접속한다. URL : https://developers.naver.com/main/ Step 02 - 로그인 화면 우측 상단에서 로그인을 진행한다. Step 03 - API 이용신청 및 Application 등록 상단 메뉴에서 Application 클릭 후, 내 애플리케이션을 클릭한다. 확인 버튼을 클릭한다. 이용약관에 동의한다. 계정 정보를 등록 및 휴대폰 인증을 진행한다. 애플리케이션을 등록한다. (아무이름을 작성한다) 개인 PC로 접속하기 위해 WEB 설정 - localhost를 입력한다. 사용 API는 여기에서는 간단하게 검색만 지정한다.</description>
    </item>
    
    <item>
      <title>크롬드라이버 설정 방법 - Windows (2023 Aug)</title>
      <link>https://dschloe.github.io/settings/2023/8/chrome_driver_settings_windows/</link>
      <pubDate>Tue, 01 Aug 2023 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2023/8/chrome_driver_settings_windows/</guid>
      <description>개요 selenium 4.10 버전에서 크롬드라이버 설정하는 방법에 대해 기술하고자 한다. 크롬 버전 확인 크롬 버전 확인은 아래와 같이 진행한다. 먼저 설정을 클릭한다. Chrome 정보를 클릭한다. 본인의 크롬 버전을 확인한다. 크롬 드라이버 다운로드 싸이트 : https://chromedriver.chromium.org/downloads 여기에서 각 크롬버전에 맞게 들어간다. 그런데 간혹 최신버전은 빨간색 글씨 처럼 별도로 접근해 들어가야 한다. 참고 : https://googlechromelabs.github.io/chrome-for-testing/ 필자의 경우 크롬 버전은 115.0.5790.110 이지만 Status가 X로 되어 있다. 이럴 경우 115.0.5790.102 버전을 선택 한다. 위 화면에서 chromedriver를 본인 컴퓨터 OS에 맞는 것을 찾아서 다운로드 받는다.</description>
    </item>
    
    <item>
      <title>PowerShell 실행정책 Unrestricted 설정 방법</title>
      <link>https://dschloe.github.io/settings/2023/7/powershell_executionpolicy/</link>
      <pubDate>Mon, 31 Jul 2023 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2023/7/powershell_executionpolicy/</guid>
      <description>개요 vagrant 가상환경 설치 중 몇몇 수강생 분들의 에러 확인 PowerShell 실행정책에 따라, 잘 안되는 것을 확인 그런데 choco 실행 전에는 아래와 같이 설정을 하라고 되어 있다. 그런데, 일부 수강생중에는 설치 시 에러가 나는 것을 확인, 따라서 이를 모두 unrestricted로 변경 후, 재 설치를 진행해본다. 이전 글 참조 : https://dschloe.github.io/settings/2023/7/window_vagrant_ubutun18_04_python/ choco 설정의 내용 재 확인 choco 공식 홈피에서 제공한대로 설정을 해본다. PS C:\Users\j2hoo&amp;gt; Get-ExecutionPolicy Restricted 위 상황에서 첫번째 명령어를 입력한다. PS C:\Users\j2hoo&amp;gt; Set-ExecutionPolicy AllSigned PS C:\Users\j2hoo&amp;gt; Get-ExecutionPolicy AllSigned 현재 전체 실행 정책 목록을 확인해본다.</description>
    </item>
    
    <item>
      <title>윈도우 우분투 가상 환경 설치 (feat.chocolatey)</title>
      <link>https://dschloe.github.io/settings/2023/7/window_vagrant_ubutun18_04_python/</link>
      <pubDate>Sun, 30 Jul 2023 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2023/7/window_vagrant_ubutun18_04_python/</guid>
      <description>개요 크롤링 교재에서 윈도우에 우분투 가상 환경을 설치하는 부분이 있어서 실제로 잘 되는지 테스트를 해보았다. 향후 교재를 활용한다면, 해당 가상환경에서 진행 하는 것도 고려할 수 있다. 가상환경은 vagrant를 활용했다. 교재 파이썬을 활용한 크롤러 개발과 스크레이핑 입문 Step 01. Chocolatey 설치 윈도우에서 많이 활용되는 패키지 매니저가 바로 Chocolatey 이다. 먼저 3가지를 확인해야 한다. 첫번째 PowerShel이 설치 되어 있어야 하며, 최소 지원 버전은 3이다. PowerShell 버전 확인 PowerShell 탭을 열고 $PSVersionTable 명령어를 실행한다.</description>
    </item>
    
    <item>
      <title>Django Gmail 발송 예제 (2023년 버전)</title>
      <link>https://dschloe.github.io/python/2023/07/django_email_sample/</link>
      <pubDate>Thu, 27 Jul 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/07/django_email_sample/</guid>
      <description>개요 최근 django 강의를 진행하면서, Gmail로 이메일을 발송 하는 예제에서 인증 코드 진행하는 부분이 오래된 것을 확인 업그레이드 된 버전을 소개한다. 가상환경 및 django 라이브러리 설치 먼저 빈 폴더를 생성 후, 가상환경을 생성한다. (옵션) virtualenv 라이브러리 미 설치 시 $ pip install virtualenv 기 설치가 되어 있다면 아래 코드를 순차적으로 실행한다. $ virtualenv venv $ source venv/Scripts/activate 가상환경에 접속해 있다면 django를 설치 한다. $ pip install django 장고 프로젝트 및 앱 설치 이제 장고 프로젝트를 설정한다.</description>
    </item>
    
    <item>
      <title>Django Project ToDoList - 5</title>
      <link>https://dschloe.github.io/python/2023/07/django_todolist_5/</link>
      <pubDate>Wed, 26 Jul 2023 00:40:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/07/django_todolist_5/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 이전 내용 확인 이 글을 처음 봤다면, 이전 블로그를 참조하기를 바란다. 첫번째 글 : https://dschloe.github.io/python/2023/07/django_todolist_1/ 두번째 글 : https://dschloe.github.io/python/2023/07/django_todolist_2/ 세번째 글 : https://dschloe.github.io/python/2023/07/django_todolist_3/ 네번째 글 : https://dschloe.github.io/python/2023/07/django_todolist_4/ Step 02 - 데이터 삭제 방법 개요 및 HTML 수정 완료 버튼을 눌렀을 시, 데이터를 삭제하는 기능을 구현한다.</description>
    </item>
    
    <item>
      <title>Django Project ToDoList - 4</title>
      <link>https://dschloe.github.io/python/2023/07/django_todolist_4/</link>
      <pubDate>Wed, 26 Jul 2023 00:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/07/django_todolist_4/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 이전 내용 확인 이 글을 처음 봤다면, 이전 블로그를 참조하기를 바란다. 첫번째 글 : https://dschloe.github.io/python/2023/07/django_todolist_1/ 두번째 글 : https://dschloe.github.io/python/2023/07/django_todolist_2/ 세번째 글 : https://dschloe.github.io/python/2023/07/django_todolist_3/ Step 02 - 남은 과제 사용자가 입력한 문자열을 데이터베이스에 저장하기 DB에 저장된 내용을 보여 주기 Step 03 - 모델에 데이터 저장 먼저, my_to_do_app 폴더에 있는 [views.</description>
    </item>
    
    <item>
      <title>Django Project ToDoList - 3</title>
      <link>https://dschloe.github.io/python/2023/07/django_todolist_3/</link>
      <pubDate>Wed, 26 Jul 2023 00:20:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/07/django_todolist_3/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 이전 내용 확인 이 글을 처음 봤다면, 이전 블로그를 참조하기를 바란다. 첫번째 글 : https://dschloe.github.io/python/2023/07/django_todolist_1/ 두번째 글 : https://dschloe.github.io/python/2023/07/django_todolist_2/ Step 02 - model.py 작성 및 장고 서버 반영 ToDo에 대한 데이터를 다룰 예정이며, 다음과 같이 코드를 작성한다.</description>
    </item>
    
    <item>
      <title>Django Project ToDoList - 2</title>
      <link>https://dschloe.github.io/python/2023/07/django_todolist_2/</link>
      <pubDate>Wed, 26 Jul 2023 00:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/07/django_todolist_2/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 이전 내용 확인 이 글을 처음 봤다면, 이전 블로그를 참조하기를 바란다. 첫번째 글 : https://dschloe.github.io/python/2023/07/django_todolist_1/ Step 02 - HTML 템플릿 사용 HTML과 CSS가 적용된 기본 템플릿은 다음 github 저장소에서 다운로드 받을 수 있다.
책 저자 깃허브 : https://github.</description>
    </item>
    
    <item>
      <title>Django Project ToDoList - 1</title>
      <link>https://dschloe.github.io/python/2023/07/django_todolist_1/</link>
      <pubDate>Tue, 25 Jul 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/07/django_todolist_1/</guid>
      <description>개요 Django 한 그릇 뚝딱 교재의 내용에서 멀티캠퍼스 강의에 맞게 일부 수정함 2019년 버전이고 현재는 2023년이기 때문에 소스코드 변경 사항이 필요할 거 같아서 글을 남김 교재 홍보 교재 구매 : https://www.yes24.com/Product/Goods/83568594 Step 01 - 깃허브 Repo 생성 아래와 같이 깃허브에서 Repo를 생성한다. Repo명 : ToDoList-with-Django Step 02 - 바탕화면으로 Git Clone 이 때 중요한 것은 본인 경로에 한글이 없도록 하는 것이 중요하다. 간혹 한글이 있는 경우 인코딩 문제로 라이브러리 설치 등 되지 않을 수가 있다.</description>
    </item>
    
    <item>
      <title>대전 공기관 태블로 강의 실습</title>
      <link>https://dschloe.github.io/ds-projects/2023/07/tableau_lecture/</link>
      <pubDate>Tue, 18 Jul 2023 01:03:28 +0900</pubDate>
      
      <guid>https://dschloe.github.io/ds-projects/2023/07/tableau_lecture/</guid>
      <description>개요 본 튜토리얼은 실제 공기관에서 진행할 때 수강생들이 직접 보고 할 수 있도록 만든 샘플 자료입니다. 무단 복사 및 블로그 게시는 금지입니다. Step 01. Tableau Public 다운로드 아래 경로에서 Tableau Public를 다운로드 받는다. [만들기] - [Tableau Desktop Public Edition 다운로드] 참고 : https://public.tableau.com/app/discover Step 02. Tableau Desktop 설치 시작 Step 03. 태블로 화면 확인 및 파일 불러오기 아래 화면에서 Microsoft Excel 파일 불러온다. Step 04. 워크시트 1 - 지역별 근로자 수 현황 엑셀 데이터를 불러온 후, 시트로 이동한다.</description>
    </item>
    
    <item>
      <title>필자의 직무전환, 이직, 그리고 연봉 점프업 1편</title>
      <link>https://dschloe.github.io/ds-projects/2023/07/salary1/</link>
      <pubDate>Mon, 17 Jul 2023 01:03:28 +0900</pubDate>
      
      <guid>https://dschloe.github.io/ds-projects/2023/07/salary1/</guid>
      <description>개요 수강생들이 가장 궁금해 하는 연봉에 대한 여러가지 이야기 그리고 필자의 이야기 마케팅, SI, 스타트업, 그리고 프리랜서의 이야기 약 2편에 걸쳐서 연재할 예정 어느 오픈 카톡방에서.. 필자가 주로 애용하는 오픈 카톡방이 있다. 다양한 정보와 수다를 즐기는 곳인데, 여기에 아래와 같은 글이 공유되었다.
참조 : 연봉 점프업의 비밀 1/3(산업구조 관점) by Soojung Shin 이 글을 읽으니 필자의 과거 행적이 스쳐 지나갔다.
첫번째 꿈은 선교 그리고 NGO 20대의 꿈은 쉽게 말하면 돈을 버는 직업은 아니었다.</description>
    </item>
    
    <item>
      <title>2023년 상반기 결산 - 좋은 인연, 박사학위, 자격증, 출판, 유럽여행</title>
      <link>https://dschloe.github.io/ds-projects/2023/07/review/</link>
      <pubDate>Sat, 15 Jul 2023 01:03:28 +0900</pubDate>
      
      <guid>https://dschloe.github.io/ds-projects/2023/07/review/</guid>
      <description>개요 블로그를 3년간 운영하면서 회고 또는 결산하는 글을 써본적은 없었다. 요즘에 역 시차적응 때문인지.. 최근 중요한 결정을 내린 후폭풍인지.. 새벽에 자주 잠이 깨는데, 일어난 김에 몇가지 회고의 글을 남겨보려고 한다. (글쓰는 현재 지금 시각 새벽 2시다..) 좋은 인연 상반기에도 좋은 인연이 생겼다.
수많은 학생들, 새로운 기회의 확장, 새로운 학교 및 새로운 과정에서의 여러 만남들 2개 기관은 작년에 이어서 진행한 건, 1개 기관은 신규로 진행한 건 강의 평가가 모두 좋게 나와서 감사할 뿐이다.</description>
    </item>
    
    <item>
      <title>(파이썬) 빅데이터 분석기사 실기 - 제2유형, 회귀</title>
      <link>https://dschloe.github.io/python/2023/06/dataq_02_reg/</link>
      <pubDate>Thu, 22 Jun 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/06/dataq_02_reg/</guid>
      <description>작업형 2유형 최종정리 작업형1 : 3문제 (30점), 데이터 전처리 작업형2 : 1문제 (40점), 분류/회귀 예측 모델링 작업형3 : 2문제 (30점), 가설 검정 주요 라이브러리 palmerpenguins : 팔머펭귄 데이터셋의 목표는 iris 데이터셋의 대안으로 데이터 탐색 및 시각화를 위한 데이터셋 제공. scikit-learn : 머신러닝을 위한 라이브러리 lightgbm : LightGBM은 Microsoft에서 개발한 오픈 소스 기계 학습 라이브러리로, 대용량 데이터셋에서 빠른 속도와 높은 성능을 제공하는 것이 특징 주의 각 코드에 대한 설명은 별도로 하지 않습니다.</description>
    </item>
    
    <item>
      <title>(파이썬) 빅데이터 분석기사 실기 - 제2유형, 분류</title>
      <link>https://dschloe.github.io/python/2023/06/dataq_02_clf/</link>
      <pubDate>Wed, 21 Jun 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/06/dataq_02_clf/</guid>
      <description>작업형 2유형 최종정리 작업형1 : 3문제 (30점), 데이터 전처리 작업형2 : 1문제 (40점), 분류/회귀 예측 모델링 작업형3 : 2문제 (30점), 가설 검정 주요 라이브러리 palmerpenguins : 팔머펭귄 데이터셋의 목표는 iris 데이터셋의 대안으로 데이터 탐색 및 시각화를 위한 데이터셋 제공. scikit-learn : 머신러닝을 위한 라이브러리 lightgbm : LightGBM은 Microsoft에서 개발한 오픈 소스 기계 학습 라이브러리로, 대용량 데이터셋에서 빠른 속도와 높은 성능을 제공하는 것이 특징 주의 각 코드에 대한 설명은 별도로 하지 않습니다.</description>
    </item>
    
    <item>
      <title>(파이썬) 빅데이터 분석기사 실기 준비 - 제3유형</title>
      <link>https://dschloe.github.io/python/2023/06/dataq_03/</link>
      <pubDate>Tue, 20 Jun 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/06/dataq_03/</guid>
      <description>작업형 3유형 최종정리 작업형1 : 3문제 (30점), 데이터 전처리 작업형2 : 1문제 (40점), 분류/회귀 예측 모델링 작업형3 : 2문제 (30점), 가설 검정 라이브러리 확인 파이썬에서 가설검정을 위한 통계와 관련된 라이브러리는 크게 2가지이다. scipy : SciPy는 수치 계산, 최적화, 선형 대수, 신호 및 이미지 처리, 통계 분석 등과 같은 과학적 계산 작업을 수행하는 데 사용됨 statsmodels : Statsmodels는 통계 분석과 추정을 위한 파이썬 라이브러리로, 선형 회귀, 로지스틱 회귀, 시계열 분석, 비모수적 추정 등 다양한 통계 모델을 지원함.</description>
    </item>
    
    <item>
      <title>Python Pandas 날짜 데이터 다루기</title>
      <link>https://dschloe.github.io/python/2023/06/dealing_dates/</link>
      <pubDate>Sat, 17 Jun 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/06/dealing_dates/</guid>
      <description>개요 연도, 월, 주만 있는 컬럼을 날짜 데이터 타입으로 변경하려면 어떻게 해야할까? 약간의 트릭이 필요하다 데이터 생성 가상의 데이터를 생성한다. import pandas as pd data = [ {&amp;#34;year&amp;#34;: 2020, &amp;#34;month&amp;#34;: 1, &amp;#34;week&amp;#34;: 2, &amp;#34;company&amp;#34; : &amp;#34;A회사&amp;#34;, &amp;#34;revenue_pct&amp;#34; : 49}, {&amp;#34;year&amp;#34;: 2020, &amp;#34;month&amp;#34;: 1, &amp;#34;week&amp;#34;: 2, &amp;#34;company&amp;#34; : &amp;#34;B회사&amp;#34;, &amp;#34;revenue_pct&amp;#34; : 51}, {&amp;#34;year&amp;#34;: 2021, &amp;#34;month&amp;#34;: 1, &amp;#34;week&amp;#34;: 2, &amp;#34;company&amp;#34; : &amp;#34;A회사&amp;#34;, &amp;#34;revenue_pct&amp;#34; : 37}, {&amp;#34;year&amp;#34;: 2021, &amp;#34;month&amp;#34;: 1, &amp;#34;week&amp;#34;: 2, &amp;#34;company&amp;#34; : &amp;#34;B회사&amp;#34;, &amp;#34;revenue_pct&amp;#34; : 63}, {&amp;#34;year&amp;#34;: 2022, &amp;#34;month&amp;#34;: 12, &amp;#34;week&amp;#34;: 1, &amp;#34;company&amp;#34; : &amp;#34;A회사&amp;#34;, &amp;#34;revenue_pct&amp;#34; : 70}, {&amp;#34;year&amp;#34;: 2022, &amp;#34;month&amp;#34;: 12, &amp;#34;week&amp;#34;: 1, &amp;#34;company&amp;#34; : &amp;#34;B회사&amp;#34;, &amp;#34;revenue_pct&amp;#34; : 30}, ] df = pd.</description>
    </item>
    
    <item>
      <title>출간 기념, Streamlit으로 프로젝트 한방에 끝내기 with 파이썬(2023, Sara &amp; Evan)</title>
      <link>https://dschloe.github.io/ds-projects/2023/06/book_intro/</link>
      <pubDate>Thu, 01 Jun 2023 01:03:28 +0900</pubDate>
      
      <guid>https://dschloe.github.io/ds-projects/2023/06/book_intro/</guid>
      <description>책을 출간하였습니다. Streamlit이란 Streamlit은 데이터 분석가가 간단한 코드 몇줄로 빠르게 웹앱을 만들어 줄 수 있는 Python 라이브러리입니다. 웹사이트 : https://streamlit.io/ 누가 읽어야 할까요? 데이터 분석가 : 웹개발은 모르지만 대시보드를 만들어야 하는 분 국비교육 수강중인 비전공자 : Java 웹개발로 머신러닝 플랫폼을 만들어야 하는 분 개별적인 포트폴리오가 필요한 취업준비생 : ML/DL 알고리즘 익히는 것도 어려운데, 웹개발은 언제 배우죠? 데모 페이지 기초문법 포함 2달이면 충분히 아래 데모 페이지와 같이 만들 수 있습니다. 데모 페이지 : https://dschloe-streamlit-book-seoul-app-w9me9j.</description>
    </item>
    
    <item>
      <title>Streamlit와 BigQuery 활용한 배포 (API)</title>
      <link>https://dschloe.github.io/gcp/2023/05/streamlit_bigquery/</link>
      <pubDate>Thu, 18 May 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/05/streamlit_bigquery/</guid>
      <description>사전학습 이 글을 읽기전에 한번 Streamlit 라이브러리를 활용한 배포 - BigQuery 사용 을 읽고 오기를 바란다. 실습 순서 서울시 부동산 실거래가를 API 크롤링으로 가져온다. JSON 형태의 데이터를 pandas 데이터프레임으로 변환한다. 데이터프레임을 BigQuery에 전체 데이터를 저장한다. 저장된 데이터프레임을 BigQuery에서 일부 컬럼만 불러온다. 실습 1 - API 크롤링에서 빅쿼리로 데이터 저장 .streamlit/secrets.toml 을 열고 아래와 같이 설정한다. seoul_api_key는 서울 열린데이터 광장을 의미한다. gcp_service_account 아래 내용은 api key를 json 파일로 열면 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>Kaggle Wandb API 설정</title>
      <link>https://dschloe.github.io/kaggle/2023/05/kaggle_wandb/</link>
      <pubDate>Wed, 17 May 2023 11:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/2023/05/kaggle_wandb/</guid>
      <description>개요 Wandb에 접속 후, 활용해본다. 회원가입 회원가입을 진행한다. 사이트 : https://wandb.ai/site 여기에서 Github로 로그인을 진행한다. Authorize wandb를 클릭한다. Create your account 항목에 Full name과 회사명을 입력한다. 아래와 같이 지정했다. 교육 목적으로 선택했다. 팀 이름명을 지정한다. 추후에 설정한다. API Key가 나타난다. 어딘가에 인증키를 저장해둔다. db3cce8abed215f7b3770979a0006861dbcfe4f2 추후 확인 시 User Settings을 클릭한다. Scroll Down 하면 API 키값이 나타난다. 캐글 노트북 상단 메뉴 [Add-ones] - [Secrets]를 클릭한다. Secret 값을 아래와 같이 추가한다. 추가한 후, 아래 명령어를 추가한다.</description>
    </item>
    
    <item>
      <title>Streamlit Matplotlib 한글폰트 적용 예제</title>
      <link>https://dschloe.github.io/python/2023/05/streamlit_korean_fonts/</link>
      <pubDate>Tue, 16 May 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/05/streamlit_korean_fonts/</guid>
      <description>Streamlit Matplotlib-Seaborn 한글폰트 적용 개요 배포 시, matplotlib &amp;amp; seaborn 한글 폰트 적용 하는 방법에 대해 알아본다. 나눔고딕 폰트를 적용해본다. 폰트 다운로드 사이트 : https://fonts.google.com/specimen/Nanum+Gothic 개발환경 세팅 git clone 명령어를 활용하여 프로젝트 repo를 다운로드 받는다. 가상환경을 설정한다. virtualenv venv 실행한다. source venv/Scripts/activate 실행하여 가상환경에 접속한다. $ virtualenv venv created virtual environment CPython3.9.13.final.0-64 in 606ms creator CPython3Windows(dest=C:\Users\YONSAI\Desktop\streamlit-korean-fonts\venv, clear=False, no_vcs_ignore=False, global=False) seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=C:\Users\YONSAI\AppData\Local\pypa\virtualenv) added seed packages: pip==23.1.2, setuptools==67.</description>
    </item>
    
    <item>
      <title>SPSS 반복측정 분산분석</title>
      <link>https://dschloe.github.io/spss/2023/04/repeated_anova/</link>
      <pubDate>Fri, 28 Apr 2023 09:38:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/spss/2023/04/repeated_anova/</guid>
      <description>반복측정 분산분석 comercial_ratings.csv 데이터 불러오기 데이터탐색 분석 - 기술통계량 - 데이터탐색 아래와 같이 4개의 설문조사 데이터는 종속변수로 넣는다. 확인 버튼을 누른다. 데이터가 40개가 넘으므로 정규성 검토를 할 필요가 없음 만약에 정규성 분포를 한다고 하면 어떻게 할까? 일반선형모형 - 반복측정’ 여기에서 수준의 수를 정의하는 것이 1차 핵심이다. 총 광고의 종류는 4개이므로 요인의 수는 4가 된다. 요인의 이름은 문맥에 맞게 저장한다 측정 이름도 결과에 맞게 저장한다. 예) 매력도, 평가 등 1차 준비는 나온 것이다.</description>
    </item>
    
    <item>
      <title>SPSS - 케이스 선택</title>
      <link>https://dschloe.github.io/spss/2023/04/case_selection/</link>
      <pubDate>Sun, 23 Apr 2023 09:38:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/spss/2023/04/case_selection/</guid>
      <description>공지 본 내용은 아래 교재를 참조하여 작성하였다. SPSS를 활용하여 논문을 쓰셔야 하는 분은 좋은 책이니 반드시 살 것을 권한다. 한번에 통과하는 논문 SPSS (한빛아카데미) : http://www.yes24.com/Product/Goods/59577796 PREVIEW 케이스 선택은 주로 연구 대상만 남겨두고 나머지 케이스는 필터링하거나 삭제할 때 사용 케이스 선택 방법 : 데이터 - 케이스 선택 케이스 케이스 선택은 특정 케이스를 필터링(삭제하지 않고 분석 시 제외하는 것)하거나 삭제하고자 할 때 사용함 예시 : 연구 대상자가 남자라면 성별이 여자인 케이스는 필터링하거나 삭제해야 함 케이스 선택 방법 SPSS 상단 메뉴의 데이터-케이스 선택에서 진행함 연구 대상자가 남자일 때 어떻게 진행하는지 살펴본다.</description>
    </item>
    
    <item>
      <title>R 4.2.3 설치 - Windows</title>
      <link>https://dschloe.github.io/r/2023/04/r_4_2_3_install/</link>
      <pubDate>Tue, 04 Apr 2023 18:38:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/2023/04/r_4_2_3_install/</guid>
      <description>R 프로그램 설치 싸이트 : https://www.r-project.org/ download R 클릭 0-Cloud 선택 각 OS에 맞는 버전 설치, 여기서는 Windows 선택 Windows의 경우 아래와 같이 나타난다. Download R-4.2.3 for Windows 설치 다운로드 받은 설치 파일을 관리자 권한으로 실행한다. 언어는 한국어로 해도 상관없지만, 필자는 주로 영어로 선택해서 했기 때문에, 영어로 진행하도록 한다. 특별하게 주의 깊게 살펴서 해야 할 항목은 없기 때문에, Next 버튼을 순차적으로 클릭한다. R설치가 정상적으로 완료가 되면, 바탕화면에 R 로고가 나타날 것이다.</description>
    </item>
    
    <item>
      <title>Google Clound &amp; WSL2 Ubuntu 20.04 개발환경 설정</title>
      <link>https://dschloe.github.io/gcp/2023/02/gcp_wsl2_settings/</link>
      <pubDate>Sun, 26 Feb 2023 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/2023/02/gcp_wsl2_settings/</guid>
      <description>개요 GCP에서 개발환경을 설정하도록 한다. Local PC에서 GCP로 접속을 하도록 한다. 사전준비 WSL2 Ubuntu 설치 과정은 여기에서 다루지 않는다. 개발환경 설치 Python3 설치한다. (본인에게 맞는 언어를 선택한다) sudo apt update sudo apt install -y python3 python3-pip python3 최신 버전(417.0.1) gcloud CLI 설치 참고자료 : https://cloud.google.com/sdk/docs/install-sdk?hl=ko gcloud CLI를 설치하기 전 운영체제가 다음 요구사항을 충족하는지 확인합니다. $ sudo apt-get install apt-transport-https ca-certificates gnupg 패키지 소스로 gcloud CLI 배포 URI를 추가합니다. 배포판에서 서명 옵션을 지원하는 경우 다음 명령어를 실행합니다.</description>
    </item>
    
    <item>
      <title>Matplotlib 한글폰트 적용 예제 - Windows 10</title>
      <link>https://dschloe.github.io/python/2023/02/matplotlib_koreanfont/</link>
      <pubDate>Wed, 22 Feb 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/02/matplotlib_koreanfont/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 개요 한글폰트를 다운로드 받아서 matplotlib에 적용하는 코드를 작성해본다. 주요 코드를 기억해서 업무에 활용해보도록 한다. 폰트 다운로드 일반적으로 자주 사용하는 폰트를 다운로드 받는다. 참고 : https://www.kopus.org/biz-electronic-font2/ 스크롤을 내리면 TTF 다운로드 버튼을 클릭한다. 폰트 설치 다운로드 받은 폰트를 압축을 푼다. 캐시 정리 일반적으로는 다른 오피스 프로그램을 사용할 때는 위 폰트를 글꼴 설정에 추가하면 끝이다. 그러나, Matplotlib에서는 글꼴 설정이 끝이 아니라 Matplotlib에서 관리하는 폰트에 해당 글꼴이 들어있느냐가 매우 중요하다.</description>
    </item>
    
    <item>
      <title>가계금융복지조사 데이터 수집</title>
      <link>https://dschloe.github.io/settings/2023/2/mdis_data_load/</link>
      <pubDate>Sat, 18 Feb 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2023/2/mdis_data_load/</guid>
      <description>개요 통계청(https://mdis.kostat.go.kr/) 에서는 마이크로데이터를 제공하고 있음 해당 사이트에서 회원가입은 필수로 진행해야 한다. MDIS 다운로드 서비스 이용 2022년 기준 가계금융복지조사 데이터를 다운로드 받는다. 다운로드 서비스/소득소비자산/가계금융복지조사/가구마스터(제공)/2022년도를 아래와 같이 순차적으로 클릭한다. 다운로드받을 데이터의 형태와 해당 데이터를 입수할 때 필요한 ‘통계 툴 읽기 스크립트’를 선택한다. Python 스크립트는 제공하지 않아서, R로 선택을 한다. 위 그림에서 마이페이지를 클릭한다. </description>
    </item>
    
    <item>
      <title>Docker Streamlit Sample</title>
      <link>https://dschloe.github.io/settings/2023/2/docker_streamlit_app_windows10/</link>
      <pubDate>Wed, 15 Feb 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2023/2/docker_streamlit_app_windows10/</guid>
      <description>개요 도커를 활용하여 Streamlit 배포를 진행해본다. Dockerfile의 의미에 대해 이해한다. Dockerfile Docker 이미지를 빌드하기 위한 일련의 명령어를 포함하는 텍스트 파일 컨테이너에서 애플리케이션이 실행될 때 필요한 환경과 종속성을 정의하는 방법을 제공 패키지 설치, 파일 복사 및 환경 변수 설정 등의 지시어가 포함 사전준비 github에 sample 프로젝트를 올려둔다. 예제 : https://github.com/streamlit/streamlit-example 필자는 독립적으로 github repository를 작성했다. 소스코드 예제 소스코드는 크게 아래와 같이 작성했다. 먼저 app.py는 아래와 같다. import numpy as np import pandas as pd import matplotlib import sklearn import scipy import plotly import streamlit as st def main(): st.</description>
    </item>
    
    <item>
      <title>Docker 기본 문법</title>
      <link>https://dschloe.github.io/settings/2023/2/docker_basic/</link>
      <pubDate>Tue, 14 Feb 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2023/2/docker_basic/</guid>
      <description>무작정 도커 시작하기 docker에 Ubuntu를 설치하고 실행해본다. 현재 파일 목록들을 살펴본다. 빠져 나올 때는 EXIT를 실행한다. C:\Users\human&amp;gt;docker run -it ubuntu:18.04 Unable to find image &amp;#39;ubuntu:18.04&amp;#39; locally 18.04: Pulling from library/ubuntu 72d9f18d70f3: Pull complete Digest: sha256:a3765b4d74747b5e9bdd03205b3fbc4fa19a02781c185f97f24c8f4f84ed7bbf Status: Downloaded newer image for ubuntu:18.04 root@7a7a49e2d83e:/# ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@7a7a49e2d83e:/# 현재 도커 컨테이너 리스트를 확인한다. $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7a7a49e2d83e ubuntu:18.</description>
    </item>
    
    <item>
      <title>Git 배치파일 Windows</title>
      <link>https://dschloe.github.io/settings/2023/1/git_batchfile_windows/</link>
      <pubDate>Fri, 10 Feb 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2023/1/git_batchfile_windows/</guid>
      <description>개요 배치파일로 생성 후, 작업 스케줄러를 활용하여 자동으로 커밋을 실행하는 코드를 작성한다. 다른 예제도 같이 살펴본다. 윈도우 배치 파일 - 파이썬 가상환경 적용 배치파일 생성하기 프로젝트 폴더에 배치파일을 실행한다. 파일명은 submit.bat 로 지정했다. set root=C:\Users\human\Desktop\streamlit-predictions call git add . call git commit -m &amp;#34;updated from batch file&amp;#34; call git push 배치파일 실행하기 우선 해당 폴더에서 submit.bat 파일을 더블클릭한다. 더블 클릭하면 자동으로 배치파일이 실행되면서 해당 명령어들이 순차적으로 돌아가는 것을 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>Streamlit &amp; ChatGPT API 배포 예제</title>
      <link>https://dschloe.github.io/python/2023/02/streamlit_openai_example/</link>
      <pubDate>Thu, 09 Feb 2023 01:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/02/streamlit_openai_example/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 개요 ChatGPT API 배포 예제 흐름도를 보여주도록 한다. Streamlit 회원가입, OpenAI 회원가입은 완료했다는 가정하에 본 블로그를 읽기 바란다. Streamlit : https://share.streamlit.io/ OpenAI : https://openai.com/api/ API Key 생성 아래 화면에서 View API Keys를 클릭한다. 아래 화면에서 Create new secret key 버튼을 클릭한다. 계정 발급 시 필수 확인 사항 필자는 사업자 G메일 계정이 있고, 개인 계정이 있다. 먼저 개인 계정의 사용자 대시보드 화면은 아래와 같이 나온다.</description>
    </item>
    
    <item>
      <title>지도시각화 예제 - QGIS를 활용한 geojson 파일 만들기</title>
      <link>https://dschloe.github.io/python/2023/02/qgis_create_geojson/</link>
      <pubDate>Sun, 05 Feb 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/02/qgis_create_geojson/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH Installation Map 시각화를 위한 주요 라이브러리를 설치한다. pip install numpy pandas matplotlib seaborn jupyterlab geopandas pydeck Enabling pydeck for Jupyter Jupyter는 더 복잡한 서버/클라이언트 상호 작용을 허용할 수 있다. 사용자 또는 시스템 관리자가 주피터에서 사용할 수 있도록 pydeck를 사용하도록 설정해야 한다. 바이너리 데이터 전송, 데이터 선택 및 시간 경과에 따른 데이터 업데이트는 파이덱이 주피터 환경에서 사용 가능한 경우에만 대화식으로 작동할 수 있다.</description>
    </item>
    
    <item>
      <title>Streamlit 라이브러리를 활용한 배포 예제 - sqlite</title>
      <link>https://dschloe.github.io/python/2023/02/streamlite_with_sqlite/</link>
      <pubDate>Wed, 01 Feb 2023 00:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/02/streamlite_with_sqlite/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 개요 간단한 프로젝트라도 DB와 연동하는 작업은 매우 중요하다. 클라우드 DB를 사용하기 위해서는 클라우드 회원가입 등 번거로운 절차를 거쳐야 하며, 또한 비용도 추가될 수도 있다. SQLite를 사용하면 간단한 DB 작업도 진행할 수 있다. Streamlit + SQLite 연동 작업을 간단히 하도록 해본다. SQLite 데이터 핸들링을 하기 위해서는 Python 기초 문법, Pandas 라이브러리를 배워야 한다. Pandas는 본 블로그에서 CSV 파일을 읽고 저장을 하는데 사용을 하게 된다.</description>
    </item>
    
    <item>
      <title>서울시 부동산 실거래가 정보 API 크롤링 2 - 크롤링편 (XML)</title>
      <link>https://dschloe.github.io/python/2023/01/seoul_real_estate_02/</link>
      <pubDate>Tue, 31 Jan 2023 19:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/01/seoul_real_estate_02/</guid>
      <description>개요 Open API를 통해서 부동산 실거래가 정보를 pandas 데이터프레임으로 변환하는 코드를 구현한다. 요청인자 확인 샘플 URL은 크게 2가지를 제공한다. 서울시 부동산 실거래가 정보 http://openapi.seoul.go.kr:8088/(인증키)/xml/tbLnOpendataRtmsV/1/5/ 서울시 부동산 실거래가 정보(마곡일성트루엘플래닛) http://openapi.seoul.go.kr:8088/(인증키)/xml/tbLnOpendataRtmsV/1/5/2022/11500/강서구/10500/일반/0758/0002/마곡일성트루엘플래닛/오피스텔 출력 예제는 다음과 같다. &amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;tbLnOpendataRtmsV&amp;gt; &amp;lt;list_total_count&amp;gt;2639192&amp;lt;/list_total_count&amp;gt; &amp;lt;RESULT&amp;gt; &amp;lt;CODE&amp;gt;INFO-000&amp;lt;/CODE&amp;gt; &amp;lt;MESSAGE&amp;gt;정상 처리되었습니다&amp;lt;/MESSAGE&amp;gt; &amp;lt;/RESULT&amp;gt; &amp;lt;row&amp;gt; &amp;lt;ACC_YEAR&amp;gt;2023&amp;lt;/ACC_YEAR&amp;gt; &amp;lt;SGG_CD&amp;gt;11545&amp;lt;/SGG_CD&amp;gt; &amp;lt;SGG_NM&amp;gt;금천구&amp;lt;/SGG_NM&amp;gt; &amp;lt;BJDONG_CD&amp;gt;10100&amp;lt;/BJDONG_CD&amp;gt; &amp;lt;BJDONG_NM&amp;gt;가산동&amp;lt;/BJDONG_NM&amp;gt; &amp;lt;LAND_GBN&amp;gt;1&amp;lt;/LAND_GBN&amp;gt; &amp;lt;LAND_GBN_NM&amp;gt;대지&amp;lt;/LAND_GBN_NM&amp;gt; &amp;lt;BONBEON&amp;gt;0776&amp;lt;/BONBEON&amp;gt; &amp;lt;BUBEON&amp;gt;0000&amp;lt;/BUBEON&amp;gt; &amp;lt;BLDG_NM&amp;gt;가산대명벨리온&amp;lt;/BLDG_NM&amp;gt; &amp;lt;DEAL_YMD&amp;gt;20230127&amp;lt;/DEAL_YMD&amp;gt; &amp;lt;OBJ_AMT&amp;gt;12300&amp;lt;/OBJ_AMT&amp;gt; &amp;lt;BLDG_AREA&amp;gt;16.28&amp;lt;/BLDG_AREA&amp;gt; &amp;lt;TOT_AREA&amp;gt;25.630000&amp;lt;/TOT_AREA&amp;gt; &amp;lt;FLOOR&amp;gt;8&amp;lt;/FLOOR&amp;gt; &amp;lt;RIGHT_GBN/&amp;gt; &amp;lt;CNTL_YMD/&amp;gt; &amp;lt;BUILD_YEAR&amp;gt;2017&amp;lt;/BUILD_YEAR&amp;gt; &amp;lt;HOUSE_TYPE&amp;gt;오피스텔&amp;lt;/HOUSE_TYPE&amp;gt; &amp;lt;REQ_GBN&amp;gt;중개거래&amp;lt;/REQ_GBN&amp;gt; &amp;lt;RDEALER_LAWDNM&amp;gt;서울 금천구&amp;lt;/RDEALER_LAWDNM&amp;gt; &amp;lt;/row&amp;gt; &amp;lt;row&amp;gt; &amp;lt;ACC_YEAR&amp;gt;2023&amp;lt;/ACC_YEAR&amp;gt; &amp;lt;SGG_CD&amp;gt;11500&amp;lt;/SGG_CD&amp;gt; &amp;lt;SGG_NM&amp;gt;강서구&amp;lt;/SGG_NM&amp;gt; &amp;lt;BJDONG_CD&amp;gt;10500&amp;lt;/BJDONG_CD&amp;gt; &amp;lt;BJDONG_NM&amp;gt;마곡동&amp;lt;/BJDONG_NM&amp;gt; &amp;lt;LAND_GBN&amp;gt;1&amp;lt;/LAND_GBN&amp;gt; &amp;lt;LAND_GBN_NM&amp;gt;대지&amp;lt;/LAND_GBN_NM&amp;gt; &amp;lt;BONBEON&amp;gt;0793&amp;lt;/BONBEON&amp;gt; &amp;lt;BUBEON&amp;gt;0000&amp;lt;/BUBEON&amp;gt; &amp;lt;BLDG_NM&amp;gt;유림트윈파크&amp;lt;/BLDG_NM&amp;gt; &amp;lt;DEAL_YMD&amp;gt;20230127&amp;lt;/DEAL_YMD&amp;gt; &amp;lt;OBJ_AMT&amp;gt;13900&amp;lt;/OBJ_AMT&amp;gt; &amp;lt;BLDG_AREA&amp;gt;19.</description>
    </item>
    
    <item>
      <title>서울시 부동산 실거래가 정보 API 크롤링 1 - 인증키 발급편</title>
      <link>https://dschloe.github.io/python/2023/01/seoul_real_estate_01/</link>
      <pubDate>Mon, 30 Jan 2023 10:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/01/seoul_real_estate_01/</guid>
      <description>회원가입 회원가입 : 회원가입 | 서울특별시청 (seoul.go.kr) 모두 동의합니다를 선택한다. 본인인증 절차를 거친다. 회원정보를 입력한다. 부가서비스 신청은 옵션이기 때문에 여기서 별도로 다루지는 않겠다. 회원가입이 완료가 되었다. 서울 열린데이터 광장 로그인 이제 데이터 수집을 위해, 해당 사이트에 로그인을 진행한다. 찾고 싶은 데이터를 입력해주세요 부동산을 입력하고 검색을 진행한다. 여기에서 서울시 부동산 실거래가 정보 탭을 클릭한다. 하단에 인증키 신청을 클릭한다. 작성이 끝나면 바로 API 발급이 부여가 된다. </description>
    </item>
    
    <item>
      <title>ChatGPT를 활용한 싱가포르 여행 후기 - Spectra Show 관람기</title>
      <link>https://dschloe.github.io/trip/2023/01/singapore_trip_chatgpt/</link>
      <pubDate>Sat, 21 Jan 2023 00:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/trip/2023/01/singapore_trip_chatgpt/</guid>
      <description>개요 ChatGPT를 활용하여 각 여행지의 기본정보를 제공한다. 사진은 필자가 직접 찍은 것을 활용했다. 마리나 샌즈 호텔 마리나 샌즈 호텔은 싱가포르에서 유명한 호텔입니다. 이 호텔은 싱가포르의 주요 관광지와 접근성이 좋고, 객실이 깨끗하고 서비스가 좋다고 소개되고 있습니다. 마리나 샌즈 호텔에서는 수영장, 사우나, 제과점, 정원, 수프 식사 서비스 등을 제공합니다. 객실 안에는 에어컨, 텔레비젼, 전화, 커피/차 메이커, 일회용 샴푸, 바디 샴푸, 수건, 샤워 캡 등이 구비되어 있습니다. 마리나 샌즈 호텔 내부에는 쇼핑몰, 레스토랑, 커피숍 등이 있습니다.</description>
    </item>
    
    <item>
      <title>OpenCV 개발환경 윈도우 버전</title>
      <link>https://dschloe.github.io/python/2023/01/opencv_install_windows/</link>
      <pubDate>Thu, 19 Jan 2023 10:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2023/01/opencv_install_windows/</guid>
      <description>개요 Windows에서 Opencv 개발환경을 구축한다. 아나콘다를 설치하지 않고 구축한다. 사전 준비 파이썬 설치는 이미 진행된 것으로 가정한다. 설치 웹사이트 : https://www.python.org/ 또한 가상환경을 이미 설치한 것으로 가정한다. 주요 설치 명령어 opencv-python은 OpenCV의 메인 모듈을 포함하고, opencv-contrib-python은 메인 모듈과 Extras 모듈을 포함한다. 설치 시, NumPy는 자동으로 설치 된다. matplotlib 라이브러리는 파이썬 기본 시각화 라이브러리이다. pafy 라이브러리는 Youtube의 메타 데이터를 수집/검색하거나 다운로드 할 수 있도록 도와줌 youtube_dl 라이브러리는 터미널에서 사용 가능한 라이브러리이다. pygame은 파이썬에서 제공하는 게임 라이브러리이다.</description>
    </item>
    
    <item>
      <title>GROUP BY 1의 의미와 사용법 예제</title>
      <link>https://dschloe.github.io/sql/2022/12/groupby_1/</link>
      <pubDate>Thu, 22 Dec 2022 14:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/2022/12/groupby_1/</guid>
      <description>개요 GROUP BY 1의 구체적인 의미에 대해 파악을 한다. 데이터 개요 주어진 데이터는 아래와 같다. 이 데이터는 미국의 과거 및 현재 국회의원 데이터셋을 사용한다. 참조 : https://github.com/unitedstates/congress-legislators SELECT * FROM legislators_terms; 쿼리 예제 다음 쿼리는 리텐션을 구하는 쿼리를 작성하기 위해 작성했다. 먼저, 각 의원이 첫 임기를 시작한 날짜를 first_term으로 정의한다. SELECT id_bioguide , MIN(term_start) AS first_term FROM legislators_terms GROUP BY 1; GROUP BY 1 대신에 GROUP BY id_bioguide로 변경하여 코드를 작성해본다.</description>
    </item>
    
    <item>
      <title>Streamlit 라이브러리를 활용한 배포 - BigQuery 사용</title>
      <link>https://dschloe.github.io/python/2022/12/streamlit_bigquery/</link>
      <pubDate>Fri, 02 Dec 2022 15:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2022/12/streamlit_bigquery/</guid>
      <description>개요 Streamlit 라이브러리와 BigQuery를 사용하여 배포를 진행한다. GCP 클라우드 프로젝트 설정 과정은 생략한다. BigQuery API 사용설정 Project API에서 ENABLE APIS AND SERVICES 버튼을 클릭한다. 빅쿼리 API를 탐색한다. 키워드명 : BigQuery API manage 버튼을 클릭한다. 인증키를 다운로드 받도록 한다. (CREATE CREDENTIALS클릭) 아래와 같이 지정 후, 스크롤을 내려서 NEXT 버튼을 클릭한다. 임의의 Service account ID 작성 후, CREATE AND CONTINUE 버튼을 클릭한다. 프로젝트 권한을 부여 후, CONTINUE 버튼을 클릭한다. Done 버튼을 클릭한다. Service Accounts - [우측] Manage keys 버튼 클릭 Create new key 버튼 클릭 JSON 클릭 json 파일을 다운로드 받는다.</description>
    </item>
    
    <item>
      <title>Streamlit 라이브러리를 활용한 배포 예제</title>
      <link>https://dschloe.github.io/python/2022/11/streamlit_deploy/</link>
      <pubDate>Tue, 29 Nov 2022 09:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2022/11/streamlit_deploy/</guid>
      <description>사전준비 배포를 하기 위해서는 필수로 진행해야 할 사전준비가 필요하다. Git &amp;amp; Github 설치 과정은 생략한다. Step 01 - Streamlit 회원가입 https://share.streamlit.io/signup 아래 이미지에서 Continue with Github 와 같이 회원가입을 진행한다. Set up your account를 작성한다. 작성이 끝나면 다음과 같은 화면이 나오면 정상적으로 등록이 된 것이다. Step 02 - Github 레포 설정 Gitub 레포를 설정한다. 이 때, 주의해야 할 것은 Public으로 설정을 해야한다. .gitignore 파일도 Setting 하는 것이 좋다. Step 03 - 주요 라이브러리 설치 다음 코드를 실행하여 배포를 위한 라이브러리를 설치한다.</description>
    </item>
    
    <item>
      <title>Google Analytics 4 설치 - Hugo 깃허브</title>
      <link>https://dschloe.github.io/settings/2022/11/ga4_install/</link>
      <pubDate>Sun, 27 Nov 2022 01:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2022/11/ga4_install/</guid>
      <description>개요 Google Analytics 4 설치 과정을 정리하였다. 사전준비 본 글에서는 Google Analytics 4 관련 설명은 생략한다. 어느정도 관련 도구를 이해한다는 전제 조건에서 글을 정리한다. 단계별 설치 과정 단계별로 설치 과정을 알아보자. (1) GA4 추적 ID 가져오기 Google Analytics 4 에서 추적 코드를 받는다. 추적 코드는 Admin - Data Streams에서 확인이 가능하다. Add stream 에서 Hugo Website 주소를 입력한 후 설정을 하면 된다.
그럼 MEASUREMENT ID 확인이 가능하다.
G-XXXXXXX 시작하는 ID만 있으면 충분하다.</description>
    </item>
    
    <item>
      <title>윈도우 배치 파일 - 파이썬 가상환경 적용</title>
      <link>https://dschloe.github.io/settings/2022/11/windows_batch_file/</link>
      <pubDate>Mon, 21 Nov 2022 01:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2022/11/windows_batch_file/</guid>
      <description>개요 Python 가상환경을 만든 후, 자동으로 배치 파일이 돌아가도록 하는 코드를 작성하도록 한다. Step 01 - 라이브러리 설치 가상환경을 만든 후, pandas 라이브러리를 설치하도록 한다. $ virtualenv venv $ ./venv/Scripts/activate 만약 에러가 아래와 에러가 생길 경우, $ .\venv\Scripts\activate .\venv\Scripts\activate : 이 시스템에서 스크립트를 실 행할 수 없으므로 C:\Users\h\Desktop\python_batch\venv\ Scripts\activate.ps1 파일을 로드할 수 없습니다. 자세한 내용은 about_Execution_Policies(https://go.microsoft. com/fwlink/?LinkID=135170)를 참조하십시오. 위치 줄:1 문자:1 + .\venv\Scripts\activate + ~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : 보안 오류: (:) [], PSSec uri tyException + FullyQualifiedErrorId : UnauthorizedAccess PowerShell을 관리자 권한으로 실행 후 아래 코드를 입력한다.</description>
    </item>
    
    <item>
      <title>Heroku를 활용한 카카오챗봇 배포 - DB조회편</title>
      <link>https://dschloe.github.io/python/2022/11/heroku_db_query_iris/</link>
      <pubDate>Mon, 14 Nov 2022 15:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2022/11/heroku_db_query_iris/</guid>
      <description>읽기 전 공지 본 글은 2022년 11월 28일까지만 유효합니다. 무료 버전이 사라지기 때문에, 앞으로 어떻게 될지는 현재 글 쓰는 시점에서는 모릅니다. 이 부분에 주의해서 참고 하시기를 바랍니다. 강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 [비전공자 대환영] 캐글 데이터를 활용한 Optuna with MLFlow - 캐글다지기 머신러닝 하이퍼파라미터 튜닝 등을 배우고 싶다면 다음 강의를 참고하세요.</description>
    </item>
    
    <item>
      <title>Heroku를 활용한 카카오챗봇 배포 - 응용편</title>
      <link>https://dschloe.github.io/python/2022/11/heroku_deploy_final_calculation/</link>
      <pubDate>Thu, 10 Nov 2022 15:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2022/11/heroku_deploy_final_calculation/</guid>
      <description>읽기 전 공지 본 글은 2022년 11월 28일까지만 유효합니다. 무료 버전이 사라지기 때문에, 앞으로 어떻게 될지는 현재 글 쓰는 시점에서는 모릅니다. 이 부분에 주의해서 참고 하시기를 바랍니다. 강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 [비전공자 대환영] 캐글 데이터를 활용한 Optuna with MLFlow - 캐글다지기 머신러닝 하이퍼파라미터 튜닝 등을 배우고 싶다면 다음 강의를 참고하세요.</description>
    </item>
    
    <item>
      <title>Heroku를 활용한 카카오챗봇 배포 - 인사말편</title>
      <link>https://dschloe.github.io/python/2022/11/heroku_deploy_final_greeting/</link>
      <pubDate>Thu, 10 Nov 2022 11:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2022/11/heroku_deploy_final_greeting/</guid>
      <description>읽기 전 공지 본 글은 2022년 11월 28일까지만 유효합니다. 무료 버전이 사라지기 때문에, 앞으로 어떻게 될지는 현재 글 쓰는 시점에서는 모릅니다. 이 부분에 주의해서 참고 하시기를 바랍니다. 강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 [비전공자 대환영] 캐글 데이터를 활용한 Optuna with MLFlow - 캐글다지기 머신러닝 하이퍼파라미터 튜닝 등을 배우고 싶다면 다음 강의를 참고하세요.</description>
    </item>
    
    <item>
      <title>Heroku를 활용한 배포 - DB 연결편</title>
      <link>https://dschloe.github.io/python/2022/11/heroku_deploy_final/</link>
      <pubDate>Wed, 09 Nov 2022 01:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/2022/11/heroku_deploy_final/</guid>
      <description>읽기 전 공지 본 글은 2022년 11월 28일까지만 유효합니다. 무료 버전이 사라지기 때문에, 앞으로 어떻게 될지는 현재 글 쓰는 시점에서는 모릅니다. 이 부분에 주의해서 참고 하시기를 바랍니다. 강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 [비전공자 대환영] 캐글 데이터를 활용한 Optuna with MLFlow - 캐글다지기 머신러닝 하이퍼파라미터 튜닝 등을 배우고 싶다면 다음 강의를 참고하세요.</description>
    </item>
    
    <item>
      <title>Docker Installation in Windows</title>
      <link>https://dschloe.github.io/settings/2022/10/docker_windows/</link>
      <pubDate>Sat, 29 Oct 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/2022/10/docker_windows/</guid>
      <description>사전 준비 WSL2가 설치가 되어 있어야 한다. 참고 : https://dschloe.github.io/settings/wsl2_install_on_windows/ 도커 설치 해당 싸이트에 접속한다. (참조 : https://www.docker.com/products/docker-desktop/) 관리자 권한으로 실행 설치가 완료가 되면 Close and Log Out 버튼이 나오면 클릭하면 윈도우 로그아웃이 진행되기 때문에, 다시 재 로그인을 하도록 한다. 아래 그림 메뉴 우측 상단에 Sign In 버튼을 클릭해 로그인을 한다. 도커 Settings 창에 들어가서 아래 그림처럼 변경후 Apply &amp;amp; Restart 버튼을 클릭한다. 테스트 PowerShell에서 도커 명령어가 실행되는지 확인한다. PS C:\Users\h&amp;gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES PS C:\Users\h&amp;gt; docker --version Docker version 20.</description>
    </item>
    
    <item>
      <title>WSL2 설치 윈도우 10</title>
      <link>https://dschloe.github.io/settings/wsl2_install_on_windows/</link>
      <pubDate>Tue, 25 Oct 2022 14:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/wsl2_install_on_windows/</guid>
      <description>Step 0. 설정을 통해 Hyper-V 역할 활성화 Windows 기능 사용/사용 안 함 재부팅을 해야 한다. Step 1. WSL2 설치 과정 Windows PowerShell 관리자로 실행 후 다음 명령어 입력 $ dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart $ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 위 명령어 실행 후, 재부팅 필수 x64 머신용 최신 WSL2 Linux 커널 업데이트 패키지를 다운로드 받아 안내에 따라 설치합니다. Windows Powershell 열고 아래 코드 실행 $ wsl --set-default-version 2 WSL 2와의 주요 차이점에 대한 자세한 내용은 https://aka.</description>
    </item>
    
    <item>
      <title>Excel with MySQL 연동</title>
      <link>https://dschloe.github.io/sql/excel_with_mysql/</link>
      <pubDate>Sun, 09 Oct 2022 14:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/excel_with_mysql/</guid>
      <description>개요 엑셀 VBA 강의 중 Excel에서 MySQL DB와 연동하는 방법 의뢰를 받음 엑셀은 MySQL과 연결이 (생각보다) 매우 쉽게 할 수 있도록 설계 되어 있었음 사전준비 MySQL 설치 과정은 다음 자료를 참고한다. https://hongong.hanbit.co.kr/mysql-다운로드-및-설치하기mysql-community-8-0/ 버전 확인 먼저 필자는 윈도우 11에서 작업중임 필자의 엑셀 정보는 아래와 같음 [계정] - [Excel 정보] 클릭하면 아래와 같음 필자의 MySQL 정보는 아래와 같음 필수 설치 프로그램 다운로드 및 설치 https://www.microsoft.com/ko-kr/download/details.aspx?id=48217 에 접속 후 다운로드 받은 후 설치를 진행한다.</description>
    </item>
    
    <item>
      <title>Plotly 그래프 - 막대 그래프 색상 변경</title>
      <link>https://dschloe.github.io/python/dash/plotly_07_bar_color/</link>
      <pubDate>Mon, 19 Sep 2022 12:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/plotly_07_bar_color/</guid>
      <description>개요 특정 컬럼의 색상을 변경하는 코드를 작성한다. 기본 그래프 작성 우선 아래와 같은 기본 그래프를 작성한다. import plotly.express as px tips = px.data.tips() tips_mean_day = tips.groupby(&amp;#34;day&amp;#34;).mean().reset_index() tips_mean_day.head() fig = px.bar(tips_mean_day, x = &amp;#39;day&amp;#39;, y = &amp;#39;tip&amp;#39;) fig.show() Sun 색상 변경 Sun 값의 막대 그래프의 색상을 변경하도록 한다. 먼저 marker.color를 활용하여 색상을 먼저 지정한 뒤, X축 라벨의 순서를 후에 재정렬한 것이다. fig.data[0].marker.color = [&amp;#39;#ff0000&amp;#39;, &amp;#39;#ff0000&amp;#39;, &amp;#39;black&amp;#39;, &amp;#39;#ff0000&amp;#39;] fig.layout.xaxis.categoryarray = [&amp;#34;Thur&amp;#34;, &amp;#34;Fri&amp;#34;, &amp;#34;Sat&amp;#34;, &amp;#34;Sun&amp;#34;] fig.</description>
    </item>
    
    <item>
      <title>Plotly 그래프 - 막대 그래프 X축 라벨 변경하기</title>
      <link>https://dschloe.github.io/python/dash/plotly_06_bargraphedit_xlabel/</link>
      <pubDate>Wed, 14 Sep 2022 12:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/plotly_06_bargraphedit_xlabel/</guid>
      <description>개요 기존에 작성한 그래프를 목적에 맞게 수정 및 변경할 수 있다. Figure Object를 활용한다. 데이터 불러오기 및 가공 tips 데이터를 불러온 뒤, 데이터를 가공하여 평균 값을 구한다. import plotly.express as px tips = px.data.tips() tips_mean_day = tips.groupby(&amp;#34;day&amp;#34;).mean().reset_index() tips_mean_day.head() 막대 그래프 작성하기 기본 막대그래프를 작성한다. 그런데, X축의 값을 보면 요일별로 정리가 안된 것을 확인할 수 있다. 이 부분을 수정하도록 한다. fig = px.bar(tips_mean_day, x = &amp;#39;day&amp;#39;, y = &amp;#39;tip&amp;#39;) fig.show() 막대 그래프의 X 라벨 변경하기 우선 막대그래프의 순서를 변경하도록 한다.</description>
    </item>
    
    <item>
      <title>Plotly 그래프 - Plotly Express</title>
      <link>https://dschloe.github.io/python/dash/plotly_05_express/</link>
      <pubDate>Tue, 13 Sep 2022 12:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/plotly_05_express/</guid>
      <description>개요 High-Level API 형태인 Plotly Express에 대해 학습하도록 한다. Plotly Express는 간단하게 말하면 Pandas Dataframe과 직접적으로 연동이 가능하다. 보다 직관적으로 그래프를 시각화할 수 있기 때문에 초기 밑그림을 그릴 때는 Plotly Express로 작성하는 것이 좋다. 전체 설명 참고자료 : Plotly Express in Python Plotly Express 요약 Plotly Express Function은 graph_objects를 기반으로 작성되며, 그래프의 반환값도 plotly.graph_objects 형태이다. 공식 문서에는 약 30개 이상이 그래프 유형이 존재하는 것으로 알려지고 있다. 참조 : plotly.express: high-level interface for data visualization Plotly Express 그래프 종류 Plotly Express currently includes the following functions:</description>
    </item>
    
    <item>
      <title>Plotly 그래프 - 테마 변경하기</title>
      <link>https://dschloe.github.io/python/dash/plotly_04_theme_changes/</link>
      <pubDate>Mon, 12 Sep 2022 12:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/plotly_04_theme_changes/</guid>
      <description>개요 plotly 그래프의 테마를 변경하는 방법에 대해 알아본다. 그래프 테마의 종류 확인하기 우선 기본 그래프를 확인한다. import plotly.graph_objects as go weekly_sales = dict({ &amp;#34;data&amp;#34;: [{ &amp;#34;type&amp;#34;: &amp;#34;bar&amp;#34;, &amp;#34;x&amp;#34;: [&amp;#34;Monday&amp;#34;, &amp;#34;Tuesday&amp;#34;, &amp;#34;Wednesday&amp;#34;, &amp;#34;Thursday&amp;#34;, &amp;#34;Friday&amp;#34;, &amp;#34;Saturday&amp;#34;, &amp;#34;Sunday&amp;#34;], &amp;#34;y&amp;#34;: [28, 27, 25, 31, 32, 35, 36] }], &amp;#34;layout&amp;#34; : {&amp;#34;title&amp;#34;: {&amp;#34;text&amp;#34;: &amp;#34;Sales of the week&amp;#34;, &amp;#34;x&amp;#34;: 0.5, &amp;#34;font&amp;#34;: {&amp;#34;color&amp;#34;: &amp;#34;red&amp;#34;, &amp;#34;size&amp;#34;: 15}}} }) fig = go.Figure(weekly_sales) fig.show() 그래프 테마를 변경하기 위해 우선 종류를 확인해야 한다.</description>
    </item>
    
    <item>
      <title>Plotly 그래프 - 이미지 내보내기</title>
      <link>https://dschloe.github.io/python/dash/plotly_03_exports/</link>
      <pubDate>Sun, 11 Sep 2022 12:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/plotly_03_exports/</guid>
      <description>개요 Plotly 그래프를 다양한 방법으로 내보내는 코드를 작성해본다. 본 블로그에서는 HTML, PNG 두가지 형태로 내보내는 방법을 숙지한다. HTML로 내보내기 plotly figures는 HTML 및 자바스크립트로 구성되어 있다. 소스코드는 아래와 같다. fig.write_html(&amp;#39;html_plot.html&amp;#39;, config={&amp;#39;toImageButtonOptions&amp;#39;:{&amp;#39;format&amp;#39;: &amp;#39;svg&amp;#39;}}) image로 내보내기 이미지로 내보내기 위해서는 아래와 같이 소스코드를 작성한다. fig.write_image(&amp;#39;path/to/image_file.svg&amp;#39;,height=600, width=850) 그런데, 실행 시, 다음과 에러가 나올 경우 아래와 같이 라이브러리를 설치한다. --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &amp;lt;ipython-input-11-691564193a43&amp;gt; in &amp;lt;module&amp;gt; ----&amp;gt; 1 fig.write_image(&amp;#39;img/tutorial.png&amp;#39;, height = 600, width = 850) /Library/Frameworks/Python.</description>
    </item>
    
    <item>
      <title>Plotly 그래프 - Figure Object 이해하기</title>
      <link>https://dschloe.github.io/python/dash/plotly_02_figure_object/</link>
      <pubDate>Sat, 10 Sep 2022 12:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/plotly_02_figure_object/</guid>
      <description>Figure Object Figure Object는 크게 두가지로 구성(Attribute)이 되어 있다. data : 여기에서는 그래프와 관련된 각종 정보가 담긴 데이터를 의미한다. 예를 들면, 산점도를 그린다면, X와 Y값의 정보를 확인할 수 있다. 그래프의 색상도 정의할 수 있다. layout : data외의 모든 것은 layout에 속한다. 기본적으로 layout은 그래프의 Styling 요소들이 들어 있다. 예를 들면, X축, Y축의 제목, 색상 등을 변경하고자 할 때는 layout에 접근해야 한다. 간단하게 Figure Object를 정의해본다. import plotly.graph_objects as go fig = go.</description>
    </item>
    
    <item>
      <title>Plotly 그래프 시작하기 - 필수 사전 준비</title>
      <link>https://dschloe.github.io/python/dash/plotly_01_started/</link>
      <pubDate>Fri, 09 Sep 2022 12:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/plotly_01_started/</guid>
      <description>개요 Plotly 그래프의 기본 생태계를 익히도록 한다. Plotly 그래프를 작성하도록 한다. 라이브러리 불러오기 본 코드는 모두 Local 가상환경을 설치한 후, Jupyter Lab에서 작성했다. 해당 설치 과정은 본 블로그에서는 생략한다. 참조 : https://dojang.io/mod/page/view.php?id=2470 현재 plotly 버전은 다음과 같다. import plotly print(plotly.__version__) 5.1.0 로컬 환경에서 Jupyter notebook에서 plotly 그래프가 간혹 나타나지 않는 경우가 있다. 그런 경우, 아래와 같이 추가로 설치를 진행한다. jupyter labextension install jupyterlab-plotly 설치가 완료되었다면, 아래와 같은 코드를 추가로 실행한다. import plotly plotly.</description>
    </item>
    
    <item>
      <title>Flask Web Resume Using Templates</title>
      <link>https://dschloe.github.io/python/python_edu/09_web/flask_web_resume/</link>
      <pubDate>Sat, 03 Sep 2022 10:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/09_web/flask_web_resume/</guid>
      <description>개요 Flask 웹개발을 통해 간단한 Resume를 작성해본다. 가상환경 프로젝트 폴더에 가상환경을 설치한다. virtualenv venv created virtual environment CPython3.9.12.final.0-64 in 5343ms creator CPython3Windows(dest=C:\Users\human\Desktop\flask-resume-evan-examples\venv, clear=False, no_vcs_ignore=False, global=False) seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=C:\Users\human\AppData\Local\pypa\virtualenv) added seed packages: pip==22.2.2, setuptools==63.2.0, wheel==0.37.1 activators BashActivator,BatchActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator 라이브러리 설치 가상환경에 접속 후, Flask 라이브러리를 설치한다. pip install Flask [app.py](http://app.py) 에 다음과 같이 작성한다. from flask import Flask, render_template app = Flask(__name__) @app.route(&amp;#39;/&amp;#39;) def index(): first_name = &amp;#39;Evan&amp;#39; return render_template(&amp;#39;index.</description>
    </item>
    
    <item>
      <title>Dash App Using Flask Factory Pattern and Blueprint - 2</title>
      <link>https://dschloe.github.io/python/dash/dash_app_factory_pattern_2/</link>
      <pubDate>Fri, 26 Aug 2022 09:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/dash_app_factory_pattern_2/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 기존 Flask-Dash-Heroku 연동 예제를 업그레이드 한다. Flask Factory Application의 기본 개념 및 Blueprint의 기본 개념을 이해한다. Dash App을 Flask Factory Application에 맞추어 가공 한다. 리뷰 기존 필자가 작성해두었던 Flask-Dash-Heroku App을 리뷰한다. 참조 : Flask-Dash-Heroku 연동 참조 : Dash App Using Flask Factory Pattern and Blueprint - 1 미리보기 다음과 같이 메뉴가 있도록 코드를 작성할 예정이다.</description>
    </item>
    
    <item>
      <title>Dash App Using Flask Factory Pattern and Blueprint - 1</title>
      <link>https://dschloe.github.io/python/dash/dash_app_factory_pattern_1/</link>
      <pubDate>Thu, 25 Aug 2022 09:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/dash_app_factory_pattern_1/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 기존 Flask-Dash-Heroku 연동 예제를 업그레이드 한다. Flask Factory Application의 기본 개념 및 Blueprint의 기본 개념을 이해한다. 리뷰 기존 필자가 작성해두었던 Flask-Dash-Heroku App을 리뷰한다. 참조 : Flask-Dash-Heroku 연동 미리보기 다음과 같이 메뉴가 있도록 코드를 작성할 예정이다.</description>
    </item>
    
    <item>
      <title>Grafana 설치 및 대시보드 만들기 - 기본편</title>
      <link>https://dschloe.github.io/settings/grafana_install/</link>
      <pubDate>Sat, 20 Aug 2022 13:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/grafana_install/</guid>
      <description>개요 Grafana 대시보드를 다운로드 받고, 그래프를 작성한다. DB 연동을 통해 대시보드를 작성해본다. 설치 Grafana Download 사이트 : https://grafana.com/grafana/download?edition=oss&amp;amp;platform=windows 오픈소스로 다운로드 받는다. 설치가 끝난 이후에는 localhost:3000/login에 접속을 할 수 있다. Sign in 페이지가 나오면 admin을 각각 입력하면, 패스워드 변경하는 입력이 나오면 그 때 각자 본인에게 맞는 패스워드로 변경한다. 필자는 12345678로 지정했다. 첫번째 대시보드 Dashboard를 클릭한다. Add a new panel를 클릭한다. 아래 그림에서 Data source를 클릭한다. Query 탭에 Grafana를 선택한 상태에서 우측 상단의 Apply 버튼을 클릭한다.</description>
    </item>
    
    <item>
      <title>Flask-Dash-Heroku 연동</title>
      <link>https://dschloe.github.io/python/dash/flask_dash_heroku/</link>
      <pubDate>Thu, 18 Aug 2022 09:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/flask_dash_heroku/</guid>
      <description>개요 Flask 및 Dash를 활용하여 간단한 대시보드를 생성할 수 있다. 기존 구현한 대시보드를 Heroku에 배포할 수 있다. 사전준비 파이썬 가상환경 설치 및 기존 라이브러리에 대한 이해가 어느정도 있음을 가정한 상태에서 본 블로그를 작성했음을 유의한다. Heroku 회원가입 및 로그인이 되어 있어야 한다. Step 1. Github Repo생성 Github Repo 생성 시, 중복되지 않을 법한 이름으로 생성 필자 Repo : flask-heroku-dash-evan1234 해당 Repo를 로컬로 가져온다. git clone https://github.com/your_name/your_unique_repo.git Step 2. 가상환경 설치 및 주요 라이브러리 설치 먼저 가상환경을 설치한다.</description>
    </item>
    
    <item>
      <title>Mecab 사용자 단어 사전 추가 in R, windows 10</title>
      <link>https://dschloe.github.io/r/text_mining/mecab_user_dic_in_r/</link>
      <pubDate>Wed, 17 Aug 2022 17:38:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/text_mining/mecab_user_dic_in_r/</guid>
      <description>개요 Mecab에서 사용자 단어를 추가하고 직접 사용하는 예제를 만들어본다. 사전에 Mecab은 설치가 되어 있다고 가정한다. 만약 처음 설치한다면, 다음 참조 링크에서 설치를 진행한다. 참조 : RcppMeCab 패키지 설치 (Windows) 문제점 아래그림과 같이 ‘사회적경제’라는 단어가 잡히지 않는 것을 확인할 수 있다. 해결방법 먼저, 사전 위치를 찾는다. mecab &amp;gt; user-dic 폴더 내에 nnp.csv 파일을 찾는다. 서식에 관한 구체적인 내용을 참조링크를 확인한다. 품사태그 설명 nnp.csv 파일을 메모장으로 열고 수정한다. 사용자 사전 수정 적용하기 위해 Window PowerShell을 관리자 권한으로 연다 mecab 폴더로 이동해야 하기 위해 아래와 같이 입력을 한다.</description>
    </item>
    
    <item>
      <title>Flask Heroku Pandas Postgres 튜토리얼</title>
      <link>https://dschloe.github.io/python/python_edu/09_web/flask_heroku_pandas_posgres/</link>
      <pubDate>Tue, 09 Aug 2022 10:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/09_web/flask_heroku_pandas_posgres/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Flask 기본적인 작동 원리를 배운다. Postgres와 SQLAlchemy를 활용한다. Heroku에 배포를 진행한다. 사전준비 Github에 각 개인에게 맞는 Github Repo를 생성한다. 주의 : 반드시 Unique하게 작성해야 한다. 가상환경 설정을 진행한다. PostgreSQL DB 설정은 다음을 참조한다. Postgre SQL Installation on Windows 10 virtualenv venv 주요 라이브러리를 설치한다.</description>
    </item>
    
    <item>
      <title>Scikit-Learn ML Model with Java</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/sklearn2java/</link>
      <pubDate>Fri, 05 Aug 2022 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/sklearn2java/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 scikit-learn 모델을 JAVA에서 구동 시켜야 한다. 크게 3가지 방법론이 존재한다.(원문 참조 : Moving from Python to Java to deploy your machine learning model to production embed : Java 코드 내에서 직접 Python 코드 구현 방법.</description>
    </item>
    
    <item>
      <title>Oracle CSV File Upload using CMD</title>
      <link>https://dschloe.github.io/sql/oracle_csv_upload/</link>
      <pubDate>Fri, 22 Jul 2022 14:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/oracle_csv_upload/</guid>
      <description>개요 iris.csv 파일을 오라클 명령어를 통해서 업로드를 진행한다. 대부분의 명령어는 터미널에서 처리하였다. SQLPLUS 접속 SQL에 접속한다. 테이블 생성 터미널에서 iris 테이블을 생성한다. CREATE TABLE iris ( sepal_length INTEGER, sepal_width INTEGER, petal_length INTEGER, petal_width INTEGER, species varchar2(20) ); ctl 파일 생성 메모장에 아래와 같이 ctl 파일을 생성한다. 파일명은 control.ctl이다. LOAD DATA INFILE &amp;#39;iris.csv&amp;#39; INTO TABLE iris fields terminated by &amp;#39;,&amp;#39; ( sepal_length, sepal_width, petal_length, petal_width, species ) 파일 업로드 sqlplus 접속을 종료한다.</description>
    </item>
    
    <item>
      <title>MLFlow with Scikit-Learn</title>
      <link>https://dschloe.github.io/python/python_edu/08_mlops/mlflow_with_sklearn/</link>
      <pubDate>Mon, 11 Jul 2022 10:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/08_mlops/mlflow_with_sklearn/</guid>
      <description>개요 Scikit-Learn 모델을 만든 후, MLFlow로 모델을 배포한다. 머신러닝 코드에 대한 설명은 생략한다. 가상환경 설정에 관한 내용도 생략한다. 라이브러리 불러오기 기존 코드에서 mlflow 라이브러리만 추가한다. %matplotlib inline import numpy as np import pandas as pd import matplotlib as mpl import matplotlib.pyplot as plt import sklearn import seaborn as sns import mlflow import mlflow.sklearn from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split, KFold from sklearn.preprocessing import StandardScaler from sklearn.metrics import roc_auc_score, plot_roc_curve, confusion_matrix print(f&amp;#34;numpy version {np.</description>
    </item>
    
    <item>
      <title>주요 핵심 머신러닝 리뷰</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/ch04_main_ml_models/</link>
      <pubDate>Wed, 06 Jul 2022 10:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/ch04_main_ml_models/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 수강생들의 머신러닝을 활용한 웹 개발 프로젝트 전 복습 차원에서 준비함. 주 내용은 주요 참고자료를 기반으로 작성하였으며, 참고자료에 없는 코드는 직접 작성하였음을 밝힘. 가장 인기 있는 모델 XGBoost와 LightGBM 그 외, 선형회귀, 로지스틱 회귀, 결정 트리, 앙상블 학습, 랜덤 포레스트, XGBoost, LightGBM 선형 회귀 선형 회귀식을 활용한 모델 회귀 계수와 절편을 찾는 것이 중요 기초통계에서 다루는 선형 회귀와 기본적인 개념에서는 동일하나, 기초통계에서와 예측 모델에서의 쓰임새는 다르다는 것을 기억한다.</description>
    </item>
    
    <item>
      <title>django Web 개발 - IRIS Prediction</title>
      <link>https://dschloe.github.io/python/django/django_iris_sklearn/</link>
      <pubDate>Sat, 25 Jun 2022 10:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/django/django_iris_sklearn/</guid>
      <description>개요 Python Django와 Sklearn을 활용하여 간단한 iris prediction 웹을 만들어본다. 사전준비 머신러닝 기본 이론 및 원리는 어느정도 알고 있다고 가정한다. Django 앱에 대해 어느정도 알고 있다고 가정한다. 무엇을 배우는가? 머신러닝 모델을 활용하여 배포하는 과정을 배운다. 가상환경 설정 가상환경을 생성한다. $ virtualenv venv created virtual environment CPython3.9.1.final.0-64 in 475ms creator CPython3Posix(dest=/Users/evan/Desktop/django-iris-tutorial/venv, clear=False, no_vcs_ignore=False, global=False) seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/Users/evan/Library/Application Support/virtualenv) added seed packages: pip==22.1.1, setuptools==62.3.2, wheel==0.37.1 activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator 만들어진 가상환경에 접속한다.</description>
    </item>
    
    <item>
      <title>MySQL Database 생성 및 권한 부여</title>
      <link>https://dschloe.github.io/settings/mysql_database_creation/</link>
      <pubDate>Sun, 19 Jun 2022 09:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/mysql_database_creation/</guid>
      <description>개요 MySQL 관리자 계정인 root로 DB 관리시스템에 접속 후 DB를 생성한다. 사전준비 MySQL 설치 및 환경변수를 설정한다. 참조 : https://dschloe.github.io/settings/mysql_installation_windows11/ DB 생성 콘솔창에서 MySQL 명령을 실행한다. C:\Users\your_name&amp;gt;mysql -uroot -p Enter password: **** Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 19 Server version: 8.0.28 MySQL Community Server - GPL Copyright (c) 2000, 2022, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates.</description>
    </item>
    
    <item>
      <title>MySQL 설치 및 환경변수 설정 Windows 11</title>
      <link>https://dschloe.github.io/settings/mysql_installation_windows11/</link>
      <pubDate>Sat, 18 Jun 2022 09:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/mysql_installation_windows11/</guid>
      <description>개요 Windows 11에 MySQL을 설치합니다. MySQL 챗봇 시스템의 학습 데이터 관리 위해 MySQL을 사용함 설치 주소 : https://dev.mysql.com/downloads/ MySQL Installer for Windows 파일을 선택함 MSI Installer를 다운로드 받는다. 다운로드 받은 파일을 순차적으로 설치 한다. 비밀번호는 잃어버리면 안된다. (비번 : 1234) 앞서 설정한 비밀번호를 입력하고 체크 버튼을 누른다. 정상적으로 설치가 완료되었다. 윈도우에서 돋보기 모양을 누른 후, MySQL 8.0 Command Line Client를 클릭한다. root 계정 비밀번호를 입력 후 접속한다. 비밀번호 1234를 클릭한다. 환경변수 설정 환경변수 설정을 하지 않으면 cmd 명령어 창에서 mysql 명령어를 사용할 수 없다.</description>
    </item>
    
    <item>
      <title>S3 with Python Basic Tutorial</title>
      <link>https://dschloe.github.io/aws/04_s3/s3_basic/</link>
      <pubDate>Mon, 30 May 2022 10:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/04_s3/s3_basic/</guid>
      <description>Bucket 만들기 Bucket을 만들어보도록 한다. import boto3 print(boto3.__version__) 1.23.5 bucket = boto3.resource(&amp;#39;s3&amp;#39;) response = bucket.create_bucket( Bucket = &amp;#34;your_bucket_name&amp;#34;, ACL=&amp;#34;private&amp;#34;, # public-read CreateBucketConfiguration = { &amp;#39;LocationConstraint&amp;#39; : &amp;#39;ap-northeast-2&amp;#39; } ) print(response) s3.Bucket(name=&#39;your_bucket_name&#39;) 버킷 대시보드에서 실제 Bucket이 만들어졌는지 확인한다. Client Bucket 이번에는 client 버킷을 생성한다. client = boto3.client(&amp;#39;s3&amp;#39;) response = client.create_bucket( Bucket = &amp;#34;your_bucket_name&amp;#34;, ACL = &amp;#34;private&amp;#34;, CreateBucketConfiguration = { &amp;#39;LocationConstraint&amp;#39; : &amp;#39;ap-northeast-2&amp;#39; } ) print(response) {&#39;ResponseMetadata&#39;: {&#39;RequestId&#39;: &#39;1X0BAXRG653Q7Y61&#39;, &#39;HostId&#39;: &#39;WwKyxNBcd1V9x6D/WZn8twMKSWKBnkwVCPWtvarZvyNSSvqr7Q77J6OFAdWuYAwiv/nQfXoW/0U=&#39;, &#39;HTTPStatusCode&#39;: 200, &#39;HTTPHeaders&#39;: {&#39;x-amz-id-2&#39;: &#39;WwKyxNBcd1V9x6D/WZn8twMKSWKBnkwVCPWtvarZvyNSSvqr7Q77J6OFAdWuYAwiv/nQfXoW/0U=&#39;, &#39;x-amz-request-id&#39;: &#39;1X0BAXRG653Q7Y61&#39;, &#39;date&#39;: &#39;Wed, 25 May 2022 03:16:52 GMT&#39;, &#39;location&#39;: &#39;http://your_bucket_name.</description>
    </item>
    
    <item>
      <title>Google Adsense with Hugo</title>
      <link>https://dschloe.github.io/settings/googleads/</link>
      <pubDate>Sun, 29 May 2022 09:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/googleads/</guid>
      <description>동기부여 블로그 광고수익 비교 글을 보게 되었다. 그런데, 현재 운영중인 이 블로그의 일일 방문자수가 300-400명이어서 방치하면 안될 것 같았다. 간단하게 Google Adsense를 Hugo Website에 추가하도록 한다.
사전준비 먼저 Hugo Website는 Google Analytics와 미리 연동이 되어 있어야 한다. 참조 : Hugo 블로그에 Google analytics 추가하기 Google Adsense 우선 Google Adsense에 접속한다.
Google Ads에서 아래 그림과 같이 사이트를 클릭한다. 사이트 추가 버튼을 누른다. 본인의 블로그 URL을 추가한다. HTML Tag를 복사하고, 검토 요청 버튼을 클릭한다.</description>
    </item>
    
    <item>
      <title>IAM User Practice</title>
      <link>https://dschloe.github.io/aws/01_settings/iam_users/</link>
      <pubDate>Sat, 28 May 2022 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/01_settings/iam_users/</guid>
      <description>라이브러리 불러오기 기 설치된 라이브러리를 불러오도록 한다. import boto3 print(boto3.__version__) 1.23.5 IAM User 관련 주요 코드 다음 코드는 유저를 생성하는 코드이다. def create_user(username): iam = boto3.client(&amp;#39;iam&amp;#39;) response = iam.create_user(UserName=username) print(response) create_user(&amp;#39;testuser2fromwsl2&amp;#39;) {&#39;User&#39;: {&#39;Path&#39;: &#39;/&#39;, &#39;UserName&#39;: &#39;testuser2fromwsl2&#39;, &#39;UserId&#39;: &#39;AIDAVRRRQ3HFXFQPOOY7Q&#39;, &#39;Arn&#39;: &#39;arn:aws:iam::381282212299:user/testuser2fromwsl2&#39;, &#39;CreateDate&#39;: datetime.datetime(2022, 5, 24, 5, 30, 6, tzinfo=tzutc())}, &#39;ResponseMetadata&#39;: {&#39;RequestId&#39;: &#39;d5fa242b-9aa9-4ad9-a75a-ed23e041d4ba&#39;, &#39;HTTPStatusCode&#39;: 200, &#39;HTTPHeaders&#39;: {&#39;x-amzn-requestid&#39;: &#39;d5fa242b-9aa9-4ad9-a75a-ed23e041d4ba&#39;, &#39;content-type&#39;: &#39;text/xml&#39;, &#39;content-length&#39;: &#39;495&#39;, &#39;date&#39;: &#39;Tue, 24 May 2022 05:30:05 GMT&#39;}, &#39;RetryAttempts&#39;: 0}} 이번에는 모든 사용자를 가져오는 코드를 작성한다.</description>
    </item>
    
    <item>
      <title>AWS 개발환경 설정 - WSL2 &amp; S3 &amp; RDS</title>
      <link>https://dschloe.github.io/aws/01_settings/settings/</link>
      <pubDate>Thu, 26 May 2022 10:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/01_settings/settings/</guid>
      <description>개요 윈도우 WSL2에서 AWS 개발을 위한 기본 개발환경 설정을 진행한다. WSL2 설치 WSL2 설치 및 사용법은 다음 링크를 통해서 확인한다. (여기서 설치법은 다루지 않는다!) URL : https://www.lainyzine.com/ko/article/how-to-install-wsl2-and-use-linux-on-windows-10/ Restart WSL2 WSL2 처음 작업할 때, 실행한다. exec $SHELL WSL2 주요 필수 패키지 설치 Python 3.8 버전을 설치한다. sudo apt update sudo apt install software-properties-common sudo add-apt-repository ppa:deadsnakes/ppa sudo apt install python3.7 Python 버전은 다음과 같다. $ python3 --version Python 3.8.10 만약 Python 버전 변경이 안되면 전체 삭제하고 진행한다.</description>
    </item>
    
    <item>
      <title>Django with Elastic Beanstalk - Settings</title>
      <link>https://dschloe.github.io/aws/03_elastic_beanstalk/ch01_eb_django_settings/</link>
      <pubDate>Sun, 22 May 2022 10:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/03_elastic_beanstalk/ch01_eb_django_settings/</guid>
      <description>한줄 요약 생각보다 쉽지 않기 때문에 Windows로 하기 보다는 WSL2로 하는 것을 권한다. 이 부분은 추후 업데이트 할 예정이다. Windows에 EB CLI 설치 공식 문서 : https://docs.aws.amazon.com/ko_kr/elasticbeanstalk/latest/dg/eb-cli3-install-windows.html
우선 기존 아나콘다로 파이썬 환경이 구축되어 있다면, 아나콘다를 삭제하고 진행한다.
3.8 버전 이상으로 하면, 배포 시 생각보다 잘 되지 않을 가능성이 크다. 필자는 Python 버전도 3.7로 재 설치 했다.
C:\WINDOWS\system32&amp;gt;python --version Python 3.7.4 C:\WINDOWS\system32&amp;gt;pip --version pip 19.0.3 from c:\users\human\appdata\local\programs\python\python37-32\lib\site-packages\pip (python 3.7) pip을 이용하여 EB CLI를 설치한다.</description>
    </item>
    
    <item>
      <title>[Python] 카카오톡 챗봇 오픈빌더를 활용한 사칙연산 계산기 구현</title>
      <link>https://dschloe.github.io/python/kakao_chatbot/chatbot_calculator/</link>
      <pubDate>Mon, 16 May 2022 14:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/kakao_chatbot/chatbot_calculator/</guid>
      <description>읽기 전 공지 본 글은 2022년 11월 28일까지만 유효합니다. 무료 버전이 사라지기 때문에, 앞으로 어떻게 될지는 현재 글 쓰는 시점에서는 모릅니다. 이 부분에 주의해서 참고 하시기를 바랍니다. 개요 카카오톡 챗봇 만들기를 Python + FLASK를 통해 간단한 튜토리얼을 만들어본다. 사전준비 OBT 참여승인을 받아야 한다. 기본설정 카카오톡 챗봇 버튼 클릭 후, 봇 이름 생성 [봇 만들기] - [카카오톡 챗봇] 카카오톡 채널 연결을 진행한다. virtualenv를 활용하여 가상환경을 설정한다.
$ virtualenv venv created virtual environment CPython3.</description>
    </item>
    
    <item>
      <title>Python Selenium Crawling Tutorial</title>
      <link>https://dschloe.github.io/python/crawling/python_selenium_crawling/</link>
      <pubDate>Mon, 09 May 2022 20:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/crawling/python_selenium_crawling/</guid>
      <description>강의소개 인프런에서 Streamlit 관련 강의를 진행하고 있습니다. 인프런 : https://inf.run/YPniH 개요 크롬 드라이버를 활용하여 Selenium을 설치한다. 네이버 평점에서 특정 영화(노트북)를 관람한 관람객이 영화에 댓글을 단 영화 수집 크롬 드라이버 설치 자신의 크롬 버전과 같은 버전을 설치한다. 오른쪽 상단에서 더보기를 클릭한다. 도움말 &amp;gt; Chrome 정보를 클릭한다. 이번에는 크롬 드라이버를 다운로드 받는다. 사이트 주소 : https://chromedriver.chromium.org/downloads 다운로드 받은 파일은 C드라이브 하단에 chatbot 폴더에 위치시킨다. URL : C:\chatbot 라이브러리 설치 chatbot 프로젝트를 생성하고, 가상환경을 추가한다 (추가 내용 생략).</description>
    </item>
    
    <item>
      <title>django Web 개발 1 - 기본 설정</title>
      <link>https://dschloe.github.io/python/django/django_01/</link>
      <pubDate>Sat, 07 May 2022 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/django/django_01/</guid>
      <description>프로젝트 개요 Python Django로 To-do List를 만들어본다. 파이썬 설치 파이썬 설치는 Anaconda 또는 Python 홈페이지에서 직접 설치한다. Anaconda : https://www.anaconda.com/ Python : https://www.python.org/ 가상환경 설치 파이썬 설치가 끝났다면, 해당 깃허브를 다운로드 받는다. $ git clone https://github.com/dschloe/django_to_do.git django_to_do 폴더에 진입 후 아래와 같이 실행한다. $ cd django_to_do $ virtualenv venv created virtual environment CPython3.9.7.final.0-64 in 7884ms creator CPython3Windows(dest=C:\Users\human\Desktop\django_to_do\venv, clear=False, no_vcs_ignore=False, global=False) seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=C:\Users\human\AppData\Local\pypa\virtualenv) added seed packages: pip==22.</description>
    </item>
    
    <item>
      <title>카카오톡 오픈 빌더 챗봇 만들기 1편</title>
      <link>https://dschloe.github.io/settings/kakaotalk_open_builder_01/</link>
      <pubDate>Sat, 30 Apr 2022 21:14:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/kakaotalk_open_builder_01/</guid>
      <description>개요 카카오톡 오픈 빌더 챗봇을 만드는 과정을 보여준다. 회원가입이 필요할 수 있다. 카카오톡 채널을 만든다. 등록하기 구글 검색창에서 카카오톡 오픈 빌더를 검색한다.. 로그인을 하도록 한다.. 챗봇 관리자센터 OBT 참여 신청 메뉴가 나오는지 확인한다. 카카오톡 채널 관리자 가입 카카오톡 관리자 채널에서 새로운 채널을 만든다.. URL : https://center-pf.kakao.com/ 아래 화면에서 새 채널 만들기를 클릭한다. 채널을 개설한다. 프로필 사진, 소개글은 추후에 작성이 가능하다. 작성이 끝나면 확인 버튼을 클릭한다. 이상이 없다면, ‘네, 입력한 정보로 개설하겠습니다.</description>
    </item>
    
    <item>
      <title>Visual Studio Code Oracle 연동</title>
      <link>https://dschloe.github.io/sql/vscode_oracle/</link>
      <pubDate>Tue, 26 Apr 2022 00:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/vscode_oracle/</guid>
      <description>개요 VSCode에서 오라클을 연동하는 코드를 작성해본다. Extension Extension에서 Oracle을 검색 후, 설치를 진행한다. 설치 중간에 아래와 같은 문구가 나오면 해당 파일을 설치해야 한다. 필수 설치 파일 설치 URL은 다음과 같다. URL : https://www.oracle.com/database/technologies/appdev/dotnet/install-dotnetcore-windows.html 위 그림에서 Install .NET Runtime for Windows x64를 클릭하면 아래 화면과 함께 설치 파일이 다운로드 된다. 설치 파일을 클릭하면 아래와 같은 설치 관리자가 등장한다. 특별하게 고려할 것은 없다. 정상적으로 설치가 되면 아래와 같은 화면이 나오면 설치는 종료가 된 것이다.</description>
    </item>
    
    <item>
      <title>PyCharm Oracle 연동</title>
      <link>https://dschloe.github.io/sql/pycharm_oracle/</link>
      <pubDate>Mon, 25 Apr 2022 14:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/pycharm_oracle/</guid>
      <description>개요 PyCharm에서 Oracle과 연동하는 방법에 대해 작성한다. Database Navigator 설치 Project 폴더에서 File - Settings - Plugins를 실행한다. 검색창에 Database를 입력한다. Database Navigator를 선택한다. 설치가 완료되면, Restart IDE 창이 활성화가 될 것이다. PyCharm을 재 시작한다. DB Navigator 실행 상단 메뉴창에서 DB Navigator를 선택한다. 새로운 데이터베이스 버튼을 클릭한 후, Oracle을 선택한다. 필수 입력값을 입력 한 후, Test Connection을 실행하여 정상적으로 연동이 되었는지 확인한다. SQL 테스트 이제 새로운 파일을 열고 쿼리 테스트를 진행해본다.</description>
    </item>
    
    <item>
      <title>SQL Developer with Git</title>
      <link>https://dschloe.github.io/sql/sql_developer_git/</link>
      <pubDate>Sun, 24 Apr 2022 10:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/sql_developer_git/</guid>
      <description>개요 SQL Developer에서 깃헙과 연동하는 방법을 알려준다. 깃허브 회원가입 및 깃 설치는 이미 된 것으로 가정한다. 새로운 Repository를 만든다. 필자는 oracle_lectures라는 Repository를 만들었다. SQL Developer에서 필요한 작업 이제 SQL Developer 프로그램을 연다. 팀 - Git - 복제 순으로 순차적으로 연다. 아래 화면에서 다음을 클릭한다. 아래 화면에서 새로 생성한 URL, Username, Password를 순차적으로 입력한다. 이 때, Repo 생성 시, Private으로 되어 있었다면 인증 에러가 생길 수 있다. 그런 경우 Public으로 변경한다. 아래 화면에서 main을 선택 후, 다음을 클릭한다.</description>
    </item>
    
    <item>
      <title>오라클 19c 기본 세팅</title>
      <link>https://dschloe.github.io/sql/oracle_basic_settings/</link>
      <pubDate>Sat, 23 Apr 2022 14:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/oracle_basic_settings/</guid>
      <description>1단계 sqlplus 실행하기 설치가 끝난 후, 윈도우에서 sqlplus 입력 사용자명은 system, 비밀번호는 오라클 설치 시 (1234)] 주의 : 관리자로 실행 2단계 : 테이블스페이스 생성하기 테이블스페이스는 myts라는 이름으로 100MB 크기로 생성 만약 데이터가 증가하면 5MB씩 자동 증가 옵션 추가 생성 구문은 다음과 같음 SQL&amp;gt; CREATE TABLESPACE myts DATAFILE &amp;#39;C:\oracle\oradata\MYORACLE\myts.dbf&amp;#39; SIZE 100M AUTOEXTEND ON NEXT 5M; 테이블스페이스가 생성되었습니다. 3단계 : 사용자 생성 사용자를 생성하는 코드를 작성한다. SQL&amp;gt; CREATE USER ora_user IDENTIFIED BY evan DEFAULT TABLESPACE MYTS TEMPORARY TABLESPACE TEMP; 사용자가 생성되었습니다.</description>
    </item>
    
    <item>
      <title>오라클 삭제 - Windows</title>
      <link>https://dschloe.github.io/sql/oracle_deinstallation/</link>
      <pubDate>Fri, 22 Apr 2022 14:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/oracle_deinstallation/</guid>
      <description>개요 오라클 설치가 제대로 안되는 경우가 왕왕 있다. 이럴 경우, 삭제 후 재설치하는 것을 권장한다. 1단계 : 오라클 서비스 중지시키기 제어판 - 시스템 및 보안 - 관리도구 - 서비스 메뉴를 실행해 Oracle로 시작되는 모든 서비를 중지시킨다. 또는 윈도우 검색창에서 서비스를 검색해도 앱에 접근할 수 있다. 2단계 : 삭제 시동 파일 실행하기 오라클 설치 폴더 - deinstall 폴더에서 deinstall.bat 파일을 관리자 권한으로 실행한다. 이름 목록 지정화면에서 설치 시 지정했던 전역데이터베이스 이름을 입력하고, 계속하겠습니까?</description>
    </item>
    
    <item>
      <title>Spark Tutorial - Web UI on WSL</title>
      <link>https://dschloe.github.io/settings/spark_tutorial_web_ui/</link>
      <pubDate>Thu, 21 Apr 2022 12:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/spark_tutorial_web_ui/</guid>
      <description>개요 간단하게 Spark Tutorial을 활용하여 Web UI를 가동한다. Spark Submit을 활용한다. 파이썬 가상환경 파이썬 가상환경을 작성한다. (필자의 경로는 pyskt_tutorial) $ pwd /mnt/c/hadoop/pyskt_tutorial 가상환경을 생성한다. evan@evan:/mnt/c/hadoop/pyskt_tutorial$ virtualenv venv 생성된 가상환경에 접속한다. evan@evan:/mnt/c/hadoop/pyskt_tutorial$ source venv/bin/activate (venv) evan@evan:/mnt/c/hadoop/pyskt_tutorial$ PySpark 설치 pyspark를 설치한다. (venv) evan@evan:/mnt/c/hadoop/pyskt_tutorial$ pip install pyspark Requirement already satisfied: pyspark in ./venv/lib/python3.8/site-packages (3.2.1) Requirement already satisfied: py4j==0.10.9.3 in ./venv/lib/python3.8/site-packages (from pyspark) (0.10.9.3) 데이터 생성 가상의 데이터를 생성한다. 소스파일과 구분 위해 data 폴더를 만든 후, 마크다운 파일을 하나 만들 것이다.</description>
    </item>
    
    <item>
      <title>WSL2에서의 Spark 설치</title>
      <link>https://dschloe.github.io/settings/spark_install_using_wsl/</link>
      <pubDate>Tue, 19 Apr 2022 12:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/spark_install_using_wsl/</guid>
      <description>개요 간단하게 PySpark를 설치해보는 과정을 작성한다. WSL2 설치 방법은 다루지 않는다. 필수 파일 설치 자바 및 Spark 파일을 설치하도록 한다. $ sudo apt-get install openjdk-8-jdk $ sudo wget https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz $ sudo tar -xvzf spark-3.2.0-bin-hadoop3.2.tgz .bashrc 파일 수정 필자의 현재 경로는 다음과 같다. evan@evan:/mnt/c/hadoop$ pwd /mnt/c/hadoop 설치한 파일은 다음과 같다. evan@evan:/mnt/c/hadoop$ ls spark-3.2.0-bin-hadoop3.2 spark-3.2.0-bin-hadoop3.2.tgz vi ~/.bashrc 파일을 열고 다음과 같이 코드를 작성한다. 다른 코드는 만지지 않는다. 가장 맨 마지막으로 내려온다. export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 export SPARK_HOME=/mnt/c/hadoop/spark-3.</description>
    </item>
    
    <item>
      <title>PyCaret Kaggle Notebook (Since April 10, 2022)</title>
      <link>https://dschloe.github.io/kaggle/pycaret_kaggle_test/</link>
      <pubDate>Mon, 18 Apr 2022 23:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/pycaret_kaggle_test/</guid>
      <description>개요 PyCaret이 최근 업데이트 되면서 Kaggle에서 설치 오류가 뜨기 시작함. 메인 홈페이지 : https://pycaret.gitbook.io/docs/ 해결책은 몇가지 있으나, 그 중 Downgrade 해서 설치 할 예정 캐글 대회 시작 캐글 노트북 시작을 하면 다음 코드가 나타난다. 다음 Cell부터 진행한다. # This Python 3 environment comes with many helpful analytics libraries installed # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here&amp;#39;s several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.</description>
    </item>
    
    <item>
      <title>Hugo 깃허브 블로그 - Windows (2022)</title>
      <link>https://dschloe.github.io/settings/hugo_github_windows/</link>
      <pubDate>Sun, 17 Apr 2022 15:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/hugo_github_windows/</guid>
      <description>패키지 관리자 설치 Chocolatey (Windows) If you are on a Windows machine and use Chocolatey for package management, you can install Hugo with the following one-liner: 우선 PowerShell을 관리자로 실행 후, 아래와 같이 Chocolately를 설치한다. 명령어 : Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(&#39;[https://community.chocolatey.org/install.ps1](https://community.chocolatey.org/install.ps1)&#39;)) Windows PowerShell Copyright (C) Microsoft Corporation. All rights reserved. 새로운 크로스 플랫폼 PowerShell 사용 https://aka.ms/pscore6 PS C:\WINDOWS\system32&amp;gt; Set-ExecutionPolicy Bypass -Scope Process -Force; [System.</description>
    </item>
    
    <item>
      <title>Airflow 데이터 파이프라인 구축 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json_sample/</link>
      <pubDate>Thu, 14 Apr 2022 21:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json_sample/</guid>
      <description>개요 이번에는 CSV-JSON으로 데이터를 변환하는 파이프라인을 구축하도록 한다. Step 01. Dags 폴더 생성 프로젝트 Root 하단에 Dags 폴더를 만든다. dags 폴더를 확인한다. $ ls airflow.cfg airflow.db dags logs venv webserver_config.py Step 02. 가상의 데이터 생성 이번 테스트에서 사용할 라이브러리가 없다면 우선 설치한다. $ pip3 install faker pandas faker 라이브러리를 활용하여 가상의 데이터를 생성한다. (파일 경로 : data/step01_writecsv.py) from faker import Faker import csv output=open(&amp;#39;data.csv&amp;#39;,&amp;#39;w&amp;#39;) fake=Faker() header=[&amp;#39;name&amp;#39;,&amp;#39;age&amp;#39;,&amp;#39;street&amp;#39;,&amp;#39;city&amp;#39;,&amp;#39;state&amp;#39;,&amp;#39;zip&amp;#39;,&amp;#39;lng&amp;#39;,&amp;#39;lat&amp;#39;] mywriter=csv.writer(output) mywriter.writerow(header) for r in range(1000): mywriter.</description>
    </item>
    
    <item>
      <title>R Selenium 설치 가이드 (Windows)</title>
      <link>https://dschloe.github.io/r/r_settings/r_selenium/</link>
      <pubDate>Wed, 13 Apr 2022 17:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/r_settings/r_selenium/</guid>
      <description>개요 R에서 Selenium을 설치하는 과정을 보여준다. 우선 자바가 설치되어 있는지 확인한다. 유투브에서 제목만 가져오는 Demo 코드를 작성한다. 자바를 모르시는 분 만약 자바 설치를 해본적이 없다면 아래 코드를 순차적으로 입력한다. install.packages(&amp;#34;multilinguer&amp;#34;) library(multilinguer) install_jdk() # Rtools 설치 필요 # https://cran.r-project.org/bin/windows/Rtools write(&amp;#39;PATH=&amp;#34;${RTOOLS40_HOME}\\usr\\bin;${PATH}&amp;#34;&amp;#39;, file = &amp;#34;~/.Renviron&amp;#34;, append = TRUE) Sys.which(&amp;#34;make&amp;#34;) install.packages(c(&amp;#34;stringr&amp;#34;, &amp;#34;hash&amp;#34;, &amp;#34;tau&amp;#34;, &amp;#34;Sejong&amp;#34;, &amp;#34;RSQLite&amp;#34;, &amp;#34;devtools&amp;#34;), type = &amp;#34;binary&amp;#34;) install.packages(&amp;#34;remotes&amp;#34;) remotes::install_github(&amp;#34;haven-jeon/KoNLP&amp;#34;, upgrade = &amp;#34;never&amp;#34;, INSTALL_opts = c(&amp;#34;--no-multiarch&amp;#34;)) library(KoNLP) useNIADic() 마지막 코드에서 콘솔창이 보인다면 정상적으로 설치가 완료가 된 것이다.</description>
    </item>
    
    <item>
      <title>Apache NiFi 설치와 설정 in WSL2</title>
      <link>https://dschloe.github.io/settings/apache_nifi_wsl2/</link>
      <pubDate>Tue, 12 Apr 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/apache_nifi_wsl2/</guid>
      <description>설치 wsl2에서 JAVA 설치 한다. $ sudo apt-get update &amp;amp;&amp;amp; sudo apt-get upgrade $ sudo apt install openjdk-11-jre-headless $ vi ~/.bash_profile export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 curl을 이용해서 NiFi를 현재 경로에 내려받는다. $ sudo wget https://downloads.apache.org/nifi/1.16.0/nifi-1.16.0-bin.tar.gz .tar.gz 파일의 압축을 푼다. $ sudo tar xvzf nifi-1.16.0-bin.tar.gz 압축파일을 푼 다음에는 cd nifi-1.16.0 폴더에 접속을 한다. $ cd nifi-1.16.0/bin ls를 실행해서 nifi-env.sh 파일이 있는지 확인하고 있다면, vi 에디터로 연다. .bash_profile에서 한 것처럼 동일하게 자바 환경변수를 잡아준다. $ sudo vi nifi-env.</description>
    </item>
    
    <item>
      <title>Convert Plotly Jupyterlab to HTML</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/plotly_convert_html/</link>
      <pubDate>Tue, 12 Apr 2022 00:02:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/plotly_convert_html/</guid>
      <description>개요 jupyter notebook에서 plotly 기반의 시각화를 작성한다. jupyter notebook에서 html로 변환 시, plotly로 작성된 코드는 나타나지 않았다. 이 때 필수적으로 입력해야 할 코드를 작성한다. 필수 코드 적용 전 변환 시 간단한 시각화 코드를 작성 후, html로 변환한다. import plotly.express as px fig = px.line(x=[&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;], y=[1,3,2], title=&amp;#34;sample figure&amp;#34;) fig.show() 아래 그림은 일반적으로 JupyterLab 에디터에서 HTML로 변환하는 과정이다. File - Save and Export Notebook As&amp;hellip; - HTML 순차적으로 클릭한다. 그런데, HTML로 변환된 파일을 클릭하면, 위 코드에서 보였던 코드는 안 보이게 된다.</description>
    </item>
    
    <item>
      <title>ElasticSearch &amp; Kibana 설치 in WSL2</title>
      <link>https://dschloe.github.io/settings/elasticsearch_kibana_wsl2/</link>
      <pubDate>Mon, 11 Apr 2022 11:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/elasticsearch_kibana_wsl2/</guid>
      <description>Step 1. 사전 필수 패키지 설치 우선 시스템 패키지를 업데이트 하고, HTTPS와 관련된 패키지를 설치한다. $ sudo apt update $ sudo apt install apt-transport-https 자바를 설치한다. 이미 설치가 되어 있다면 버전만 확인한다. $ sudo apt install openjdk-11-jdk 설치한 버전을 확인한다. $ java -version openjdk version &amp;#34;11.0.14.1&amp;#34; 2022-02-08 OpenJDK Runtime Environment (build 11.0.14.1+1-Ubuntu-0ubuntu1.20.04) OpenJDK 64-Bit Server VM (build 11.0.14.1+1-Ubuntu-0ubuntu1.20.04, mixed mode, sharing) 자바 환경 변수를 설정하기 위해 아래와 같이 에디터를 입력한다. $ sudo vi /etc/environment 그리고 아래와 같이 추가한다.</description>
    </item>
    
    <item>
      <title>PostgreSQL Installation on WSL2 and Windows</title>
      <link>https://dschloe.github.io/sql/postgreslq_wsl2/</link>
      <pubDate>Sun, 10 Apr 2022 14:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/postgreslq_wsl2/</guid>
      <description>개요 WSL2에서 PostgreSQL을 설치한다. pgAdmin은 Windows에 설치한다. 터미널 업그레이드 먼저 WSL 터미널을 열고, Ubuntu 패키지를 모두 업데이트 및 업그레이드를 한다. $ sudo apt update [sudo] password for evan: Hit:1 https://artifacts.elastic.co/packages/7.x/apt stable InRelease Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB] Hit:3 http://archive.ubuntu.com/ubuntu focal InRelease Get:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB] Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB] Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [1712 kB] Get:7 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [916 kB] Fetched 2963 kB in 5s (600 kB/s) Reading package lists.</description>
    </item>
    
    <item>
      <title>VSCode Remote WLS 연동</title>
      <link>https://dschloe.github.io/settings/vscode_wsl2/</link>
      <pubDate>Sat, 09 Apr 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/vscode_wsl2/</guid>
      <description>VSCode 설치 우선 VSCode를 설치한다. URL : https://code.visualstudio.com/download 이 때, 관리자로 실행할 것이기 때문에 System Installer를 다운로드 받는다. 설치 시, 환경변수 체크란만 잘 확인한다. 설치가 다 끝난 후에는 재부팅을 실시한다. Remote WSL 연동 Extension 버튼을 클릭한다. 검색창에서 Remote WSL을 검색 후, 설치를 진행한다. 모두 클릭 후, Mark Done을 선택한다. Open Folder를 클릭한다. WSL에서 설치했던 airflow-test 폴더를 선택한다. 해당 프로젝트를 열도록 한다. 메뉴바에 Terminal을 선택 후, 화면 하단에서 WSL이 있는지 확인한다. 해당 메뉴를 클릭하면 아래와 같이 터미널이 변경된 것을 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>Setting up Apache-NiFi in Windows 10</title>
      <link>https://dschloe.github.io/settings/apache_nifi_installation_windows/</link>
      <pubDate>Thu, 07 Apr 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/apache_nifi_installation_windows/</guid>
      <description>개요 윈도우에서 NiFi를 설치해본다. NiFi를 설치하기 위해서는 자바 설치가 필요하다. Step 01. NiFi 다운로드 먼저 웹사이트에 접속한다. URL : https://www.apache.org/dyn/closer.lua?path=/nifi/1.16.0/nifi-1.16.0-bin.zip /img/settings/apache_nifi_installation_windows
가장 먼저 나오는 링크를 클릭한다. URL : https://dlcdn.apache.org/nifi/1.16.0/nifi-1.16.0-bin.zip 다운로드 받은 파일의 압축을 풀도록 한다. Step 02. Java 환경 설정 Java 설치 내용은 아래 블로그를 참조한다. 참고자료 : https://maktony.tistory.com/13 Step 03. run-nifi 배치 파일 실행 run-nifi 배치파일을 관리자 권한으로 실행한다. 아래와 같은 메시지가 출력이 되면 성공한 것이다. Step 04. Web UI 확인 (약 1분이 지난 후) Web UI를 확인해본다.</description>
    </item>
    
    <item>
      <title>Setting up Apache-Airflow in Windows using WSL2</title>
      <link>https://dschloe.github.io/settings/apache_airflow_using_wsl2/</link>
      <pubDate>Wed, 06 Apr 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/apache_airflow_using_wsl2/</guid>
      <description>개요 Windows WSL2에서 airflow를 설치한다. Step 1. Install pip on WSL airflow를 설치하기 위해 pip를 설치한다. $ sudo apt install python3-pip [sudo] password for username: Step 2. Install virtualenv package virtualenv 라이브러리를 설치한다. $ sudo pip3 install virtualenv Step 3. Create a virtual environment C드라이브에 airflow-test 폴더를 생성한다. 해당 디렉터리로 이동한다. 이제 가상환경을 생성한다. $ virtualenv venv 가상환경에 접속을 한다. $ source venv/bin/activate 이번에는 .bashrc 파일을 수정한다. $ vi ~/.bashrc 파일을 연 후, 다음과 같은 코드를 추가한다.</description>
    </item>
    
    <item>
      <title>Windows 10 도커 설치 과정 (2022 ver)</title>
      <link>https://dschloe.github.io/settings/windows_docker_install/</link>
      <pubDate>Tue, 05 Apr 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/windows_docker_install/</guid>
      <description>개요 주요 참고자료는 다음과 같다. WSL2 설치 : https://www.lainyzine.com/ko/article/how-to-install-wsl2-and-use-linux-on-windows-10/#google_vignette 도커 설치 : https://www.lainyzine.com/ko/article/a-complete-guide-to-how-to-install-docker-desktop-on-windows-10/ Step 1. WSL2 설치 과정 Windows PowerShell 관리자로 실행 후 다음 명령어 입력 $ dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart $ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 위 명령어 실행 후, 재부팅 필수 x64 머신용 최신 WSL2 Linux 커널 업데이트 패키지를 다운로드 받아 안내에 따라 설치합니다. Windows Powershell 열고 아래 코드 실행 $ wsl --set-default-version 2 WSL 2와의 주요 차이점에 대한 자세한 내용은 https://aka.</description>
    </item>
    
    <item>
      <title>Scikit-Learn OneHot Encoding 다양한 적용 방법</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/one_hot_encoding_using_scikit_learn/</link>
      <pubDate>Sat, 02 Apr 2022 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/one_hot_encoding_using_scikit_learn/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 One-Hot Encoding 개념에 대해 이해한다. One-Hot Encoder 사용법을 익힌다. One-Hot Encoding One-Hot Encoding은 문자를 숫자로 변환하는 것이다. 먼저 그림을 보면서 이해하도록 한다. 머신러닝 알고리즘은 데이터가 모두 숫자인 것으로 이해하기 때문에 모두 변환해주어야 한다. OnetHotEncoder OneHotEncoder는 Scikit-Learn 라이브러리에 있는 클래스이다.</description>
    </item>
    
    <item>
      <title>Plot Tree 색상 변경</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/plot_tree_color_changes/</link>
      <pubDate>Thu, 31 Mar 2022 11:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/plot_tree_color_changes/</guid>
      <description>개요 skleran.tree.plot_tree의 색상을 바꿔보도록 한다. matplotlib 객체지향의 구조를 알면 어렵지(?) 않게 바꿀 수 있다. 간단하게 plot_tree 시각화를 구현해본다. 언제나 예제로 희생당하는 iris 데이터에게 애도를 표한다. 구글코랩에서 실행 시, 다음 코드를 실행하여 최신 라이브러리로 업그레이드 한다. !pip install -U matplotlib Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2) Collecting matplotlib Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB) [K |████████████████████████████████| 11.2 MB 27.0 MB/s [?25hRequirement already satisfied: kiwisolver&amp;gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.0) Requirement already satisfied: python-dateutil&amp;gt;=2.</description>
    </item>
    
    <item>
      <title>R 텍스트 마이닝 1일차 - 빅카인즈 데이터 수집</title>
      <link>https://dschloe.github.io/r/text_mining/r_text_mining_1_data_crawling/</link>
      <pubDate>Sun, 13 Mar 2022 17:38:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/text_mining/r_text_mining_1_data_crawling/</guid>
      <description>Step 01 - 빅카인즈 접속 후, 데이터 내려받기 싸이트 : https://www.bigkinds.or.kr/v2/news/index.do 해당 싸이트에서 키워드를 입력 한다. 이 때, 기간, 신문사 등을 선택할 수 있다. 필자는 키워드는 ‘사회적 경제’ 신문사는 국민일보, 조선일보, 중앙일보를 선택한다. 하단으로 내려 적용하기 버튼을 클릭한다. Step 03 - 분석 결과 및 시각화 탭을 클릭한다. 데이터 다운로드 탭 하단에 엑셀 다운로드 버튼을 클릭한다. 해당 파일에는 본문이 있지만, 보통 200자 내외로 짧게 요약이 되어 있다. Step 02 - 웹 크롤링 소스 코드 작성을 위한 사전 준비 먼저 기 다운로드 된 파일을 불러온다.</description>
    </item>
    
    <item>
      <title>Heroku App 배포</title>
      <link>https://dschloe.github.io/python/dash/heroku_app_deploy/</link>
      <pubDate>Wed, 23 Feb 2022 10:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/heroku_app_deploy/</guid>
      <description>개요 Heroku App을 배포하는 과정을 작성한다. 가장 중요한 것은 Git과 연동이 되어 있어야 한다. 깃허브 : https://github.com/ GIT : https://git-scm.com/ 이 부분에 대한 설치 과정은 생략한다. 배포하려는 프로젝트는 다음 링크에서 확인한다. 참고 : Python Sales Dashboard Using Dash and Plotly Procfile 생성 프로젝트 Root 디렉터리에 Procfile 을 생성한다. web: gunicorn index:server 이 때, index 파일명을 의미한다. 작업 파일 수정 index.py을 열고, 다음 코드를 추가한다. server = app.server 을 추가한다. app = dash.</description>
    </item>
    
    <item>
      <title>Python Sales Dashboard Using Dash and Plotly</title>
      <link>https://dschloe.github.io/python/dash/dash_sales_dashboard/</link>
      <pubDate>Sun, 13 Feb 2022 18:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/dash_sales_dashboard/</guid>
      <description>개요 Sales 데이터를 활용하여 대시보드를 만드는 과정을 제작한다. 기본 파이썬 코딩은 할 줄 안다는 전제하에 작성하며, 세부 내용이 필요하면 참고 자료를 확인할 것을 권한다. 윈도우 10에서 본 프로젝트를 수행하였다. Chapter 1. Github Repo 생성 필자는 Github 레포를 만들었다. (Repo 명: python_dash_sales) git clone을 통해서 로컬로 가져온다. $ git clone https://github.com/your_id/python_dash_sales.git Chapter 2. Python 프로젝트 생성 PyCharm을 주 에디터로 사용할 예정이다.
파이썬은 아나콘다로 설치하였고, 이 때 환경변수 설정은 잘 되어 있는지 확인한다.</description>
    </item>
    
    <item>
      <title>BigQuery ML을 사용한 펭귄 체중 예측</title>
      <link>https://dschloe.github.io/gcp/bigquery/04_bigqueryml/bigquery_ml_penguins_20220121/</link>
      <pubDate>Fri, 21 Jan 2022 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/04_bigqueryml/bigquery_ml_penguins_20220121/</guid>
      <description>개요 BigQuery ML을 소개한다. BigQuery ML을 사용하면, 머신러닝 모델을 만들고 또한 실행할 수 있다. 목표 BigQuery ML에서 CREATE MODEL 문을 사용하여 선형회귀 모델 만들기 ML.EVALUATE 함수를 사용하여 ML 모델 평가 ML.PREDICT 함수를 사용하여 ML 모델 예측 주의 사항 BigQuery 비용 관련된 문서는 다음과 같다. BigQuery 가격 책정: https://cloud.google.com/bigquery/pricing BigQuery 가격 책정**:** https://cloud.google.com/bigquery-ml/pricing 1단계: 데이터 세트 만들기 데이터 세트 ID에 bqml_practice 입력 데이터 위치로 미국 US 선택 나머지는 모두 Default로 설정한다. 2단계: 모델 만들기 데이터 소개 먼저 데이터를 소개한다.</description>
    </item>
    
    <item>
      <title>GCP Settings 2022 ver</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/gcp_settings_20220118/</link>
      <pubDate>Tue, 18 Jan 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/gcp_settings_20220118/</guid>
      <description>개요 GCP 빅쿼리를 연동하는 예제를 구현한다. 먼저 빅쿼리를 통해 데이터를 적재하는 예제를 확인한다. 구글 코랩에서 빅쿼리 데이터를 불러온다. 데이터 스튜디오에서 빅쿼리 데이터를 불러온다. 소개 빅쿼리를 소개하는 영상은 유투브에서 검색하면 매우 쉽게 확인할 수 있다. 영상 참조: 데이터 웨어하우스 끝판왕 BigQuery 어디까지 알고 계신가요 Google Cloud 회원가입 준비물 Google 계정 신용카드나 체크카드 (개인적으로 돈이 없는 체크카드 사용 권장) 구글 클라우드 사이트 접속 싸이트: https://cloud.google.com/ 무료 서버 받으려면 아래 화면에서 TRY IT FREE 를 클릭한다.</description>
    </item>
    
    <item>
      <title>Spark Installation on M1 Mac</title>
      <link>https://dschloe.github.io/python/python_edu/00_settings/spark_installation_on_m1_mac/</link>
      <pubDate>Wed, 05 Jan 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/00_settings/spark_installation_on_m1_mac/</guid>
      <description>사전준비 M1 Mac에서 스파크를 설치하는 과정을 소개 하려고 한다. 필자의 Python 버전은 아래와 같다. $ python --version Python 3.8.7 자바 설치 자바 설치는 아래에서 다운로드 받았다. URL: Java SE Development Kit 8u301 그 다음 자바 설치를 확정한다. $ java --showversion 만약 에러가 아래와 같은 에러가 발생한다면, 시스템 환경설정 - Java - 업데이트 항목을 순차적으로 클릭한다. $ java --showversion Error: Could not create the Java Virtual Machine. Error: A fatal exception has occurred.</description>
    </item>
    
    <item>
      <title>Spark Installation on Windows 10</title>
      <link>https://dschloe.github.io/python/python_edu/00_settings/spark_installation_windows_10/</link>
      <pubDate>Mon, 03 Jan 2022 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/00_settings/spark_installation_windows_10/</guid>
      <description>사전준비 스파크를 설치하는 과정은 소개 하려고 한다. 사전에 파이썬 3만 설치가 되어 있으면 된다. 만약, 파이썬이 처음이라면 Anaconda를 설치한다. 다운로드 전 필수 확인사항 스파크 설치 전에는 반드시 체크해야 하는 사항이 있다. (System Compatibility) 2022년 1월 기준은 아래와 같다. Get Spark from the downloads page of the project website. This documentation is for Spark version 3.2.0. Spark uses Hadoop’s client libraries for HDFS and YARN. Downloads are pre-packaged for a handful of popular Hadoop versions.</description>
    </item>
    
    <item>
      <title>PyCaret Installation on M1 Mac</title>
      <link>https://dschloe.github.io/python/python_edu/00_settings/pycaret_installation_on_m1_mac/</link>
      <pubDate>Fri, 31 Dec 2021 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/00_settings/pycaret_installation_on_m1_mac/</guid>
      <description>PyCaret Installation on M1 Mac 개요 M1 Mac에서 PyCaret을 설치하고 싶었다. PyCaret 은 AutoML 라이브러리이며, 단 몇줄의 코드로 복잡한 기계학습을 학습 및 비교할 수 있도록 구현한 코드라고 볼 수 있다. PyCaret 패키지: https://pycaret.org/ M1 Mac에서 해당 라이브러리를 사용하려면 크게 2가지 필수 전제 조건이 있다. LightGBM, XGboost 설치 1. PyCaret 설치 방법 일반 인텔 기반의 Mac의 설치는 매우 쉽다. (Intel Mac) $ brew install lightgbm 그러나, M1 Mac에서는 생각보다 쉽지 않다. 물론, Rosetta로 터미널을 바꾸면 Intel Mac 처럼 쓸 수 있다.</description>
    </item>
    
    <item>
      <title>PyCaret, Skorch Using Pipeline</title>
      <link>https://dschloe.github.io/python/machin_learning/pycaret_with_sktorch/</link>
      <pubDate>Tue, 28 Dec 2021 16:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/machin_learning/pycaret_with_sktorch/</guid>
      <description>개요 Scikit-Learn의 Pipeline은 강력하다. PyCaret, Skorch에도 사용이 가능하다. Google Colab에서 시도해보자. 필수 라이브러리 설치 pycaret을 설치 한 후에는 반드시 런타임 재시작을 클릭한다. !pip install pycaret Collecting pycaret Downloading pycaret-2.3.5-py3-none-any.whl (288 kB) . . Successfully installed Boruta-0.3 Mako-1.1.6 PyYAML-6.0 alembic-1.4.1 databricks-cli-0.16.2 docker-5.0.3 funcy-1.17 gitdb-4.0.9 gitpython-3.1.24 gunicorn-20.1.0 htmlmin-0.1.12 imagehash-4.2.1 imbalanced-learn-0.7.0 joblib-1.0.1 kmodes-0.11.1 lightgbm-3.3.1 mlflow-1.22.0 mlxtend-0.19.0 multimethod-1.6 pandas-profiling-3.1.0 phik-0.12.0 prometheus-flask-exporter-0.18.7 pyLDAvis-3.2.2 pycaret-2.3.5 pydantic-1.8.2 pynndescent-0.5.5 pyod-0.9.6 python-editor-1.0.4 querystring-parser-1.2.4 requests-2.26.0 scikit-learn-0.23.2 scikit-plot-0.3.7 scipy-1.5.4 smmap-5.0.0 tangled-up-in-unicode-0.1.0 umap-learn-0.</description>
    </item>
    
    <item>
      <title>Python with PostgreSQL - Create Database</title>
      <link>https://dschloe.github.io/python/python_edu/00_settings/postgresql_python/</link>
      <pubDate>Mon, 27 Dec 2021 17:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/00_settings/postgresql_python/</guid>
      <description>PostgreSQL 및 Python 연동 예제 다음 예제에서는 Python과 PostgreSQL이 연동되는 코드를 작성해본다. PostgreSQL 설치 방법은 다음 자료를 확인한다. https://dschloe.github.io/settings/postgresql_install_windows/ 라이브러리 설치 우선 설치를 진행한다. $ pip install psycopg2-binary Downloading psycopg2_binary-2.9.2-cp310-cp310-win_amd64.whl (1.2 MB) |████████████████████████████████| 1.2 MB 6.4 MB/s Installing collected packages: psycopg2-binary Successfully installed psycopg2-binary-2.9.2 현재 Database 확인 cmd 파일 창을 열고, 현재 DB 리스트를 확인한다. \list or l: 전체 databases 리스트를 조회한다. C:\Users\user&amp;gt;psql --username=postgres postgres 사용자의 암호: psql (13.5) 도움말을 보려면 &amp;#34;help&amp;#34;를 입력하십시오.</description>
    </item>
    
    <item>
      <title>Verifying Outlier Values</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/verifying_outliers2/</link>
      <pubDate>Sun, 19 Dec 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/verifying_outliers2/</guid>
      <description>이상값의 정의 다소 주관적이며(Somewhat Subjective), 특정 분포의 중심경향성, 퍼진 정도와 형태에 따라 밀접한 관련이 있다. 평균에서 표준편차보다 몇 배 더 떨어져 있다거나, 즉, 정규분포를 이루고 있지 않을 때 왜도 또는 첨도가 발생할 때 균등분포(Uniform Distribution)는, 발생할 확률이 모두 같다. 만약, 확진자수가 최소 1부터 최대 10,000,000까지 균등하게 분포한다면, 어떤 값도 이상값으로 고려하지 않는다. 이상값을 파악하려면, 반드시, 각 변수의 분포를 먼저 이해해야 한다. 라이브러리 및 데이터 불러오기 실습을 위한 데이터를 불러온다. import numpy as np import matplotlib.</description>
    </item>
    
    <item>
      <title>Finding Missing Values</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/finding_missing_values/</link>
      <pubDate>Sat, 18 Dec 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/finding_missing_values/</guid>
      <description>데이터 가져오기 pandas, numpy, matplotlib 라이브러리를 불러온다. 데이터를 불러온다. 데이터는 https://ourworldindata.org/coronavirus-source-data 에서 가져왔다. 2020년 6월 1일 기준이다. import pandas as pd covidtotals = pd.read_csv(&amp;#34;data/covidtotalswithmissings.csv&amp;#34;) print(covidtotals.head()) iso_code lastdate location total_cases total_deaths \ 0 AFG 2020-06-01 Afghanistan 15205 257 1 ALB 2020-06-01 Albania 1137 33 2 DZA 2020-06-01 Algeria 9394 653 3 AND 2020-06-01 Andorra 764 51 4 AGO 2020-06-01 Angola 86 4 total_cases_pm total_deaths_pm population pop_density median_age \ 0 390.589 6.602 38928341.</description>
    </item>
    
    <item>
      <title>결정 트리 학습 이론</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/decision_tree/</link>
      <pubDate>Thu, 09 Dec 2021 21:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/decision_tree/</guid>
      <description>개요 현대 머신러닝 이론의 백본(Backbone)이 되는 결정 트리에 대해 이론적으로 살짝 정리한다. 주요 수식은 Python Machine Learning Second Edition 교재를 주로 참고 하였다. (Page: 90 ~ 94) 교재 출처: https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow/dp/1787125939 결정 트리의 예 결정 트리는 여러가지 연속된 질문을 학습하여 분류하는 것이 원칙이다. 다음의 간단한 예를 들어본다. 결정 트리는 크게 3가지로 구성이 되어 있다. 트리 내부 노드, 리프 노드, 그리고 가지로 구성이 되어 있다. 어떻게 질문을 하느냐에 따라서 분류가 결정된다. 결정 트리는 숫자에도 적용할 수 있다.</description>
    </item>
    
    <item>
      <title>Heroku Dash App 배포 - Windows 10</title>
      <link>https://dschloe.github.io/python/dash/heroku_windows/</link>
      <pubDate>Wed, 01 Dec 2021 09:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/heroku_windows/</guid>
      <description>개요 Windows와 Virtualenv를 활용하여 빠르게 App 배포를 해본다. 1. 프로그램 다운로드 설치파일 주소: https://devcenter.heroku.com/articles/getting-started-with-python#set-up 설치할 때, 다음과 같은 에러가 발생할 수 있다. 이럴 경우에는 환경변수를 강제로 잡는다. C:\Program Files\heroku\bin Heroku가 제대로 환경설정이 되어 있는지 확인하려면, 터미널에서 다음 명령어를 입력해 확인한다. $ heroku -v heroku/7.53.0 win32-x64 node-v12.21.0 (base) Github 설치: https://git-scm.com/ 아나콘다 설치: https://www.anaconda.com/products/individual 각각의 환경설정은 모두 해둬야 한다. 2. Getting Started Heroku 회원가입을 한다. (https://signup.heroku.com/) 그리고 로그인을 한다. $ heroku login heroku: Press any key to open up the browser to login or q to exit: Opening browser to https://cli-auth.</description>
    </item>
    
    <item>
      <title>Hexo Blog 재연결</title>
      <link>https://dschloe.github.io/settings/hexo_blog_reconnected/</link>
      <pubDate>Fri, 26 Nov 2021 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/hexo_blog_reconnected/</guid>
      <description>문제점 몇몇 수강생이 노트북과 데스트탑 자리 모두에서 깃헙 블로그를 운영하고 싶어함. 또한, 기존에 올라간 블로그 소스를 그대로 사용하고 싶어함. 그런데, 제대로 반영이 안되는 경우가 있음. 해결책 그런 경우 아래와 같이 순차적으로 진행하면 된다. $ hexo init your_blog_repo # 여기는 각자 소스 레포 확인 $ cd myblog $ git init $ git remote add origin https://github.com/your_name/your_blog_repo.git # 각자 소스 레포 주소 아래 명령어에서 에러가 발생이 있다. $ git pull --set-upstream origin main # 에러 발생 그런 경우, 아래 명령어를 추가한다.</description>
    </item>
    
    <item>
      <title>Kaggle Survey Data Transformation Tip</title>
      <link>https://dschloe.github.io/kaggle/kaggle_survey_2021/data_transformation/</link>
      <pubDate>Thu, 18 Nov 2021 18:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/kaggle_survey_2021/data_transformation/</guid>
      <description>Intro Data Transformation is always important to visualise. Here, I just introduced to get value counts in different dataset. If you are newbie, please be aware of this code before you dive into visualization. # This Python 3 environment comes with many helpful analytics libraries installed # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here&amp;#39;s several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.</description>
    </item>
    
    <item>
      <title>M1 Mac Tensorflow Installation in R</title>
      <link>https://dschloe.github.io/r/r_settings/m1_tensorflow/</link>
      <pubDate>Tue, 16 Nov 2021 17:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/r_settings/m1_tensorflow/</guid>
      <description>개요 M1 Mac에서 텐서플로를 설치 한다. 필자의 현재 M1 환경은 아래와 같다. sessionInfo() R version 4.1.2 (2021-11-01) Platform: aarch64-apple-darwin20 (64-bit) Running under: macOS Big Sur 11.6 Matrix products: default LAPACK: /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/lib/libRlapack.dylib locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] ggplot2_3.3.5 dplyr_1.0.7 tfdatasets_2.7.0 keras_2.7.0 [5] reticulate_1.22 tensorflow_2.7.0 loaded via a namespace (and not attached): [1] Rcpp_1.0.7 compiler_4.1.2 pillar_1.6.4 prettyunits_1.1.1 [5] base64enc_0.1-3 tools_4.</description>
    </item>
    
    <item>
      <title>Matplotlib 한글 폰트 추가 (Mac)</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/matplotlib_kor_font/</link>
      <pubDate>Mon, 25 Oct 2021 23:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/matplotlib_kor_font/</guid>
      <description>개요 Mac 유저를 위해 한글 폰트 추가하는 방법을 설명한다. 기본 코드는 Windows에서도 동작한다. 폰트 추가 방법은 생략한다. 한글 폰트 깨진 시각화 간단하게 깨진 한글이 들어간 시각화를 구현한다. import matplotlib.font_manager as fm import matplotlib.pyplot as plt import matplotlib as mpl plt.plot([1, 2, 3, 4, 5]) plt.title(&amp;#34;테스트&amp;#34;) plt.show() /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 53580 missing from current font. font.set_text(s, 0.0, flags=flags) /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 49828 missing from current font. font.set_text(s, 0.0, flags=flags) /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 53944 missing from current font.</description>
    </item>
    
    <item>
      <title>RcppMeCab 패키지 설치 (Windows)</title>
      <link>https://dschloe.github.io/r/newpkgs/rcppmecab_install/</link>
      <pubDate>Sat, 23 Oct 2021 00:21:01 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/newpkgs/rcppmecab_install/</guid>
      <description>개요 Mecab-ko 형태소 분석기 사용 위해서는 Rcppmecab 패키지를 설치해야 함. RcppMeCab 패키지 설치 앞서서 설치할 파일이 있음. URL: https://github.com/junhewk/RcppMeCab/blob/master/README_kr.md 해당 깃허브에서 설치해야 할 파일을 다운로드 받은 후, &amp;ldquo;C:\mecab&amp;rdquo; 경로에 설치한다. 설치 파일 MeCab 프로그램: mecab-ko-0.9.2-msvc-3 MeCab 사전: mecab-ko-dic-2.1.1-20180720-msvc-2 위 파일을 다운로드 받은 후, &amp;ldquo;C:\mecab&amp;quot;에서 압축을 해제한다.
RcppMecab 패키지 불러오기. 이제 패키지를 불러오도록 한다. 해당 패키지는 Github 버전으로 설치해야 하기 때문에 아래와 같이 설치를 한다. library(remotes) install_github(&amp;#34;junhewk/RcppMeCab&amp;#34;) Downloading GitHub repo junhewk/RcppMeCab@HEAD Installing 3 packages: BH, RcppParallel, Rcpp .</description>
    </item>
    
    <item>
      <title>Hexo Blog 이미지 추가</title>
      <link>https://dschloe.github.io/settings/hexo_img/</link>
      <pubDate>Thu, 21 Oct 2021 12:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/hexo_img/</guid>
      <description>Hexo 이미지 추가 Hexo 블로그 작성 시, 이미지 파일을 추가하는 방법에 대해 배운다. 주요 참고자료 Asset Folders: https://hexo.io/docs/asset-folders Asset Folders | Hexo - Static Site Generator | Tutorial 9: https://youtu.be/feIDVQ2tz0o 방법 1. Global Asset Folder 가장 간편한 방법은 source 폴더 아래 images 폴더를 별도로 만든다. 마크다운에서 아래와 같이 입력을 한다. ![](/images/image.jpg) 실제로 테스트를 해본다. (logo.md) image file: https://upload.wikimedia.org/wikipedia/commons/e/e9/Hexo-logo.png # hexo logo 테스트 - 이미지 ![](/images/Hexo-logo.png) hexo server를 실행한 뒤 결과를 확인한다.</description>
    </item>
    
    <item>
      <title>Home Credit Default - Data Visualization</title>
      <link>https://dschloe.github.io/r/kaggle/day_1_home_credit_visusalization/</link>
      <pubDate>Tue, 05 Oct 2021 09:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/kaggle/day_1_home_credit_visusalization/</guid>
      <description>공지 본 포스트는 재직자 교육을 위해 만든 강의안의 일부입니다. Introduction 대회 개요 Many people struggle to get loans due to insufficient or non-existent credit histories. And, unfortunately, this population is often taken advantage of by untrustworthy lenders. Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data&amp;ndash;including telco and transactional information&amp;ndash;to predict their clients&amp;rsquo; repayment abilities.</description>
    </item>
    
    <item>
      <title>tuber 패키지와 유투브 API를 활용한 Youtube 댓글 수집</title>
      <link>https://dschloe.github.io/r/youtube/youtube_api/</link>
      <pubDate>Thu, 30 Sep 2021 10:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/youtube/youtube_api/</guid>
      <description>공지 본 자료는 아래 책에서 일부 발췌 하였고, 해당 코드를 재응용하기 위해 노력하였습니다. 전체 원 소스 코드를 보시려면 책을 구매하시기를 바랍니다. 실무 예제로 끝내는 R 데이터 분석: 데이터 분석가에게 꼭 필요한 5가지 실무 예제로 분석 프로세스 이해하기 구입처: http://www.yes24.com/Product/Goods/103449758?OzSrank=1 개요 Youtube API에 등록 후, 댓글 수집 및 감성을 분석하는 과정을 담았습니다. 구글 API 프로젝트 생성하기 API 사용을 위해서는 구글 개발자 콘솔에 접속한다.
URL: https://console.developers.google.com/ 아래와 같이 새로운 프로젝트 만들기를 클릭 한다.</description>
    </item>
    
    <item>
      <title>Classification with Tidymodels</title>
      <link>https://dschloe.github.io/r/machine_learning/classification_tidymodels/</link>
      <pubDate>Tue, 28 Sep 2021 10:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/machine_learning/classification_tidymodels/</guid>
      <description>개요 새로운 ML 라이브러리인 tidymodels를 활용하여 분류 모델을 개발해본다. 데이터 데이터는 Loan Prediction Practice Problem에서 가져왔다.
URL: https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/#ProblemStatement 회원가입 후, 대회 참여를 하면 3개의 파일을 다운로드 받을 수 있다.
Train file, Test file, Submission File Data Dictionary Train 파일의 데이터 명세서는 다음과 같다. Test 파일의 데이터 명세서는 다음과 같다. Submission 파일의 데이터 명세서는 다음과 같다. 대회목적 대출 승인 여부를 결정하는 모델을 만드는 것이 대회의 주 목적이며. 평가지표는 분류모형의 Accurarcy로 결정한다. 패키지 및 데이터 불러오기 먼저 필수 패키지를 불러온다.</description>
    </item>
    
    <item>
      <title>Airflow를 활용한 Data Cleansing 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch05_cleaning_transforming/data_cleaning_using_airflow/</link>
      <pubDate>Mon, 20 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch05_cleaning_transforming/data_cleaning_using_airflow/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Pandas와 Airflow를 활용하여 데이터를 정제하는 코드를 구성한다. 우선 데이터는 아래에서 CSV 파일을 다운로드 받고, Dags 파일 하단에 위치시킨다. URL: https://github.com/PaulCrickard/escooter/blob/master/scooter.csv Raw 데이터 확인 간단하게 Raw 데이터를 확인해보도록 한다. import pandas as pd df = pd.</description>
    </item>
    
    <item>
      <title>Airflow를 활용한 PostgreSQL에서 Elasticsearch로 데이터 마이그레이션 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch04_working_databases/airflow_postgresql_elasticsearch/</link>
      <pubDate>Sat, 18 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch04_working_databases/airflow_postgresql_elasticsearch/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Airflow를 활용하여 PostgreSQL에 저장된 데이터를 디스크로 다운로드 받고, 그리고 그 파일을 다시 읽어서 Elasticsearch에 저장하도록 한다. 전체적인 흐름은 getData from PostgreSQL &amp;gt;&amp;gt; insertData to Elasticsearch 로 저장할 수 있다. 전체 코드 실행 우선 전체 코드를 실행하도록 한다.</description>
    </item>
    
    <item>
      <title>파이썬을 활용한 엘라스틱서치에서 데이터 추출</title>
      <link>https://dschloe.github.io/python/data_engineering/ch04_working_databases/elasticsearch_python_extract/</link>
      <pubDate>Fri, 17 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch04_working_databases/elasticsearch_python_extract/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 데이터를 질의하는 방법과 데이터를 삽입하는 방법은 동일하다. 다만, 이 때에는 search 메서드를 사용하다. 또한, doc 문서도 조금 다르다. 기본적으로 SQL 과 문법이 다르기 때문에 공식문서를 확인한다. 실행 본 테스트를 실행하기에 앞서서, Elasticsearch 과 Kibana 를 먼저 구동시키고, 데이터가 미리 삽입 되어 있으면 좋다.</description>
    </item>
    
    <item>
      <title>파이썬과 엘라스틱서치 DB 연동</title>
      <link>https://dschloe.github.io/python/data_engineering/ch04_working_databases/elasticsearch_with_python_dbinsert/</link>
      <pubDate>Wed, 15 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch04_working_databases/elasticsearch_with_python_dbinsert/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 NoSQL 데이터베이스 시스템의 하나인 Elasticsearch 를 다루는 방법을 설명한다. NoSQL 은 데이터를 행들과 열들로 저장하지 않는 데이터베이스를 말한다. 대개 JSON문서 형태로 저장하고, SQL이 아닌 절의 언어를 주로 사용한다. 설치 먼저 설치를 진행한다. (venv) $ pip3 install elasticsearch Collecting elasticsearch Downloading elasticsearch-7.</description>
    </item>
    
    <item>
      <title>파이썬과 PostgreSQL DB 연동 예제</title>
      <link>https://dschloe.github.io/python/data_engineering/ch04_working_databases/python_postgresql/</link>
      <pubDate>Fri, 10 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch04_working_databases/python_postgresql/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 MacOS에서의 기본 설치 과정은 생략하도록 한다. 새로운 DB를 생성하도록 한다. 먼저 환경변수를 설정한다. 해당 경로를 가져오는 방법은 Postgre SQL Installation on MacOS M1에서 확인한다. (venv) $ export PATH=/opt/homebrew/bin:$PATH:/Applications/Postgres.app/Contents/Versions/13/bin 먼저 기본 데이터베이스에 연결한다. (venv) $ psql postgres psql (13.</description>
    </item>
    
    <item>
      <title>Apache Airflow를 활용한 CSV에서 JSON으로 변환하기</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json/</link>
      <pubDate>Thu, 09 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/airflow_csv2json/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Apache Airflow에서 가장 중요한 개념은 DAG(Directed Acyclic Graph)이다. DAG를 만들 시, Bash 스크립트 및 연산자(Operator)로 작업을 정의할 수 있다. 이 때, 파이썬 함수로 조직화 한다. Airflow 설치방법을 모른다면 다음 페이지에서 확인한다. Apache Airflow Installation Step 01.</description>
    </item>
    
    <item>
      <title>파이썬을 활용한 JSON 파일 입출력 예제 with faker</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/json_input_output/</link>
      <pubDate>Wed, 08 Sep 2021 18:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/json_input_output/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 JSON은 (JavaScript Object Notataion)의 약자이며, 주로 API 호출 시에 사용한다. JSON 데이터를 개별적인 파일 형태로 저장하기도 한다. json 라이브러리를 활용하여 입출력을 진행하고, pandas 라이브러리를 통해서도 직접 불러오도록 한다. JSON 파일 쓰기 전체 코드 파일은 wirtejson.</description>
    </item>
    
    <item>
      <title>파이썬을 활용한 CSV 파일 입출력 예제 with faker</title>
      <link>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/csv_input_ouput/</link>
      <pubDate>Wed, 08 Sep 2021 16:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch03_reading_writing_file/csv_input_ouput/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 사전 작업 우선 임시 데이터를 기록할 라이브러리인 faker 를 설치한다. 흔히 쓰이는 필드들을 함수 하나로 쉽게 만들 수 있도록 지원한다. (venv) $ pip3 install faker 데이터 생성하기 전체 코드 필자는 [writecsv.py](http://writecsv.py) 형태로 저장하였다. 먼저 한줄 씩 설명하면 다음과 같다.</description>
    </item>
    
    <item>
      <title>Kibana Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/kibana_install/</link>
      <pubDate>Tue, 07 Sep 2021 13:13:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/kibana_install/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Elastic Search는 GUI를 제공하지 않고 API만 제공한다. 따라서, 시각화 도구인 키바나를 GUI로 사용하도록 하는 것이 특징이다. Elastic Search 설치는 Elastic Search Engine Installation에서 확인한다. 즉, 다시 말하면 Elastic Search 는 API 데이터만 제공할 뿐이고, 이를 가시적으로 보여주기 위해서는 Kibana를 설치해야 한다는 뜻이다.</description>
    </item>
    
    <item>
      <title>Elastic Search Engine Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/elastic_search_install/</link>
      <pubDate>Tue, 07 Sep 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/elastic_search_install/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 검색 엔진을 말한다. Mac에서 설치하는 과정을 진행한다. 가상 환경은 virtualenv 를 통해서 진행한다. 참조: https://lee-mandu.tistory.com/517?category=838684 그 후에 가상 환경에 접속한다. 설치 각 OS별 설치 과정은 해당 URL에서 참조할 수 있다. URL: https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html MacOS: https://www.</description>
    </item>
    
    <item>
      <title>Apache Airflow Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</link>
      <pubDate>Mon, 06 Sep 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_airflow_install/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 NiFi와 같은 용도의 소프트웨어이며, 현재 가장 인기 있는 오픈소스 데이터 파이프라인 도구라고 할 수 있다. 보통은 시스템에 경로를 설정한다. 그런데, 본 장에서는 가상환경 설정 후 진행하는 것으로 했다. 가상 환경은 virtualenv 를 통해서 진행한다.</description>
    </item>
    
    <item>
      <title>Apache NiFi Installation</title>
      <link>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_nifi_install/</link>
      <pubDate>Mon, 06 Sep 2021 16:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/data_engineering/ch02_infra/apache_nifi_install/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 데이터 엔지니어링에 필요한 기본적인 인프라를 설치 진행하는 튜토리얼을 만들었다. 기본적으로 교재에 충실하지만, 약 1년전에 쓰인 책이라, 최신 버전으로 업그레이드 하였다. Apache NiFi 설치과정 먼저 웹사이트에 방문하여 필요한 파일을 다운로드 받는다. URL: https://nifi.apache.org/download.html wget을 이용해서 NiFi를 현재 디렉터리에 내려받는다.</description>
    </item>
    
    <item>
      <title>LSTM을 활용한 주식가격 예측</title>
      <link>https://dschloe.github.io/python/python_edu/07_deeplearning/deep_learning_lstm/</link>
      <pubDate>Fri, 27 Aug 2021 16:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/07_deeplearning/deep_learning_lstm/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 [비전공자 대환영] 캐글 데이터를 활용한 Optuna with MLFlow - 캐글다지기 머신러닝 하이퍼파라미터 튜닝 등을 배우고 싶다면 다음 강의를 참고하세요. LSTM과 RNN의 개요 RNN은 자연어처리에서 사용되는 대표적인 알고리즘 순환신경망으로 표현됨 활용범위: 음성 인식, 언어 모델링, 번역, 이미지 주석 생성 Long Short-term Memory로 1997년에 소개되었음(Hochreiter and Schmidhuber, 1997).</description>
    </item>
    
    <item>
      <title>기업 요청 샘플 (수강생) - Python Dash를 활용한 대시보드</title>
      <link>https://dschloe.github.io/python/dash/dash_cpu_logdata/</link>
      <pubDate>Thu, 26 Aug 2021 14:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/dash_cpu_logdata/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 보안 로그 파일을 업로드한 뒤, 점검 결과를 자동으로 출력해주도록 한다. (수강생의 도전) 보안 로그 파일을 업로드 한 뒤, CPU 사용률이 70%가 넘으면 경고 메시지를 뛰우도록 한다. Chapter 1. 로그데이터 분석 및 확인 먼저 CPU가 들어있는 로그데이터를 확인한다.</description>
    </item>
    
    <item>
      <title>네이버 뉴스 댓글 크롤링 대시보드 만들기 with Heroku</title>
      <link>https://dschloe.github.io/python/dash/dash-crawling-tutorial/</link>
      <pubDate>Tue, 17 Aug 2021 11:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/dash-crawling-tutorial/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1. 개요 기존 웹크롤링은 주로 코드에 기반한 소개가 주를 이루었음 본 장에서는 가급적 사용자 기준에 맞춰서 뉴스 URL만 입력하면 댓글 수집할 수 있는 기능 소개함 2. 라이브러리 크롤링 및 대시보드 작업을 위한 필수 라이브러리는 다음과 같음 (requirements.</description>
    </item>
    
    <item>
      <title>Python Dash를 활용한 대시보드에서 엑셀 데이터로 다운로드 받기</title>
      <link>https://dschloe.github.io/python/dash/dash_security_log/</link>
      <pubDate>Thu, 12 Aug 2021 09:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/dash_security_log/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 [대시보드] Dash Project - Excel 다운로드 개요 각 레벨에 따라 달라지는 데이터를 시각화로 표현하고 결과치를 엑셀로 다운로드 받는 기능을 구현한다. 데이터 다운로드 데이터는 로그 분석을 통한 보안 위험도 예측 AI 경진대회 에서 가져왔다. (회원가입 필수) Data: https://dacon.</description>
    </item>
    
    <item>
      <title>Python Dash를 활용한 대시보드 만들기 with Heroku</title>
      <link>https://dschloe.github.io/python/dash/dash_project/</link>
      <pubDate>Wed, 04 Aug 2021 18:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dash/dash_project/</guid>
      <description>강의 소개 필자의 강의를 소개합니다. 개요 대시보드 프로젝트를 진행한다. Heroku에 배포까지 진행하는 것을 목적으로 한다. 참조: https://realpython.com/python-dash/ 여기에 있는 내용을 최대한 간결하게 한글로 재 작성하였다. 중간에 없는 코드들도 있으니, 가급적 본 소스코드를 활용한다. 1. 데이터 수집 데이터: https://www.kaggle.com/neuromusic/avocado-prices 다운로드 받은 파일은 임의의 폴더 안에 넣습니다. (필자: dashboard-project21) C:\Users\1\Desktop\dashboard-project21&amp;gt;tree /f 폴더 PATH의 목록입니다. 볼륨 일련 번호는 E657-CFA3입니다. C:. │ README.md │ └─data avocado.csv 파일 경로를 주의해서 보도록 합니다. 2. 가상환경 및 라이브러리 설치 conda를 활용하여 가상환경 설정을 합니다.</description>
    </item>
    
    <item>
      <title>Python과 Oracle 연동</title>
      <link>https://dschloe.github.io/sql/python_oracle/</link>
      <pubDate>Fri, 16 Jul 2021 00:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/python_oracle/</guid>
      <description>개요 파이참에서 가상환경을 만들어 오라클 연동 예제를 작성한다. 아나콘다, 파이참, 그리고 오라클 설치는 생략한다. 1. 가상환경 활성화 cmd 창에서 가상 환경을 세팅 하도록 한다. (권장: 관리자 실행) 바탕화면에 필자는 python_oracle 폴더를 생성했다. 현재 경로는 아래와 같다. C:\Users\1\Desktop\python_oracle&amp;gt; 먼저 가상환경을 만든다. conda create --name your_env_name python=3.8 . . done # # To activate this environment, use # # $ conda activate python_oracle # # To deactivate an active environment, use # # $ conda deactivate your_env_name 대신 다른 이름으로 설정해도 된다.</description>
    </item>
    
    <item>
      <title>In ML, Data Leakage - 2</title>
      <link>https://dschloe.github.io/python/machin_learning/ch04_common_pitfalls_ans_recommended_practices/</link>
      <pubDate>Thu, 15 Jul 2021 16:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/machin_learning/ch04_common_pitfalls_ans_recommended_practices/</guid>
      <description>머신러닝 전처리 자주하는 안 좋은 습관들 모음 참고 자료: https://scikit-learn.org/stable/common_pitfalls.html Sample 데이터 먼저 가상의 데이터를 하나 생성합니다. from sklearn.datasets import make_regression from sklearn.model_selection import train_test_split random_state = 42 X, y = make_regression(random_state = random_state, n_features = 1, noise = 1) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = random_state) Inconsistent preprocessing 모델을 학습시킬 때 이러한 데이터 변환을 사용하는 경우 테스트 데이터든 프로덕션 시스템의 데이터든 후속 데이터셋에도 사용해야 합니다.</description>
    </item>
    
    <item>
      <title>In ML, Data Leakage - 1</title>
      <link>https://dschloe.github.io/python/machin_learning/ch03_data_preparation/</link>
      <pubDate>Thu, 15 Jul 2021 11:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/machin_learning/ch03_data_preparation/</guid>
      <description>Data Leakage 모형 평가를 하기 전에 전체 데이터셋을 가공 및 변환함. 이를 평가에 반영하면 새로운 데이터를 예측할 때 부정확한 결과를 도출 할 수 있음. 이를 방지 하기 위해서는 training 데이터만 데이터 전처리를 수행하는 것이 바람직함. Data Leakage를 피하기 위해서는 scikit-learn modeling pipeline을 설계해햐 함. 데이터 준비 가상의 데이터를 준비한다. 데이터는 모두 수치형 데이터로 준비했다. from sklearn.datasets import make_classification X, y = make_classification(n_samples = 1000, n_features = 20, n_informative = 15, n_redundant = 5, random_state = 7) # summarize the dataset print(X.</description>
    </item>
    
    <item>
      <title>엑셀 데이터 가공하기 변환</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/excel_multipleheaders/</link>
      <pubDate>Mon, 12 Jul 2021 05:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/excel_multipleheaders/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 정리되지 못한 엑셀 파일을 불러와서 하나의 테이블을 만드는 과정을 진행해본다. 위 데이터를 원본 그대로 받아서 pandas 데이터 프레임에 추가한다. A3 셀에 있는 [시·도지사선거][서울특별시][강남구] 분리하여 각 column에 추가한다. 라이브러리 불러오기 3개의 라이브러리를 불러온다. import pandas as pd import openpyxl import os 파일 확인 data 폴더 내 데이터를 확인한다.</description>
    </item>
    
    <item>
      <title>AirFlow ch01. 개요</title>
      <link>https://dschloe.github.io/mlops/ch04_airflow/airflow_00_intro/</link>
      <pubDate>Fri, 09 Jul 2021 14:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch04_airflow/airflow_00_intro/</guid>
      <description>인프런 강의 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 Airflow 2.0 원서 나온 것을 공부용으로 활용합니다. Airflow Project 이 책에 나온 내용을 Chapter별로 요약하여 정리하려고 한다. 원서 구매 페이지는 아래와 같다. 구매 페이지: Data Pipelines with Apache Airflow Chapter 1. Apache Airflow Introduction Figure 1.</description>
    </item>
    
    <item>
      <title>AirFlow 설치 및 실행 with M1</title>
      <link>https://dschloe.github.io/mlops/ch04_airflow/airflow_01/</link>
      <pubDate>Thu, 08 Jul 2021 14:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch04_airflow/airflow_01/</guid>
      <description>인프런 강의 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 미니 프로젝트 개요 목적: Airflow와 빅쿼리를 활용하여 ETL 및 대시보드를 만들어보는 과정을 설계 환경: MacOS M1 Part I. Docker and Airflow Docker와 Airflow를 설치 및 실행한다.
필자는 가상환경을 선정하고, 그 위에 도커를 추가로 설치하였다.</description>
    </item>
    
    <item>
      <title>PostgreSQL 기초 1</title>
      <link>https://dschloe.github.io/sql/db_creation_01/</link>
      <pubDate>Sun, 04 Jul 2021 00:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/db_creation_01/</guid>
      <description>개요 psql shell 명령어를 간단히 배우도록 한다. Database, Schema, Table를 생성하도록 한다. 데이터타입에 대해 배우도록 한다. psql Shell 명령어 명령어 설명 \q psql을 종료한다. \l 데이터베이스를 조회한다. \c 입력한 DB로 이동한다. \e 외부편집기로 sql 쿼리 입력 가능 \dt 현재 DB에서 테이블을 확인할 수 있음. 자주 사용하는 명령어이기 때문에 확인한다. DB 및 Table 다루기 콘솔창에서 book 이름의 DB를 생성한다. evan=# CREATE DATABASE book; CREATE DATABASE 그 후, book에 접속한다. evan=# \c book You are now connected to database &amp;#34;book&amp;#34; as user &amp;#34;evan&amp;#34;.</description>
    </item>
    
    <item>
      <title>(Python-Plotly) Plotly 그래프 깃헙 블로그에 올리기</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_plotly_html/</link>
      <pubDate>Thu, 24 Jun 2021 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_plotly_html/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 깃헙 브로그에 동적 시각화를 올리는 방법에 대해 기술한다. 현재까지 찾아낸 것은 이게 최선입니다! 더 나은 것이 있다면 공유 부탁드립니다. (꾸벅) 필수 라이브러리 설치 라이브러리를 설치합니다. Getting Started with Plotly in Python, https://plotly.com/python/getting-started/ Getting Started with Chart Studio in Python, https://plotly.</description>
    </item>
    
    <item>
      <title>File Download VIA SSH Terminal</title>
      <link>https://dschloe.github.io/settings/csv_download_via_ssh/</link>
      <pubDate>Fri, 11 Jun 2021 09:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/csv_download_via_ssh/</guid>
      <description>1줄 요약 CURL 명령어는 진심 매우 좋더라. 동기부여 SQL 강의를 해야 하는데, 그에 맞는 데이터를 찾는 중이었다. SQL 예제와 함께 있는 데이터를 찾던 중, URL로 적힌 CSV 파일을 확인하였다. 이를 직접 Download로 쉽게 받을 수 있을 까 하는 생각에 구글링 몇개 해보였다. 참고자료 StackoverFlow에 다음과 같은 글을 찾았다.
URL: How to download CSV via terminal (SSH)? 참고 소스 코드는 아래와 같다.
-o, --output &amp;lt;file&amp;gt; Write output to &amp;lt;file&amp;gt; instead of stdout.</description>
    </item>
    
    <item>
      <title>PostgreSQL 테이블 생성 예제</title>
      <link>https://dschloe.github.io/sql/table_creation_01/</link>
      <pubDate>Wed, 09 Jun 2021 00:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/sql/table_creation_01/</guid>
      <description>테이블 생성 및 수정 삭제 pgAdmin4을 활용한 테이블 수정 삭제 Schemas에서 public-Table 마우스 오른쪽 버튼을 누른 뒤 Query Tool을 선택합니다. developers 테이블을 별도로 생성합니다. CREATE TABLE developers ( book_id INTEGER, date DATE, name VARCHAR(80) ) CREATE TABLE Query returned successfully in 65 msec. 이번에는 값을 입력하도록 합니다. INSERT INTO developers VALUES(1, &amp;#39;2019-12-17&amp;#39;, &amp;#39;&amp;#34;자바&amp;#34;&amp;#39;) 그런데, 작은 따옴표(&amp;rsquo;)를 넣고 싶을 때는 큰 따옴표(&amp;quot;)로 깜사면, 에러가 발생이 됩니다. INSERT INTO developers VALUES(2, &amp;#39;2019-12-17&amp;#39;, &amp;#34;&amp;#39;자바&amp;#39;&amp;#34;) ERROR: 오류: &amp;#34;&amp;#39;자바&amp;#39;&amp;#34; 이름의 칼럼은 없습니다 LINE 1: INSERT INTO developers VALUES(1, &amp;#39;2019-12-17&amp;#39;, &amp;#34;&amp;#39;자바&amp;#39;&amp;#34;) ^ SQL state: 42703 Character: 48 이런 경우에는 작은 따옴표를 두번 입혀서 깜사도록 합니다.</description>
    </item>
    
    <item>
      <title>pgAdmin4 GUI installation on MacOS M1</title>
      <link>https://dschloe.github.io/settings/pgadmin4/</link>
      <pubDate>Mon, 07 Jun 2021 23:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/pgadmin4/</guid>
      <description>pgAdmin 설치 및 서버 연결 (MacOS) GUI 프로그램을 설치해본다. Windows는 자동으로 설치가 되기 때문에 생략을 한다. 먼저 해당 싸이트에 접속을 합니다. URL: https://www.pgadmin.org/download/ macOS를 클릭한 뒤 다음 화면에서 pgAdmin 4 v5.3 최신버전을 다운로드 받도록 합니다. 프로그램을 설치하면 첫 화면에서 Password를 입력하도록 합니다. 새로운 서버를 생성하여 서버를 등록하도록 합니다. 그 후에 이름은 LocalTest라고 정합니다. 그 후에, username은 postgres를 username으로 입력하고 Postgresql을 설치할 때 설정한 password를 입력합니다. 실제 서버에 연결 되었는지 확인하도록 합니다.</description>
    </item>
    
    <item>
      <title>Postgre SQL Installation on Windows 10</title>
      <link>https://dschloe.github.io/settings/postgresql_install_windows/</link>
      <pubDate>Fri, 04 Jun 2021 07:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/postgresql_install_windows/</guid>
      <description>Windows PostgreSQL Downloads URL: https://www.enterprisedb.com/downloads/postgres-postgresql-downloads 각 컴퓨터에 맞는 버전을 선택합니다. 필자는 13.3 버전을 선택하였습니다.
이번에는 프로그램을 클릭하여 설치를 진행합니다. 모든 값은 default로 진행합니다.
비밀번호는 작성 후, 반드시 기억하시기를 바랍니다.
필자는 temp라고 명명하였습니다. 포트는 5432를 확인합니다. 언어는 한국어로 선택하도록 합니다. 몇번의 Next를 더 누르시면서, 설치를 진행합니다. 설치가 완료되면 Stack Builder 체크 박스는 제 후 완료를 합니다. 해 프로그램을 검색하여 PostgreSQL이 잘 설정되는지 확인을 하도록 합니다.
환경변수 추가 CMD에서 활용하려면 환경변수를 설정하도록 합니다.</description>
    </item>
    
    <item>
      <title>[Python] 이미지 데이터 입출력</title>
      <link>https://dschloe.github.io/python/opencv/ch01_fileio/</link>
      <pubDate>Wed, 02 Jun 2021 14:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/opencv/ch01_fileio/</guid>
      <description>1줄 요약 OpenCV를 활용한 다양한 이미지 입출력에 대해 배우도록 한다. Reading/Writing an image file 이미지 관련 I/O BMP, PNG, JPEG, and TIFF also supported. import numpy as np img = np.zeros((3, 3), dtype=np.uint8) img array([[0, 0, 0], [0, 0, 0], [0, 0, 0]], dtype=uint8) 각 픽셀은 8비트 int로 구성되어 있음. 각 픽셀의 범위는 0-255, 0은 검은색, 255는 흰색을 의미함. import cv2 img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) img array([[[0, 0, 0], [0, 0, 0], [0, 0, 0]], [[0, 0, 0], [0, 0, 0], [0, 0, 0]], [[0, 0, 0], [0, 0, 0], [0, 0, 0]]], dtype=uint8) 3차원 배열을 의미.</description>
    </item>
    
    <item>
      <title>Postgre SQL Installation on MacOS M1</title>
      <link>https://dschloe.github.io/settings/postgresql_install/</link>
      <pubDate>Mon, 31 May 2021 07:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/postgresql_install/</guid>
      <description>1줄 요약 MacOS M1에서 PostgreSQL 설치에서 중요한 건 환경변수만 추가한다. M1의 구조 M1애서는 Intel, Silicon, Universal 3개의 시스템을 지원한다. 그런데, PostgreSQL 프로그램은 기본적으로 Intel 기반으로 작동을 한다. Postgre SQL 다운로드 해당 웹 페이지로 간다. (URL: https://postgresapp.com/) 다운로드 받은 후 Postgres-2.4.3-13.dmg (2021.5.31일 기준) 설치 파일을 클릭한 후, 아래 화면이 나오면, 설치를 진행합니다. 설치 진행이 완료가 되면 아래 화면에서 Initialize 또는 Start 버튼을 클릭하면 설치는 끝이 납니다. 환경변수 설정 그런데, 환경변수 설정을 하지 않으면 터미널에서 실행이 되지 않습니다.</description>
    </item>
    
    <item>
      <title>Pandas 속도 비교 - with or without Dictionary</title>
      <link>https://dschloe.github.io/python/pandas/dictionary_replace/</link>
      <pubDate>Sun, 30 May 2021 10:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/dictionary_replace/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 Dictionary를 활용한 값 변경의 속도가 훨씬 빠르다. 데이터 불러오기 diamonds 데이터셋을 불러온다. import pandas as pd import seaborn as sns diamonds = sns.load_dataset(&amp;#39;diamonds&amp;#39;) print(diamonds) carat cut color clarity depth table price x y z 0 0.</description>
    </item>
    
    <item>
      <title>[MLOps] Weight &amp; Biases 소개 및 사용 방법</title>
      <link>https://dschloe.github.io/mlops/wandb/install/</link>
      <pubDate>Sat, 29 May 2021 09:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/wandb/install/</guid>
      <description>인프런 강의 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 wandb로 MLOps를 배워봅니다. References Weight &amp;amp; Biases(wandb) 사용법(wandb 설치 및 설명) by greeksharifa 초기 설정 싸이트: https://wandb.ai/site
회원가입을 한 뒤, 가장 먼저 나오는 화면은 아래 대시보드 입니다. 참조: 필자는 Mac M1을 사용하는 중입니다.</description>
    </item>
    
    <item>
      <title>Pandas 속도 비교 - loc vs replace(2)</title>
      <link>https://dschloe.github.io/python/pandas/loc_replace_2/</link>
      <pubDate>Thu, 20 May 2021 00:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/loc_replace_2/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 값을 변경할 때에는 .replace 메서드를 사용합니다. 개요 Replace 속도를 측정해보자. 이번에는 multiple 값을 변경하는 방법에 대해 알아봅니다. 비교 1 .loc vs .replace 값을 바꾸는 방법은 다음과 같다. data[&#39;column&#39;].loc[data[&#39;column&#39;] == &#39;Old Value&#39;] = &#39;New Value&#39; import pandas as pd import seaborn as sns diamonds = sns.</description>
    </item>
    
    <item>
      <title>Pandas 속도 비교 - loc vs replace</title>
      <link>https://dschloe.github.io/python/pandas/loc_replace/</link>
      <pubDate>Sat, 15 May 2021 20:36:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/loc_replace/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 loc and Replace 속도를 비교 측정해본다.. 방법 1. .loc vs .replace 값을 바꾸는 방법은 다음과 같다. data[&#39;column&#39;].loc[data[&#39;column&#39;] == &#39;Old Value&#39;] = &#39;New Value&#39; import pandas as pd import seaborn as sns diamonds = sns.</description>
    </item>
    
    <item>
      <title>Pandas 속도 비교 - iloc and loc</title>
      <link>https://dschloe.github.io/python/pandas/loc_iloc/</link>
      <pubDate>Wed, 12 May 2021 20:36:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/loc_iloc/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 .loc[]와 .iloc[] 인덱스의 속도 차이를 측정해본다. 개요 시간이 허락한다면, Pandas 속도를 비교하는 게시글을 자주 작성하려고 한다. Pandas가 상대적으로 속도가 느리기 때문에, 조금 더 효율적인 코드를 작성하는 쪽에 초점을 맞춰본다. .loc[] : index name locator를 의미한다.</description>
    </item>
    
    <item>
      <title>[Python] PyCaret Windows 10 아나콘다 설치 방법</title>
      <link>https://dschloe.github.io/python/newpkgs/pycaret_install/</link>
      <pubDate>Tue, 11 May 2021 00:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/newpkgs/pycaret_install/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 관리자 실행해서 아나콘다 가상 환경을 만든 후, 새로운 패키지를 설치한다. PyCaret 설치 방법 (Windows 10) 윈도우 10 환경에서 PyCaret 패키지를 설치해봅니다. 아나콘다 설치에 관한 내용은 생략합니다. 다만, 이 때, 필요한 것은 환경변수에 추가가 되어 있어야 합니다.</description>
    </item>
    
    <item>
      <title>시간 측정의 중요성 및 방법</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/ch01_measuring_time/</link>
      <pubDate>Mon, 10 May 2021 07:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/ch01_measuring_time/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 코드를 효과적으로 작성해야 하는 이유를 확인한다. Calculation 비교 요한 카를 프리드리히 가우스(1777-1855)가 문제를 냈다고 알려짐
1 + 2 + &amp;hellip; + 1000000 까지 해당하는 모든 연속 양수의 합계를 구한다.
두가지 방법이 존재한다.</description>
    </item>
    
    <item>
      <title>[Python] PyDataset Library를 활용한 Sample 데이터 수집</title>
      <link>https://dschloe.github.io/python/newpkgs/pydataset/</link>
      <pubDate>Sun, 09 May 2021 17:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/newpkgs/pydataset/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 R처럼 Sample 데이터를 쉽게 불러오자. Sample Dataset Sample Data를 가져오는 코드를 작성합니다. 이 때 PyDataset 라이브러리를 활용합니다. URL: https://github.com/iamaziz/PyDataset !pip install pydataset Collecting pydataset [?25l Downloading https://files.pythonhosted.org/packages/4f/15/548792a1bb9caf6a3affd61c64d306b08c63c8a5a49e2c2d931b67ec2108/pydataset-0.2.0.tar.gz (15.9MB) [K |████████████████████████████████| 15.9MB 285kB/s [?</description>
    </item>
    
    <item>
      <title>Custom Containers with AI Platform Training</title>
      <link>https://dschloe.github.io/mlops/ch03_running_ai_platform_pipelines/ch01_using_custom_containers_with_ai_platform_training/</link>
      <pubDate>Wed, 05 May 2021 14:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch03_running_ai_platform_pipelines/ch01_using_custom_containers_with_ai_platform_training/</guid>
      <description>인프런 강의 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 UCI Machine Learning Repository 데이터를 활용해서 MLOps를 구축해본다. 본 장에서는 MLOps의 간단한 흐름을 파악하는데 주력한다. 실제로는 하나부터 열까지 모든 코드를 따 짜야 한다. 관련 내용은 추후에 여유가 될 때 업데이트를 해보도록 한다. 감사 인사 God Google 감사합니다.</description>
    </item>
    
    <item>
      <title>Training Data Split in BigQuery</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/random_sampling/</link>
      <pubDate>Tue, 04 May 2021 22:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/random_sampling/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>R Path Setting on MacOS</title>
      <link>https://dschloe.github.io/settings/r_path/</link>
      <pubDate>Mon, 03 May 2021 13:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/r_path/</guid>
      <description>1줄 요약 터미널에서 R 실행이 안된다면 PATH를 설정한다. 문제 상황 MacOS 터미널에서 R을 실행하고 싶은데, 가끔 아래와 같은 에러 메시지가 나올때가 있다. $ R bash: R: command not found 문제 해결 이는 환경설정 문제이다. 즉, 이러한 경우에는 여러 솔루션이 있다.
Ref. Running R from Mac OSX terminal 그 중에서 필자는 Fourth Solution: 선택하였다.
$ export PATH=&amp;#34;/Library/Frameworks/R.framework/Resources:$PATH&amp;#34; 그 후에 terminal에서 which R을 실행해본다. 아래와 같이 정상적으로 출력이 된다면, 환경설정은 잘 된 것이다.</description>
    </item>
    
    <item>
      <title>(Python) Pandas Data Convert</title>
      <link>https://dschloe.github.io/python/pandas/pandas_data_convert/</link>
      <pubDate>Wed, 28 Apr 2021 14:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_data_convert/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 Pandas에서 데이터 형변환은 astype로 끝낸다. 참고자료 astype에 대한 공식 문서를 살펴본다. 참고자료: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html 예제 가상의 temp 데이터를 만든다. 모두 0, 1, 2 데이터이지만 각 데이터 타입은 모두 다르다. import pandas as pd temp = pd.</description>
    </item>
    
    <item>
      <title>(Python) Defining the Encoding</title>
      <link>https://dschloe.github.io/settings/encoding/</link>
      <pubDate>Fri, 23 Apr 2021 09:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/encoding/</guid>
      <description>1줄 요약 공식 문서를 한번 읽어보도록 합니다. Why? 한글 사용자에게 인코딩은 언제나 어렵습니다. 한글 깨져요&amp;hellip; 그리고 파이썬의 기본 인코딩은 ASCII라 합니다. How to use 임의의 .py 파일에서 다음과 같이 시작을 합니다. #!/usr/bin/python # -*- coding: utf-8 -*- import os, sys ... 첫줄은 /usr/bin에 있는 파이썬에서 실행한다는 의미.
경로는 각자의 코드에서 수정 가능 두번째 줄은 File Encoding 형식을 지정
참조: Unicode &amp;amp; Character Encodings in Python: A Painless Guide References Defining the Encoding, https://www.</description>
    </item>
    
    <item>
      <title>(SQL-Tutorial) 데이터 분석을 위한 SQL 레시피와 빅쿼리 사용</title>
      <link>https://dschloe.github.io/gcp/bigquery/03_sql_recipe/01_sql_tutorial_intro/</link>
      <pubDate>Thu, 22 Apr 2021 09:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/03_sql_recipe/01_sql_tutorial_intro/</guid>
      <description>1줄 요약 데이터 분석을 위한 SQL 레시피 교재를 빅쿼리에서 활용해본다.
책 소개 블로그 글 중 잘 정리된 글이 있어 소개합니다. 빅데이터책: 데이터 분석을 위한 SQL 레시피 읽어보았습니다. 실습 준비 도서의 부록/예제소스를 다운로드 하세요.
예제 소스 코드를 열어봅니다. sql 소스코드로 구성이 되어 있는 것을 확인할 수 있습니다.
저자가 말하는 샘플 데이터 내용은 아래와 같습니다. 이번에는 임의의 SQL 파일을 열어서 확인하도록 합니다.
위 이미지에서 보면, Table을 생성하는 형태로 구성이 되어 있는 것을 알 수 있습니다.</description>
    </item>
    
    <item>
      <title>Kaggle-Python-Bigquery 연동 예제</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/python_bigquery/</link>
      <pubDate>Fri, 16 Apr 2021 15:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/python_bigquery/</guid>
      <description>1줄 요약 캐글 데이터를 빅쿼리에 넣어보 캐글 데이터 다운로드 캐글 데이터를 다운로드 받습니다. !pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: six&amp;gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1) Requirement already satisfied: tqdm in /usr/local/lib/python3.</description>
    </item>
    
    <item>
      <title>파이썬 객체 지향 프로그래밍 - Attributes &amp; Methods (2)</title>
      <link>https://dschloe.github.io/python/basic/python_oop_2/</link>
      <pubDate>Wed, 14 Apr 2021 16:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/basic/python_oop_2/</guid>
      <description>1줄 요약 클래스를 직접 구현하면서 Attributes &amp;amp; Methods의 차이점에 대해 이해한다. 개요 기본적인 클래스 등을 작성해본다. class Customer: pass class &amp;lt;name&amp;gt;: 클래스의 이름을 정의함 만약, pass를 입력하면 하나의 empty 클래스를 생성하는 것이다. 이렇게 생성된 클래스는 여러개의 인스턴스를 만들 수 있음 c1 = Customer() c2 = Customer() Methods 추가 이번에는 간단한 method를 추가한다. class Customer: def identify(self, name): print(&amp;#34;저는 소비자 &amp;#34; + name + &amp;#34; 입니다.&amp;#34;) 함수 작성 시에는 self를 가장 먼저 입력한다.</description>
    </item>
    
    <item>
      <title>파이썬 객체 지향 프로그래밍 - Attributes &amp; Methods</title>
      <link>https://dschloe.github.io/python/basic/python_oop_1/</link>
      <pubDate>Wed, 14 Apr 2021 13:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/basic/python_oop_1/</guid>
      <description>1줄 요약 Attributes &amp;amp; Methods의 차이점에 대해 이해한다. 개요 Object = State + Behavior 예) Email, Phone Number, 배송상태 Class는 일종의 가이드라인을 의미 파이썬 내의 모든 객체는 일종으 클래스임 Object Class 7 int &amp;ldquo;Hello&amp;rdquo; str pd.DataFrame() DataFrame 해당 클래스를 찾기 위해 type( )를 사용함. import numpy as np temp = np.array([1, 2, 3]) print(type(temp)) &amp;lt;class &#39;numpy.ndarray&#39;&amp;gt; State + Behavior 그렇다면, State를 지칭하는 파이썬 문법은 무엇인가? 파이썬에서는 이를 Attributes라고 부른다. 또한, Behavior를 지칭하는 파이썬 문법은 무엇인가?</description>
    </item>
    
    <item>
      <title>GCP Kubernetes Engine을 통한 배포(2)</title>
      <link>https://dschloe.github.io/mlops/ch02_kubernetes/ch02_creating_kubernetes_engine_deployments/</link>
      <pubDate>Tue, 13 Apr 2021 19:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch02_kubernetes/ch02_creating_kubernetes_engine_deployments/</guid>
      <description>인프런 강의 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 (GCP) GKE를 활용하여 nginx를 실행해보자. Step 1. GCP Shell 활성화 You can list the active account name with this command: (your_project_id)$ gcloud auth list Credentialed Accounts ACTIVE ACCOUNT * student-04-e46af1f1cd7b@qwiklabs.net To set the active account, run: $ gcloud config set account `ACCOUNT` You can list the project ID with this command: (your_project_id)$ gcloud config list project [core] project = qwiklabs-gcp-04-79efc1e4ae0f Your active configuration is: [cloudshell-24251] Step 2.</description>
    </item>
    
    <item>
      <title>[Python] Open API를 활용한 Air Quality 데이터 수집 예제</title>
      <link>https://dschloe.github.io/python/newpkgs/py-openaq/</link>
      <pubDate>Wed, 07 Apr 2021 00:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/newpkgs/py-openaq/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 오픈 데이터로 활용하여 시계열 데이터를 확보해보자. 동기 부여 Pandas 공식 홈페이지가 살짝 바뀐 듯 하였다. 시계열 데이터를 다루는 페이지를 확인하던 중 open air quality data API가 있는 것을 확인하였다. Github: https://github.com/dhhagan/py-openaq 라이브러리 설치 라이브러리 설치는 비교적 간단하다.</description>
    </item>
    
    <item>
      <title>GCP Kubernetes Engine을 통한 배포(1)</title>
      <link>https://dschloe.github.io/mlops/ch02_kubernetes/ch01_deploying_kubernetes_engine/</link>
      <pubDate>Thu, 01 Apr 2021 21:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch02_kubernetes/ch01_deploying_kubernetes_engine/</guid>
      <description>인프런 강의 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 (GCP) GKE를 활용하여 nginx를 실행해보자. Step 1. GKE Cluster Setup 네비게이션 메뉴에서 Kubernetes Engine &amp;gt; Clusters를 클릭합니다. 위 화면에서 Create를 클릭합니다.
그 이후에, Cluster 이름은 standard-cluster-1으로 바꾸고, Zone은 us-central1-a로 바꿉니다.
나머지는 모두 Default로 그냥 놔둡니다.</description>
    </item>
    
    <item>
      <title>Docker Started using Cloud Build</title>
      <link>https://dschloe.github.io/mlops/ch01_docker/ch01_working_with_cloud_build/</link>
      <pubDate>Tue, 30 Mar 2021 22:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/ch01_docker/ch01_working_with_cloud_build/</guid>
      <description>인프런 강의 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 (GCP) Cloud Build를 활용하여 Docker를 활용해보자. Step 1. API Enabled 클라우드 네비게이션 메뉴에서 APIs &amp;amp; Services를 클릭한다. Enable APIs and Services를 클릭한다. Search for APIs &amp;amp; Services에서 Cloud Build를 입력한다. Cloud Build API를 클릭한 후, Enable 버튼을 클릭한다.</description>
    </item>
    
    <item>
      <title>Google Colab에서 Kaggle API 쉽게 사용하는 방법</title>
      <link>https://dschloe.github.io/settings/kaggle_api_easy_to_use/</link>
      <pubDate>Tue, 30 Mar 2021 16:31:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/kaggle_api_easy_to_use/</guid>
      <description>한줄 요약 귀찮지만 한 2개의 Cell은 입력후 실행하자. 개요 Google Colab에서 Kaggle을 사용하려면 보통 다음과 같은 과정을 거칩니다. 패키지 설치는 필수입니다. !pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.10) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1) Requirement already satisfied: six&amp;gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: tqdm in /usr/local/lib/python3.</description>
    </item>
    
    <item>
      <title>왜 Git 그래프가 채워지지 않는가?</title>
      <link>https://dschloe.github.io/settings/git_commit_issue/</link>
      <pubDate>Mon, 29 Mar 2021 15:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/git_commit_issue/</guid>
      <description>1줄 요약 이메일을 확인하자. 개요 필자는 강의를 위해 깃헙 계정이 여러개가 존재함 강사용 PC에서 지속적으로 Commit을 진행했으나 Github 그래프가 출력이 되지 않는 오류 발생을 해결하는 과정에서 확인 Github 질의 Why are my contributions not showing up on my profile? 이런 글이 있습니다.
그러나, 제 경우에는 제 개인 PC는 반영이 잘 되고, 강사 PC에는 안되는 상황이어서, 맞지 않은 케이스였습니다.
왜? 공통 이유 중의 하나는 이메일 이 때, 가장 중요한 것은 이메일입니다. 사실, 해당 내용에도 나오지만, 가장 흔한 이유 중의 하나라고 합니다.</description>
    </item>
    
    <item>
      <title>Introduction to MLOps</title>
      <link>https://dschloe.github.io/mlops/intro/</link>
      <pubDate>Sun, 28 Mar 2021 11:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/mlops/intro/</guid>
      <description>인프런 강의 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 1줄 요약 MLOps를 소개해본다. What is MLOps? 최근 기술 트렌드 중의 Hot한 주제는 DevOps이다.
Dev는 Development의 약어이며, Ops는 Operation의 약자이다. 과거에는 개발팀과 운영팀 두개로 존재하는 것이 상식이었지만, 가장 큰 문제는 Communication 문제! 이러한 문제점을 해결하기 위해 나온 방법론이 DevOps이다.</description>
    </item>
    
    <item>
      <title>Windows 10 KoNLP 설치</title>
      <link>https://dschloe.github.io/settings/konlp_issue/</link>
      <pubDate>Fri, 26 Mar 2021 14:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/konlp_issue/</guid>
      <description>한줄 요약 KoNLP는 여기에서 무조건 해결한다. KoNLP 이슈 R에서 텍스트 마이닝을 진행할 때에는 반드시 한번쯤은 패키지 설치로 인해 어려움을 겪는다. - R 입문자 분들이 초반에 호기롭게 시작하였다가 대부분 포기하려고 하는 지점이기도 하다. 사실, 조금 더 간편한 방법이 나오기를 기대한다. 1단계 Java 설치 및 환경 변수 설정 주의: 윈도우 10 64비트
여러 좋은 자료들이 많아서 같이 참고하기를 바란다.
Java 설치 관련: [JAVA] Windows에 자바 설치하기! 필자는 Java 8 version을 선택했다.
설치가 완료가 되면 아래 두개의 폴더가 있는지를 확인한다.</description>
    </item>
    
    <item>
      <title>트위터 데이터 수집 with R</title>
      <link>https://dschloe.github.io/r/newpkgs/rtweet/</link>
      <pubDate>Wed, 24 Mar 2021 11:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/newpkgs/rtweet/</guid>
      <description>1줄 요약 R을 활용하여 트위터 데이터를 수집하는 방법 및 절차에 대해 배우도록 한다. 트위터 API 인증 https://apps.twitter.com에 접속한다.
회원가입을 진행한다. create an app 버튼을 클릭한다. 필자는 Hobbysit-Exploring the API를 선택했다. 그 후에 개인 정보 등을 입력해야 한다. 휴대폰, 이메일 인증 등 인증 메일이 오기전까지는 조금 시일이 걸린다.
rtweet 패키지 별도의 인증 절차 없이 사용 가능한 패키지
https://github.com/ropensci/rtweet 우선 설치 후, 사용해보도록 한다.
본 코드는 Github 예제로 있는 코드를 가져온 것임 # install.</description>
    </item>
    
    <item>
      <title>disk.frame 패키지 소개</title>
      <link>https://dschloe.github.io/r/newpkgs/disk_frame/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://dschloe.github.io/r/newpkgs/disk_frame/</guid>
      <description>공지 대용량 데이터 전처리시에 필요한 패키지를 소개한다. url: https://www.youtube.com/watch?v=EOjObl_GSi4 주석은 가급적 원어를 남겨 놓으니 잘 번역하기를 바란다. 설치 설치 방법은 기존과 마찬가지로 간단하게 작성할 수 있다. install.packages(&amp;#34;disk.frame&amp;#34;) suppressPackageStartupMessages(library(disk.frame)) library(nycflights13) 패키지 주요 아이디어 메모리보다 많은 데이터를 각각의 chunks로 분해하여 하나의 폴더 안에 저장한다. (HDD 디스크 사용) 자세한 셜명은 Giuhub를 참고 (https://github.com/xiaodaigh/disk.frame) Setup 실습 환경을 구성한다. setup_disk.frame() ## The number of workers available for disk.frame is 1 # this allows large datasets to be transferred between sessions options(future.</description>
    </item>
    
    <item>
      <title>Linux 기본 명령어</title>
      <link>https://dschloe.github.io/settings/linux_command/</link>
      <pubDate>Tue, 09 Mar 2021 10:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/linux_command/</guid>
      <description>개요 기본 문법을 다뤄봅니다. (추가적으로 올리고 싶을 때마다 정리해서 올릴 예정입니다.) unzip 만약에 여러개의 zip 파일을 받는다면 어떻게 해야할까? 다음과 같이 할 수도 있다. $ unzip a.zip b.zip c.zip d.zip 코드가 조금 길어지는 것 같다. 간단하게 하면 다음과 같이 할 수도 있다. 캐글 대회 데이터를 직접 응용하도록 한다. $ kaggle competitions download -c sf-crime Warning: Looks like you&amp;#39;re using an outdated API Version, please consider updating (server 1.5.10 / client 1.</description>
    </item>
    
    <item>
      <title>CI CD Pipeline for Data Science</title>
      <link>https://dschloe.github.io/settings/ci_cd_pipeline/</link>
      <pubDate>Tue, 02 Mar 2021 16:31:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/ci_cd_pipeline/</guid>
      <description>개요 최근 밑바닥부터 시작하는 딥러닝 3로 수업을 수강생들과 진행하며 배포에 관한 내용이 있었습니다. (p 98). 구체적인 방법은 소개하지 않아서, 보충 자료로 작성하였다. 전 단계별로 진행하는데, 깃허브에 관한 기본적인 내용 및 코드는 알고 있다는 전제하에 작성하였다. 깃허브를 처음 접하시는 분들은 Github Project 포트폴리오를 참고하기를 바란다. 필요한 것 Github: https://github.com/ Travis-CI: https://www.travis-ci.com/ Codecov: https://about.codecov.io/ PyPI: https://pypi.org/ Steps - Travis Logins Travis에 깃허브로 로그인 한다. 아래와 같은 화면이 나오면 로그인이 잘 된 것이다. 영문 내용을 잘 읽어본다.</description>
    </item>
    
    <item>
      <title>Pandas read_csv skiprows 활용</title>
      <link>https://dschloe.github.io/python/pandas/pandas_skiprows/</link>
      <pubDate>Sat, 20 Feb 2021 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_skiprows/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 문제 개요 Kaggle 데이터 New York City Taxi Fare Prediction 데이터를 구글 코랩에서 Loading 하는 중 메모리 문제가 발생함 계통추출(Systematic Sampling)을 통해 데이터를 불러오기로 함 예제 실습 아래 예제를 통해서 실제로 데이터가 줄어드는지 확인을 해본다.</description>
    </item>
    
    <item>
      <title>ACEA Water, Intro to Time Series Forecasting</title>
      <link>https://dschloe.github.io/kaggle/acea_water/intro-to-time-series-forecasting/</link>
      <pubDate>Tue, 16 Feb 2021 18:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/acea_water/intro-to-time-series-forecasting/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 Overview Can you build a model to predict the amount of water in each waterbody to help preserve this natural resource? This is an Analytics competition where your task is to create a Notebook that best addresses the Evaluation criteria below.</description>
    </item>
    
    <item>
      <title>Tutorial of Ranzcr EDA</title>
      <link>https://dschloe.github.io/kaggle/tutorial-of-ranzcr-eda/</link>
      <pubDate>Thu, 11 Feb 2021 18:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/tutorial-of-ranzcr-eda/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 Competition https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification Intro Thanks to RANZCR/resnext50_32x4d starter [training] Please visit here and upvote import os import pandas as pd from matplotlib import pyplot as plt import seaborn as sns Check File Size Check Each Size of Dataset Folder in this competition train_records = 4.</description>
    </item>
    
    <item>
      <title>Kaggle API on Mac/Linux</title>
      <link>https://dschloe.github.io/kaggle/kaggle_api/</link>
      <pubDate>Fri, 05 Feb 2021 21:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/kaggle_api/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 새로운 학생들과 Kaggle 경진대회를 나가게 되었다. 참여 경진대회 VinBigData Chest X-ray Abnormalities Detection 기존에는 주로 Google Colab에서 했지만, 대용량 데이터부터 터미널로 다운로드 받아야 한다. 핵심 문장 kaggle.json 파일을 각 OS에 맞게 옮긴다.
Kaggle API 다운로드 계정 [Profile]-[My Account]를 클릭 후, 아래 화면에서 Kaggle API를 다운로드 받는다.</description>
    </item>
    
    <item>
      <title>Kaggle House Price ML</title>
      <link>https://dschloe.github.io/kaggle/house_price_ml/</link>
      <pubDate>Mon, 01 Feb 2021 09:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/house_price_ml/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 현재 책 출판 준비 중입니다. 구체적인 설명은 책이 출판된 이후에 요약해서 올리도록 합니다. 이전 글 Kaggle Feature Engineering - House Price URL: https://dschloe.github.io/kaggle/kaggle_feature_engineering/ 이전 글에서, Kaggle API, Feature Engineering에 대한 코드를 정리했으니, 참고하기를 바란다.</description>
    </item>
    
    <item>
      <title>Kaggle Feature Engineering - House Price</title>
      <link>https://dschloe.github.io/kaggle/kaggle_feature_engineering/</link>
      <pubDate>Thu, 28 Jan 2021 09:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/kaggle_feature_engineering/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 현재 책 출판 준비 중입니다. 구체적인 설명은 책이 출판된 이후에 요약해서 올리도록 합니다. Kaggle API Kaggle API를 활용한 데이터를 수집하는 예제는 Feature Engineering with Housing Price Prediction - Numerical Features 에서도 확인할 수 있기 때문에 생략 합니다.</description>
    </item>
    
    <item>
      <title>ml 개발환경 세팅</title>
      <link>https://dschloe.github.io/settings/m1_settings/</link>
      <pubDate>Thu, 21 Jan 2021 01:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/m1_settings/</guid>
      <description>개요 M1에서 GPU를 활용한 딥러닝을 수행하는 예제 코드를 구현해봤다.
참고: M1 tensorflow Test Preview Apple 공식 Repo대로 설치를 하면 잘 될 것이라 생각했지만, 생각지 못한 복병을 만났다.
어떻게 해결했는지 그 과정에 대해 잠깐 기술하려고 한다.
Rosetta 너는 누구니? 그동안 맥북은 인텔 기반의 Mac 프로세서를 사용해왔고, M1은 애플이 개발한 프로세서를 처음 도입한 것이다. 그런데, 이게 왜 문제가 되는 것일까? </description>
    </item>
    
    <item>
      <title>M1 tensorflow Test Preview</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/m1_tensorflow/</link>
      <pubDate>Sun, 17 Jan 2021 21:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/m1_tensorflow/</guid>
      <description>개요 M1에서 Tensorflow 테스트를 진행해본다. 현재 M1 시스템 환경은 아래와 같다. (2021-01-16) 주의: 텐서플로 공식 버전은 아님
라이브러리 설치 다음 코드를 설치해본다. Apple 공식 Repo: https://github.com/apple/tensorflow_macos 실행 전, 필수 체크 사항 macOS 11.0+ Python 3.8, available from the Xcode Command Line Tools $ /bin/bash -c &amp;#34;$(curl -fsSL https://raw.githubusercontent.com/apple/tensorflow_macos/master/scripts/download_and_install.sh)&amp;#34; Installation script for pre-release tensorflow_macos 0.1alpha1. Please visit https://github.com/apple/tensorflow_macos for instructions and license information. This script will download tensorflow_macos 0.1alpha1 and needed binary dependencies, then install them into a new or existing Python 3.</description>
    </item>
    
    <item>
      <title>Ch07_data_upload</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch07_data_load_from_local/</link>
      <pubDate>Fri, 08 Jan 2021 15:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch07_data_load_from_local/</guid>
      <description>공지 구글 빅쿼리 책 Chapter 4장 학습 참고 교재는 아래와 같다. 개요 로컬에서 데이터를 업로드 해본다. 데이터 다운로드 깃허브에서 데이터를 다운로드 받는다. $ git clone https://github.com/onlybooks/bigquery.git ch04 폴더로 이동한 뒤, 실제 압축된 파일의 내용을 페이지 단위로 확인해본다. 먼저 ch04 폴더로 이동한다. zlees 명령으로 데이터를 확인해본다. $ cd bigquery/ch04 $ zless college_scorecard.csv.gz 명령을 실행한 후 스페이스 이용하여 페이지 단위로 데이터 확인 후, 종료하려면 q키를 누른다. zless는 .gz과 같은 파일을 풀지 않고 Preview 형식으로 볼 수 있도록 도와준다.</description>
    </item>
    
    <item>
      <title>Ch06_gcloud_projects</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch06_gcloud_projects/</link>
      <pubDate>Thu, 07 Jan 2021 17:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch06_gcloud_projects/</guid>
      <description>개요 MacOS m1, Big Sur에서 gcloud 환경 세팅을 해본다. 목표는 gcloud를 설치 한 뒤, 신규 프로젝트를 설치하도록 한다. gcloud projects list 현재 active project를 실행하여 보여주는 명령어를 실행하여 확인한다. 프로젝트는 각 계정마다 조금씩 다를 수 있다. $ gcloud projects list PROJECT_ID NAME PROJECT_NUMBER biggquerysample biggquerysample 826877287968 New gcloud projects 이제 새로운 프로젝트를 만들어본다. $ gcloud projects create bigquerysample2 Create in progress for [https://cloudresourcemanager.googleapis.com/v1/projects/your_project_name]. Waiting for [your_number_will_be_created] to finish...done. Enabling service [cloudapis.</description>
    </item>
    
    <item>
      <title>Ch05_gcloud_settings</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch05_gcloud_settings/</link>
      <pubDate>Thu, 07 Jan 2021 11:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch05_gcloud_settings/</guid>
      <description>개요 MacOS m1, Big Sur에서 gcloud 환경 세팅을 해본다. 목표는 gcloud를 설치 한 뒤, 신규 프로젝트를 설치하도록 한다. Cloud SDK 시작 전 MacOS에서는 Python이 필요하다. 지원되는 버전은 Python3(권장, 3.5 ~ 3.8) 및 Python 2 (2.7.9) 이상이다. 만약 Python이 설치되지 않았다면 추가로 설치를 진행해야 한다. https://www.python.org/ Cloud SDK 시작 필요한 파일 및 설치 참고 자료는 공식홈페이지: 빠른 시작: Cloud SDK 시작하기 에서 확인한다. 압축 파일을 풀고 해당 경로로 이동한다. 이 때, 환경문제가 발생할 수 있으니, 가급적 .</description>
    </item>
    
    <item>
      <title>Kaggle Countplot with Text using Seaborn</title>
      <link>https://dschloe.github.io/kaggle/kaggle_seabon_countplot/</link>
      <pubDate>Wed, 06 Jan 2021 23:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/kaggle_seabon_countplot/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 수강생 중 1명이 캐글 경진대회에 참여하고 있는데, 시각화의 어려움을 같이 해결하면서 팁을 공유한다. 도구: Python + Seaborn + Matplotlib 캐글 데이터: https://www.kaggle.com/c/kaggle-survey-2020/notebooks?competitionId=23724&amp;amp;sortBy=voteCount 캐글 데이터 연동 캐글 데이터를 구글 드라이브에 업로드 한 뒤 구글 코랩과 연동한다.</description>
    </item>
    
    <item>
      <title>matplotlib 03_2 Scatter Plot</title>
      <link>https://dschloe.github.io/python/matplotlib/matplotlib_03_02_scatterplot/</link>
      <pubDate>Mon, 04 Jan 2021 22:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/matplotlib/matplotlib_03_02_scatterplot/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 산점도 그래프 산점도는 두 수치형 변수의 분포를 비교하고 두 변수 사이에 상관 관계가 있는지 여부를 확인하는 데 사용됩니다. 데이터 내에 구별되는 군집/분할이 있으면 산점도에서도 명확해집니다.
(1) 라이브러리 불러오기 필요한 라이브러리를 불러옵니다.
import matplotlib.pyplot as plt import numpy as np import seaborn as sns (2) 데이터 생성 이번에는 seaborn 패키지 내 tips 데이터를 활용합니다.</description>
    </item>
    
    <item>
      <title>(Mac) Python 기본 환경설정 및 주피터 노트북 설치</title>
      <link>https://dschloe.github.io/settings/jupyter_notebook_mac/</link>
      <pubDate>Sun, 03 Jan 2021 00:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/jupyter_notebook_mac/</guid>
      <description>개요 M1 맥북을 구입 후, 환경 설정을 하다보며, 기록을 남기기로 하였다. 환경변수에 대해 살짝 다루도록 한다. Jupyter Notebook 설치를 진행해본다. Note: 아나콘다가 아닌, Python 공식홈페이지에서 다운 받은 것을 전제로 한다. 설정 1. zsh to bash 환경으로 바꾸기 필자는 zsh는 잘 쓰지 않았다. 그런데, Mac은 Default로 bash 환경을 쓴다. 써보지 않았기에, bash로 바꾸도록 한다. (쉽다!) $ chsh -s /bin/bash 위 설정을 진행한 후, 터미널을 종료한 뒤 다시 시작한다. 만약, 현재 쉘 스크립트를 알고자 하면 아래와 같은 명령어를 입력하도록 한다.</description>
    </item>
    
    <item>
      <title>Hugo Blog 옮기기</title>
      <link>https://dschloe.github.io/settings/hugo_blog/</link>
      <pubDate>Wed, 30 Dec 2020 17:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/hugo_blog/</guid>
      <description>개요 새로운 맥을 구입하면서 생긴 여러 에러를 해결하면서 기록으로 남겼다. 선수 학습 본 포스트는 기존 hugo 깃허브 블로그를 운영중인 독자들을 위한 글이다. 만약 깃허브 블로그를 처음 만드시는 분은 공식 홈페이지를 참조하기를 바란다. https://gohugo.io/getting-started/installing/ 기존 블로그 활용 필자는 blog라는 깃허브 repo가 존재하였음 따라서, blog 레포를 내려 받았다. $ git clone https://github.com/yourname/your_repo.git 상황 1. submodule에 대한 충분하지 못한 이해 필자가 실수한 것이 있다. github에서 submodule은 영어 단어 그대로, 서브 모듈이다. 즉, 한개의 메인 프로젝트가 존재하지만, 다른 프로젝트는 공통으로 사용할 모듈이라는 뜻이다.</description>
    </item>
    
    <item>
      <title>Git 명령어 중급편</title>
      <link>https://dschloe.github.io/settings/git_intermediate/</link>
      <pubDate>Tue, 22 Dec 2020 21:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/git_intermediate/</guid>
      <description>개요 커밋을 하기 전에 확인해야 할 기본적인 명령어 등을 확인해본다. tracked 상태의 파일을 untracked 상태로 변경하는데, 스테이지에 등록하는 것과 반대 과정이라고 보면 된다. stage 상태에 있는 것을 unstage 상태로 변경하려면 삭제(rm)나 리셋(reset) 명령어를 사용한다. 파일 등록 취소 rm 명령어로 삭제 하려면, 기억해야 하는 것은 스테이지 영역에서만 등록된 파일을 삭제하려면 --cached 옵션을 함께 사용한다. $ git rm --cached main.py rm &amp;#39;main.py&amp;#39; 캐시 목록에서 파일이 삭제가 된 이후에 git status를 실행해본다. $ git status On branch master Changes to be committed: (use &amp;#34;git reset HEAD &amp;lt;file&amp;gt;.</description>
    </item>
    
    <item>
      <title>Git 명령어 기본편</title>
      <link>https://dschloe.github.io/settings/git_basic/</link>
      <pubDate>Mon, 21 Dec 2020 21:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/git_basic/</guid>
      <description>개요 깃 명령어의 기본적인 명령어를 실행하는 것을 목표로 한다. 깃 설치 및 깃허브 설치는 기존 게시글을 확인해본다. Github Project 포트폴리오 Git 환경설정 git 명령어를 입력 시, 제대로 실행되지 않았다면 환경변수를 추가한다. 윈도우에서 제어판을 실행한 후 시스템 &amp;gt; 고급 시스템 설정 &amp;gt; 고급 &amp;gt; 환경 변수를 작성한다. 시스템 변수 항목에서 Path를 더블클릭하도록 한다. 환경 변수 편집 창에 C:\Program Files\Git\cmd 경로를 추가한다. 영상을 통해서 한번 보도록 한다. Git 기본문법 git의 명령어의 기본 문법은 아래와 같다.</description>
    </item>
    
    <item>
      <title>NLP - From Word2Vec TO GPT-3</title>
      <link>https://dschloe.github.io/python/nlp/ch11_the_nlp_lectures/</link>
      <pubDate>Sun, 20 Dec 2020 00:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/nlp/ch11_the_nlp_lectures/</guid>
      <description>개요 본 포스트는 자연어처리의 주요 흐름에 관해 간단하게 정리한 내용이다. 일종의 모음집이라고 하면 좋을 것 같다. 구체적인 자연어 이론에 대한 설명은 대해서는 유투브 영상 및 그 와 다양한 자료들을 참고하도록 하자. . 사전 학습의 개념 사전 학습 모델이란 기존에 자비어(Xavier) 등 임의의 값으로 초기화된 모델의 가중치들을 다른 문제(task)에 학습시킨 가중치들로 초기화하는 방법이다. 이미지 분류에서는 보통 전이학습이라는 용어를 사용하기도 했다. 자연어에서의 가장 대표적인 사전학습 모델이 버트와 GPT이다. 현재는 이러한 대부분의 자연어 처리 모델이 언어 모델을 사전 학습한 모델을 활용하도록 한다.</description>
    </item>
    
    <item>
      <title>정형데이터와 함께하는 텍스트 마이닝</title>
      <link>https://dschloe.github.io/python/nlp/ch08_kaggle_price_challenge/</link>
      <pubDate>Sat, 19 Dec 2020 10:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/nlp/ch08_kaggle_price_challenge/</guid>
      <description>공지 해당 포스트는 취업 준비반 대상 강의 교재로 파이썬 머신러닝 완벽가이드를 축약한 내용입니다. 매우 좋은 책이니 가급적 구매하시기를 바랍니다. 개요 Mercari Price Suggestion Challenge는 캐글에서 진행된 과제이며, 제공되는 데이터 세트는 제품에 대한 여러 속성 및 제품 설명 등의 텍스트 데이터로 구성된다. 데이터 세트는 다음 링크에서 확인한다. https://www.kaggle.com/c/mercari-price-suggestion-challenge/data 데이터 다운로드 데이터를 다운로드 받도록 한다. !pip install kaggle !sudo apt install p7zip p7zip-full # 7z 파일을 풀기 위한 것이다. Requirement already satisfied: kaggle in /usr/local/lib/python3.</description>
    </item>
    
    <item>
      <title>텍스트 마이닝 - 감성 분석</title>
      <link>https://dschloe.github.io/python/nlp/ch04_sentiment_analysis/</link>
      <pubDate>Sun, 13 Dec 2020 10:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/nlp/ch04_sentiment_analysis/</guid>
      <description>공지 해당 포스트는 취업 준비반 대상 강의 교재로 파이썬 머신러닝 완벽가이드를 축약한 내용입니다. 매우 좋은 책이니 가급적 구매하시기를 바랍니다. 감성 분석 개요 문서의 주관적인 감성/의견/감정/기분 등을 파악하기 위한 방법으로 소셜 미디어, 여론조사, 온라인 리뷰, 피드백 등 다양한 분야에서 활용되고 있다. 감성 분석은 크게 지도학습 &amp;amp; 비지도학습 방식으로 수행된다. 데이터는 캐글 대회 데이터를 활용하였다. 따라서, 본 포스트에서는 지도학습 기반과 비지도학습 기반의 감성 분석을 실습한다. 데이터 불러오기 각각 필요한 데이터를 불러오도록 한다. from google.</description>
    </item>
    
    <item>
      <title>텍스트 마이닝 - 뉴스 분류</title>
      <link>https://dschloe.github.io/python/nlp/ch03_news_group_classification/</link>
      <pubDate>Thu, 10 Dec 2020 10:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/nlp/ch03_news_group_classification/</guid>
      <description>공지 해당 포스트는 취업 준비반 대상 강의 교재로 파이썬 머신러닝 완벽가이드를 축약한 내용입니다. 매우 좋은 책이니 가급적 구매하시기를 바랍니다. 텍스트 분류 실습 - 뉴스그룹 분류 개요 사이킷런은 fetch_20newsgroups API를 이용해 뉴스그룹의 분류를 수행해 볼 수 있는 예제 데이터 활용 가능함. 희소 행렬에 분류를 효과적으로 처리할 수 있는 알고리즘은 로지스틱 회귀, 선형 서포트 벡터 머신, 나이브 베이즈 등임. 텍스트 정규화 fetch_20newsgroups()는 인터넷에서 데이터를 받은 후, 올리는 것이기 때문에 인터넷 연결 유무를 확인한다.</description>
    </item>
    
    <item>
      <title>입문자를 위한 머신러닝 - 오차행렬</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/ch03_confusion_matrix/</link>
      <pubDate>Wed, 02 Dec 2020 10:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/ch03_confusion_matrix/</guid>
      <description>용어 정리 영어로는 confusion matrix로 불리우지만, 번역하면서 다양한 단어가 등장하고 있다. 오차행렬, 혼동행렬 제목은 오차행렬이라고 표현했지만, 영어 단어를 그대로 살려 confusion matrix라고 활용한다. Confusion Matrix 분류 모형을 통해 머신러닝을 학습하게 되면 confusion matrix 표를 우선 작성하게 된다. 이 표에서 무엇을 볼 수 있는가?
우선 전체 데이터의 크기를 확인할 수 있다. (165명) 예측값 YES는 (100+10) 110명이고, 예측값 NO는 (50+5) 55명이다. 실제값 YES는 (100+5) 105명이고, 실제값 NO는 (50+10) 60명이다. 기본 영어를 정의해본다.</description>
    </item>
    
    <item>
      <title>입문자를 위한 머신러닝 - GBM</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/ch02_gbm/</link>
      <pubDate>Sun, 29 Nov 2020 13:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/ch02_gbm/</guid>
      <description>공지 본 소스코는 교재 파이썬 머신러닝 완벽 가이드 코드를 제 수업을 드는 학생들이 보다 편하게 구글 코랩에서 사용할 수 있도록 만든 예제입니다. 책 구매하세요! http://www.yes24.com/Product/Goods/87044746?OzSrank=1 Gradient Boosting Machine 이제 GBM에 대해 학습하도록 합니다. GBM에 대해 이해하기 위해서는 경사하강법에 대해 배워야 합니다. 경사하강법은 쉽게 말하면 가장 적은 오차를 찾아가는 방법론 중이 하나입니다. 자세한 내용은 유투 강의를 들어주시기를 바랍니다. (Gradient Descent, Step-by-Step) 위 이론을 sklearn에서 구현한 것이며, 이 이론을 기반으로 다양한 알고리즘이 개발 되어 있습니다.</description>
    </item>
    
    <item>
      <title>입문자를 위한 머신러닝 - 랜덤 포레스트</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/ch01_randomforest/</link>
      <pubDate>Fri, 27 Nov 2020 21:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/ch01_randomforest/</guid>
      <description>공지 본 포스트는 교재 파이썬 머신러닝 완벽 가이드 코드를 제 수업을 드는 학생들이 보다 편하게 구글 코랩에서 사용할 수 있도록 만든 예제입니다. 책 구매하세요! http://www.yes24.com/Product/Goods/87044746?OzSrank=1 Random Forest 랜덤 포레스트의 개요
배깅의 대표적인 알고리즘 랜덤 포레스트는 개별 트리가 학습하는 데이터 세트는 전체 데이터에서 일부가 중첩되게 샘플링 된 데이터 세트 부트스트래핑 부할 방식 채택 참고 강의 이론 https://www.youtube.com/watch?v=Z97uDTsvojY https://www.youtube.com/watch?v=J4Wdy0Wc_xQ !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip !unzip &amp;#39;UCI HAR Dataset.zip&amp;#39; !mv UCI\ HAR\ Dataset human_activity --2020-11-27 05:21:51-- https://archive.</description>
    </item>
    
    <item>
      <title>텍스트 마이닝 - 희소행렬</title>
      <link>https://dschloe.github.io/python/nlp/ch02_bag_of_words_coo_csr/</link>
      <pubDate>Wed, 25 Nov 2020 10:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/nlp/ch02_bag_of_words_coo_csr/</guid>
      <description>공지 해당 포스트는 취업 준비반 대상 강의 교재로 파이썬 머신러닝 완벽가이드를 축약한 내용입니다. 매우 좋은 책이니 가급적 구매하시기를 바랍니다. 개요 피처 벡터화에 있어서의 희소행렬에 대해 배운다. BOW 형태를 가진 언어 모델의 피처 벡터화는 대부분 희소 행렬이다. 희소행렬 희소 행렬은 너무 많은 불필요한 0 값이 메모리 공간에 할당되어 메모리 공간을 많이 차지하는데 있다. 다음 그림을 살펴보자. 이러한 희소 행렬을 물리적으로 적은 메모리 공간을 차지할 수 있도록 변환해야 하는데, 이 때, COO와 CSR 형식이 존재한다.</description>
    </item>
    
    <item>
      <title>텍스트 마이닝 - Bag of Words</title>
      <link>https://dschloe.github.io/python/nlp/ch02_bag_of_words/</link>
      <pubDate>Sun, 22 Nov 2020 14:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/nlp/ch02_bag_of_words/</guid>
      <description>공지 해당 포스트는 취업 준비반 대상 강의 교재로 파이썬 머신러닝 완벽가이드를 축약한 내용입니다. 매우 좋은 책이니 가급적 구매하시기를 바랍니다. I. 개요 문서가 가지는 모든 단어(Words)를 문맥이나 순서를 무시하고 일괄적으로 단어에 대해 빈도 값을 부여하여 피처 값을 추출하는 모델을 말한다. 아래와 같은 세 개의 문장이 있다고 가정해본다. Doc 1: I love dogs. Doc 2: I hate dogs and knitting. Doc 3: Knitting is my hobby and passion. 위 문장을 각각의 행렬로 표현하면 아래와 같다.</description>
    </item>
    
    <item>
      <title>(Ref) Tools to Design or Visualize Architecture of Neural Network</title>
      <link>https://dschloe.github.io/settings/tools_design_for_neural_network/</link>
      <pubDate>Fri, 20 Nov 2020 14:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/tools_design_for_neural_network/</guid>
      <description>소개 항상 좋은 글을 올려주시는 존경하는 Pega님의 소개로 올려드립니다. Pega님 블로그: https://jehyunlee.github.io/ Tools to Design or Visualize Architecture of Neural Network draw_convnet : Python script for illustrating Convolutional Neural Network (ConvNet) NNSVG PlotNeuralNet : Latex code for drawing neural networks for reports and presentation. Have a look into examples to see how they are made. Additionally, lets consolidate any improvements that you make and fix any bugs to help more people with this code.</description>
    </item>
    
    <item>
      <title>텍스트 마이닝 - 텍스트 전처리</title>
      <link>https://dschloe.github.io/python/nlp/ch01_text_mining/</link>
      <pubDate>Wed, 18 Nov 2020 14:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/nlp/ch01_text_mining/</guid>
      <description>I. 개요 NLP(Natural Language Processing): 기계가 인간의 언어를 이해하고 해석하는 데 중점 활용예제: 기계 번역, 챗봇, 질의응답 시스템 (딥러닝) Text Analysis: 비정형 텍스트에서 의미 있는 정보를 추출하는 것에 중점 활용예제: 비즈니스 인텔리전스, 예측분석 (머신러닝) 텍스트 분석의 예 텍스트 분류: 문서가 특정 분류 또는 카테고리에 속하는 것을 예측하는 기법 감성 분석: 텍스트에서 나타나는 감정/판단/믿음/의견 등의 주관적인 요소 분석하는 기법 텍스트 요약: 텍스트 내에서의 중요한 주제나 중심 사상 추출(Topic Modeling) 텍스트 군집화(Clustering)와 유사도 측정: 비슷한 유형의 문서에 대해 군집화를 수행하는 기법.</description>
    </item>
    
    <item>
      <title>List to Pandas</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/list_pandas/</link>
      <pubDate>Mon, 09 Nov 2020 18:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/list_pandas/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 List는 파이썬 데이터 타입의 기본 자료형이다. Pandas 데이터 분석을 위한 기본적인 자료형이다. List에서 Pandas로 변환하는 작업의 다양한 방법을 활용해본다. 방법 1. 기초 List를 생성한 후, 데이터프레임으로 변환한다. 여기에서는 column과 index값을 확인해본다. import pandas as pd lst = [&amp;#34;Korea&amp;#34;, &amp;#34;Japan&amp;#34;, &amp;#34;USA&amp;#34;, &amp;#34;China&amp;#34;, &amp;#34;Russia&amp;#34;] data = pd.</description>
    </item>
    
    <item>
      <title>Seaborn intro - Correlation Heatmap</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_seaborn_heatmap/</link>
      <pubDate>Wed, 04 Nov 2020 20:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_seaborn_heatmap/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 Seaborn 개요 Matplotlib 라이브러리가 Python에서 제공하는 기본적인 시각화 도구이지만, 기본객체는 리스트 형태를 따르기 때문에, 엑셀 데이터, 즉 데이터 프레임에 익숙한 사용자들에게는 조금 불친절한 것은 아쉬움이 있습니다. 실제, 입문자를 대상으로 강의를 할 때에도 Seaborn부터 알려드리는데, 그 이유는 Pandas를 활용한 데이터 가공 직후에 보다 쉽게 연동할 수 있도록 Seaborn이 개발되었기 때문입니다.</description>
    </item>
    
    <item>
      <title>Python 통계 - 비모수 통계</title>
      <link>https://dschloe.github.io/python/python_edu/05_statistics/chapter_17_1_nonparametric_stat_analysis/</link>
      <pubDate>Tue, 03 Nov 2020 00:05:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/05_statistics/chapter_17_1_nonparametric_stat_analysis/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 분포에 대한 가정을 만족 못할 시의 문제점 1종 오류의 값이 커지거나, 분석 결과 자체에 대한 신뢰성이 떨어짐 1종 오류 및 2종 오류의 차이 모수 통계 분석 적용 못할 시, 비모수 통계 분석 활용 (1) 언제 적용할까?</description>
    </item>
    
    <item>
      <title>Seaborn Intro - Countplot</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_seaborn_countplot/</link>
      <pubDate>Thu, 29 Oct 2020 20:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_seaborn_countplot/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 Seaborn 개요 Matplotlib 라이브러리가 Python에서 제공하는 기본적인 시각화 도구이지만, 기본객체는 리스트 형태를 따르기 때문에, 엑셀 데이터, 즉 데이터 프레임에 익숙한 사용자들에게는 조금 불친절한 것은 아쉬움이 있습니다. 실제, 입문자를 대상으로 강의를 할 때에도 Seaborn부터 알려드리는데, 그 이유는 Pandas를 활용한 데이터 가공 직후에 보다 쉽게 연동할 수 있도록 Seaborn이 개발되었기 때문입니다.</description>
    </item>
    
    <item>
      <title>Seaborn intro - boxplot</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_seaborn_boxplot/</link>
      <pubDate>Wed, 28 Oct 2020 19:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_seaborn_boxplot/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 Seaborn 개요 Matplotlib 라이브러리가 Python에서 제공하는 기본적인 시각화 도구이지만, 기본객체는 리스트 형태를 따르기 때문에, 엑셀 데이터, 즉 데이터 프레임에 익숙한 사용자들에게는 조금 불친절한 것은 아쉬움이 있습니다. 실제, 입문자를 대상으로 강의를 할 때에도 Seaborn부터 알려드리는데, 그 이유는 Pandas를 활용한 데이터 가공 직후에 보다 쉽게 연동할 수 있도록 Seaborn이 개발되었기 때문입니다.</description>
    </item>
    
    <item>
      <title>Seaborn Intro - Scatterplot, Histogram</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_seaborn_numeric/</link>
      <pubDate>Mon, 26 Oct 2020 23:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_seaborn_numeric/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 Seaborn 개요 Matplotlib 라이브러리가 Python에서 제공하는 기본적인 시각화 도구이지만, 기본객체는 리스트 형태를 따르기 때문에, 엑셀 데이터, 즉 데이터 프레임에 익숙한 사용자들에게는 조금 불친절한 것은 아쉬움이 있습니다. 실제, 입문자를 대상으로 강의를 할 때에도 Seaborn부터 알려드리는데, 그 이유는 Pandas를 활용한 데이터 가공 직후에 보다 쉽게 연동할 수 있도록 Seaborn이 개발되었기 때문입니다.</description>
    </item>
    
    <item>
      <title>KDX Competition Guideline</title>
      <link>https://dschloe.github.io/r/competition/blog_kdx_guideline/</link>
      <pubDate>Wed, 14 Oct 2020 09:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/competition/blog_kdx_guideline/</guid>
      <description>개요 본 수업을 듣는 수강생들을 위해 간단한 튜토리얼을 만들었다. 대회는 다음과 같다. 싸이트: 한국데이터거래소 /img/r/competition/blog_kdx_guideline_files/img 1단계 패키지 불러오기 데이터 가공 및 시각화 위주의 패키지를 불러온다. library(tidyverse) # 데이터 가공 및 시각화 library(readxl) # 엑셀파일 불러오기 패키지 2단계 데이터 불러오기 데이터가 많아서 순차적으로 진행하도록 한다. 각 데이터에 대한 설명은활용데이터설명(PDF)을 참조한다. 먼저 제 개발환경은 아래와 같다. Note: 윈도우와 Mac은 다를 수 있음을 명심하자. sessionInfo() ## R version 4.0.2 (2020-06-22) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.</description>
    </item>
    
    <item>
      <title>(R&#43;Git) 초보자를 위한 깃허브 연동 및 에러 대처법</title>
      <link>https://dschloe.github.io/settings/rstudio_git_beginner/</link>
      <pubDate>Tue, 06 Oct 2020 09:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/rstudio_git_beginner/</guid>
      <description>개요 본 Repo는 강림직업전문학교 수강생을 위해 예시로 작성한 Repo입니다. 본 Repo에서는 R을 활용한 데이터 과학 발표자료를 공유하기 위해 만들어졌습니다. Git &amp;amp; Github 우선 Git을 설치합니다.
싸이트: https://git-scm.com/ 설정은 모두 기본 값으로 해주시기 바랍니다. Terimnal 창에서 git을 실행하여 정상적으로 설치되었는지 유무를 확인합니다.
그 다음은 Github에 회원가입을 합니다
저장소를 만드는 과정은 아래 싸이트를 참조바랍니다. 싸이트: https://goddaehee.tistory.com/221 이제 RStudio에서 프로젝트를 클릭한 후 아래 화면에서 Version Control을 클릭합니다.
그 다음은 github에서 주소를 클릭합니다. 복사한 주소를 아래그림과 같이 주소를 붙여 넣습니다.</description>
    </item>
    
    <item>
      <title>(파이썬-Matplotlib) 시각화 튜토리얼 - 히트맵</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_heatmap/</link>
      <pubDate>Fri, 02 Oct 2020 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_heatmap/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 히트맵 그래프 히트 맵(heat map)은 열을 뜻하는 히트(heat)와 지도를 뜻하는 맵(map)을 결합시킨 단어로, 다양한 강도로 다양한 색상으로 데이터 범위를 시각화하는 데 사용된다. 여기서는 상관 행렬을 열 지도로 표시하는 예를 들 수 있다. 상관 행렬의 요소는 두 변수 사이의 선형 관계의 강도를 나타내며, 행렬에는 주어진 데이터에 포함된 속성의 모든 조합에 대한 그러한 값이 포함되어 있다.</description>
    </item>
    
    <item>
      <title>(파이썬-Matplotlib) 시각화 튜토리얼 - 박스플롯</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_boxplot/</link>
      <pubDate>Thu, 01 Oct 2020 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_boxplot/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 박스플롯 그래프 박스플롯(Box Plot) 그래프는 범주형 데이터 기준으로 수치형 데이터의 분포를 파악하는데 적합하다.
박스플롯을 보면, 최소값, 1분위값, 중간값, 3분위값, 최대값을 제공한다.
(1) 라이브러리 불러오기 필요한 모듈을 불러온다.
import matplotlib.pyplot as plt import numpy as np import seaborn as sns (2) 데이터 생성 이번에는 seaborn 패키지 내 iris 데이터를 활용한다.</description>
    </item>
    
    <item>
      <title>(파이썬-Matplotlib) 시각화 튜토리얼 - 히스토그램</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_histogram/</link>
      <pubDate>Tue, 29 Sep 2020 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/ch_histogram/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 히스토그램 히스토그램 그래프는 연속형 변수의 분포를 그리는 데 사용된다. 연속형 변수 값은 필요한 빈(=bin) 수로 분활되어 x축에 표시되며, 각 빈에 포함되는 값의 카운트는 y축에 표시된다. y축에는 카운트 대신 총량의 백분율을 표시할 수 있으며, 이 경우 확률 분포를 나타내며, 이러한 그래프는 통계 분석에 사용된다.</description>
    </item>
    
    <item>
      <title>(NCS) R 기초문법</title>
      <link>https://dschloe.github.io/r/ncs/r_basic_1/</link>
      <pubDate>Fri, 18 Sep 2020 10:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/ncs/r_basic_1/</guid>
      <description>I. 개요 R을 처음 접하는 사람들을 위한 입문 포스트. 기존에 R을 하셨던 분들은 가볍게 보도록 한다. 프로그램을 설치한다. 필수 R: https://www.r-project.org/ 옵션(1) RStudio: https://rstudio.com/ 옵션(2) PyCharm: https://www.jetbrains.com/ko-kr/pycharm/download/ R은 일종의 엔진이기 때문에 필수로 설치한다. 파이썬과 같이 쓰는 유저라면 PyCharm을 R만 사용한다면 RStudio를 사용한다. (1) 데이터 분석의 기본 흐름 데이터 수집, 저장, 가공, 시각화, 모델링, 보고서 (대시보드) 입문자, 서비스 기획자는 전체의 생태계를 보자. PDF - 강사 메뉴얼 참조 II. CRAN 생태계 이해하기 전세계의 수많은 사람들과 조직들이 데이터, 통계, 머신러닝 등 다양한 문제를 해결하기 위해 여러 함수를 만들어 공유하는 곳입니다.</description>
    </item>
    
    <item>
      <title>Feature Engineering with Housing Price Prediction - Numerical Features</title>
      <link>https://dschloe.github.io/kaggle/chapter_4_4_house_price_prediction_feature_engineering3/</link>
      <pubDate>Wed, 16 Sep 2020 12:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/chapter_4_4_house_price_prediction_feature_engineering3/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Feature Engineering를 이해하고 실습한다. 결측치를 처리한다 Categorical Feature를 다룬다. I. 사전 준비작업 Kaggle API 설치 후 데이터를 Kaggle에서 직접 가져오는 것을 구현한다. (1) Kaggle API 설치 구글 코랩에서 API를 불러오려면 다음 소스코드를 실행한다. !</description>
    </item>
    
    <item>
      <title>Feature Engineering with Housing Price Prediction - Categorical Features</title>
      <link>https://dschloe.github.io/kaggle/chapter_4_4_house_price_prediction_feature_engineering2/</link>
      <pubDate>Sat, 12 Sep 2020 22:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/chapter_4_4_house_price_prediction_feature_engineering2/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Feature Engineering를 이해하고 실습한다. 결측치를 처리한다 Categorical Feature를 다룬다. I. 사전 준비작업 Kaggle API 설치 후 데이터를 Kaggle에서 직접 가져오는 것을 구현한다. (1) Kaggle API 설치 구글 코랩에서 API를 불러오려면 다음 소스코드를 실행한다. !</description>
    </item>
    
    <item>
      <title>OCE 패키지 소개</title>
      <link>https://dschloe.github.io/r/newpkgs/oce_intro/</link>
      <pubDate>Sat, 12 Sep 2020 00:21:01 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/newpkgs/oce_intro/</guid>
      <description>개요 새로운 분야에 대한 자료 정리는 언제나 흥미롭다. 오늘은 해양과학을 분석해보는 시간을 갖는다. 사실 필자는 해양과학을 모른다. 교재 교재 Oceanographic Analysis with R는 구매할 수 있다. 패키지 설치 패키지 홈페이지를 참고한다. 패키지 저자는 CRAN에서 다운로드 받는 것 보다는 깃허브에서 받는 것을 추천한다. 패키지 업데이트가 1년에 몇번 되지 않는다고 조금은 솔직하게 말한다. # install.packages(&amp;#34;oce&amp;#34;, dependencies = TRUE) library(oce) ## Loading required package: gsw ## Loading required package: testthat Evolution of oce 홈페이지에서 Oce는 오픈 소스 시스템으로 소개하고 있기 때문에, 관련 학문에 종사하는 사람들이 참여 해주는 것이 해당 패키지 발전에 매우 중요한 부분이다.</description>
    </item>
    
    <item>
      <title>Validation schemes for 2-nd level models</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/validation_schemes/</link>
      <pubDate>Fri, 11 Sep 2020 21:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/validation_schemes/</guid>
      <description>There are a number of ways to validate second level models (meta-models). In this reading material you will find a description for the most popular ones. If not specified, we assume that the data does not have a time component. We also assume we already validated and fixed hyperparameters for the first level models (models).
Simple holdout scheme Split train data into three parts: partA and partB and partC. Fit N diverse models on partA, predict for partB, partC, test_data getting meta-features partB_meta, partC_meta and test_meta respectively.</description>
    </item>
    
    <item>
      <title>Feature Engineering with Housing Price Prediction - Missing Values</title>
      <link>https://dschloe.github.io/kaggle/chapter_4_4_house_price_prediction_feature_engineering1/</link>
      <pubDate>Thu, 10 Sep 2020 17:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/chapter_4_4_house_price_prediction_feature_engineering1/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 Feature Engineering를 이해하고 실습한다. 결측치를 처리한다. I. 사전 준비작업 Kaggle API 설치 후 데이터를 Kaggle에서 직접 가져오는 것을 구현한다. (1) Kaggle API 설치 구글 코랩에서 API를 불러오려면 다음 소스코드를 실행한다. !pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.</description>
    </item>
    
    <item>
      <title>Python 통계 - 확률의 정의</title>
      <link>https://dschloe.github.io/python/python_edu/05_statistics/chapter_5_4_concept_probability/</link>
      <pubDate>Wed, 09 Sep 2020 21:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/05_statistics/chapter_5_4_concept_probability/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 확률기초이론 이산확률분포: 베르누이분포, 이항분포, 포아송분포 연속확률분포: 정규분포, 카이제곱분포, t-분포, F-분포 확률이란? 경험 또는 실험의 결과로 특정한 사건(event)이나 결과가 발생할 가능성 예1) 주사위 던져서 1이 나올 가능성 1/6 예2) 비가 올 가능성 30% (1) 확률의 정의 사건 A의 확률 = $\frac{n(A)}{N}$ N = 표본공간(=sample space) = 특정 실험에서 일어날 수 있는 모든 가능성</description>
    </item>
    
    <item>
      <title>Python 통계 - T검정 예제</title>
      <link>https://dschloe.github.io/python/python_edu/05_statistics/chapter_5_3_ttest_sample/</link>
      <pubDate>Sun, 06 Sep 2020 12:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/05_statistics/chapter_5_3_ttest_sample/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 통계분석을 활용한 문제해결 과정 비즈니스에서 통계는 그저 툴이다. 통계를 몰라도 물건을 파는데 전혀 문제가 없다. 통계는 객관적인 근거를 확보하여 유효한 의사결정을 내리기 위한 그저 도구 (Tool) 이다. 따라서, 마케팅이나 CRM과 같은 경영이슈에서도 통계는 문제해결을 이한 체계적인 절차를 제공한다.</description>
    </item>
    
    <item>
      <title>삼성카드 대회 Track-2 - 포지셔닝 분석(2)</title>
      <link>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_4/</link>
      <pubDate>Fri, 04 Sep 2020 10:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_4/</guid>
      <description>대회 소개 삼성카드 데이터분석 공모전이 시행되고 있다. 대회에 처음 참여하는 아시아경제-수강생들을 위해 일종의 가이드라인으로 제안하고자 한다. 본 포스트에서는 기본적인 내용만 전달하고자 함을 밝힌다. Track2 과정은 마케팅 전략 제안이 중요하다! 포지셔닝 분석 개요 마케팅에서 자주 보는 분석 방법중의 하나는 포지셔닝(Positioning) 기법이다. 포지셔닝 분석은 마케팅 통계분석 기법중의 하나로, 기업이나, 상품, 브랜드 같은 개체들의 포지셔닝을 수행하는 다차원 척도법(MDS: Multi-Dimensional Scaling)과 상응분석(Correspondence Analysis)이 있다. 위 두가지 분석 방법 중 무엇을 사용해야 할까? 만약 데이터셋이 주로 등간척도, 비율척도와 같이 구성되어 있다면 다차원 척도법 만약 데이터셋이 주로 명목척도, 서열척도와 같이 구성되어 있다면 상응분석 현재 삼성카드 대회의 주 데이터셋은 명목척도 및 서열척도로 구성되어 있기 때문에 상응분석으로 시작하면 된다.</description>
    </item>
    
    <item>
      <title>삼성카드 대회 Track-2 - 포지셔닝 분석(1)</title>
      <link>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_3/</link>
      <pubDate>Fri, 04 Sep 2020 02:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_3/</guid>
      <description>대회 소개 삼성카드 데이터분석 공모전이 시행되고 있다. 대회에 처음 참여하는 아시아경제-수강생들을 위해 일종의 가이드라인으로 제안하고자 한다. 본 포스트에서는 기본적인 내용만 전달하고자 함을 밝힌다. Track2 과정은 마케팅 전략 제안이 중요하다! 포지셔닝 분석 개요 마케팅에서 자주 보는 분석 방법중의 하나는 포지셔닝(Positioning) 기법이다. 포지셔닝 분석은 마케팅 통계분석 기법중의 하나로, 기업이나, 상품, 브랜드 같은 개체들의 포지셔닝을 수행하는 다차원 척도법(MDS: Multi-Dimensional Scaling)과 상응분석(Correspondence Analysis)이 있다. 위 두가지 분석 방법 중 무엇을 사용해야 할까? 만약 데이터셋이 주로 등간척도, 비율척도와 같이 구성되어 있다면 다차원 척도법 만약 데이터셋이 주로 명목척도, 서열척도와 같이 구성되어 있다면 상응분석 현재 삼성카드 대회의 주 데이터셋은 명목척도 및 서열척도로 구성되어 있기 때문에 상응분석으로 시작하면 된다.</description>
    </item>
    
    <item>
      <title>머신러닝 알고리즘 - 결정트리 회귀모형</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_3_regression_tree/</link>
      <pubDate>Thu, 03 Sep 2020 18:18:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_3_regression_tree/</guid>
      <description>I. 개요 결정트리 회귀 모형에 대해 배우도록 한다. 트리모형의 일반적인 특징에 대해 익힌다. II. 결정 트리 모형 결정 트리는 분류, 회귀, 다중출력 작업도 가능한 활용범위가 많은 머신러닝 알고리즘이다. 결정 트리는 최근에 사용하는 랜덤포레스트, XGboost, LightGBM과 같은 모형의 기본 구성 요소이다. (1) 의사결정 나무 예제 의사 결정 나무에서 자주 사용되는 예제를 우선 확인해보자.
먼저, 데이터셋을 기준으로 IRIS 붓꽃의 종류는 아래와 같이 3가지로 구성되어 있다.
Versicolor, Setosa, Virginica 위 이미지에서 보는 것처럼, 종에 따라 잎의 크기가 다른 것을 확인할 수 있다.</description>
    </item>
    
    <item>
      <title>Python 통계 - 포지셔닝 분석(2)</title>
      <link>https://dschloe.github.io/python/python_edu/05_statistics/chapter_5_2_positioning_analysis_2/</link>
      <pubDate>Thu, 03 Sep 2020 10:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/05_statistics/chapter_5_2_positioning_analysis_2/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 포지셔닝 분석 개요 마케팅에서 자주 보는 분석 방법중의 하나는 포지셔닝(Positioning) 기법이다. 포지셔닝 분석은 마케팅 통계분석 기법중의 하나로, 기업이나, 상품, 브랜드 같은 개체들의 포지셔닝을 수행하는 다차원 척도법(MDS: Multi-Dimensional Scaling)과 상응분석(Correspondence Analysis)이 있다. 위 두가지 분석 방법 중 무엇을 사용해야 할까?</description>
    </item>
    
    <item>
      <title>Python 통계 - 포지셔닝 분석(1)</title>
      <link>https://dschloe.github.io/python/python_edu/05_statistics/chapter_5_1_positioning_analysis_1/</link>
      <pubDate>Wed, 02 Sep 2020 20:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/05_statistics/chapter_5_1_positioning_analysis_1/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 포지셔닝 분석 개요 마케팅에서 자주 보는 분석 방법중의 하나는 포지셔닝(Positioning) 기법이다. 포지셔닝 분석은 마케팅 통계분석 기법중의 하나로, 기업이나, 상품, 브랜드 같은 개체들의 포지셔닝을 수행하는 다차원 척도법(MDS: Multi-Dimensional Scaling)과 상응분석(Correspondence Analysis)이 있다. 위 두가지 분석 방법 중 무엇을 사용해야 할까?</description>
    </item>
    
    <item>
      <title>삼성카드 대회 Track-2 - matplotlib 막대 그래프</title>
      <link>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_2/</link>
      <pubDate>Wed, 02 Sep 2020 15:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_2/</guid>
      <description>대회 소개 삼성카드 데이터분석 공모전이 시행되고 있다. 대회에 처음 참여하는 아시아경제-수강생들을 위해 일종의 가이드라인으로 제안하고자 한다. 본 포스트에서는 기본적인 내용만 전달하고자 함을 밝힌다. Track2 과정은 마케팅 전략 제안이 중요하다! 환경 세팅 먼저, 데이터가 모두 한글로 구성이 되어 있기 때문에 한글파일 설정부터 진행한다. 한글파일 설정이 완료되면 구글 드라이브와 연동한다. 데이터 시각화를 진행한다. %config InlineBackend.figure_format = &amp;#39;retina&amp;#39; !sudo apt-get -qq -y install fonts-nanum fonts-nanum is already the newest version (20170925-1). The following package was automatically installed and is no longer required: libnvidia-common-440 Use &#39;apt autoremove&#39; to remove it.</description>
    </item>
    
    <item>
      <title>머신러닝 지도학습 - 선형회귀</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_3_regression_basic/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:05 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_3_regression_basic/</guid>
      <description>I. 개요 머신러닝으로서 회귀 모형에 대해 숙지한다. 회귀 모형의 기본적인 개념과 평가 지표에 대해 숙지한다. II. 회귀 모형 개요 회귀(Regression)은 통계 이론 중 가장 기본이다. 회귀의 기원은 영국의 통계학자 갈톤(Galton)이 수행한 연구에서 유래한다. 부모와 자식 간의 키의 상관관계를 분석하였는데, 키가 작은 가정과 키가 큰 가정을 살펴본 결과, 무한정 작아지지도 않고, 무한정 커지지 않아 일정한 평균으로 회귀하려는 자연적 법칙을 발견했다는 것이 기원이다. (1) 회귀식의 개요 회귀는 1차 방정식이다. 지역, 방의 면적, 크기 등 여러 개의 독립변수에 따라 아파트 가격이라는 종속변수가 어떠한 관계를 나타내는지를 예측하고 모델링하는 것 즉, 수치를 예측할 때 사용한다.</description>
    </item>
    
    <item>
      <title>입문자를 위한 머신러닝 개요</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_2_ml_intro/</link>
      <pubDate>Tue, 01 Sep 2020 10:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_2_ml_intro/</guid>
      <description>개요 캐글 데이터를 불러오는 방법에 대해 숙지한다. 머신러닝의 일반적인 내용에 대해 숙지한다. I. 사전 준비작업 Kaggle API 설치 및 연동해서 GCP에 데이터를 적재하는 것까지 진행한다. (1) Kaggle API 설치 구글 코랩에서 API를 불러오려면 다음 소스코드를 실행한다. !pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6) Requirement already satisfied: urllib3&amp;lt;1.25,&amp;gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20) Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.</description>
    </item>
    
    <item>
      <title>삼성카드 대회 Track-2 데이터 고려 사항 (1)</title>
      <link>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_1/</link>
      <pubDate>Mon, 31 Aug 2020 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/competition/samsungcard20/samsung_card_track_2_1/</guid>
      <description>대회 소개 삼성카드 데이터분석 공모전이 시행되고 있다. 대회에 처음 참여하는 아시아경제-수강생들을 위해 일종의 가이드라인으로 제안하고자 한다. 본 포스트에서는 기본적인 내용만 전달하고자 함을 밝힌다. Track2 과정은 마케팅 전략 제안이 중요하다! 환경 세팅 먼저, 데이터가 모두 한글로 구성이 되어 있기 때문에 한글파일 설정부터 진행한다. 한글파일 설정이 완료되면 구글 드라이브와 연동한다. 데이터 시각화를 진행한다. %config InlineBackend.figure_format = &amp;#39;retina&amp;#39; !sudo apt-get -qq -y install fonts-nanum The following package was automatically installed and is no longer required: libnvidia-common-440 Use &#39;apt autoremove&#39; to remove it.</description>
    </item>
    
    <item>
      <title>DataFrame의 변수 추가 및 삭제</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/chapter_4_6_datatransformation/</link>
      <pubDate>Sun, 30 Aug 2020 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/chapter_4_6_datatransformation/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 데이터 개요 German Credit Card를 활용하여 데이터를 가공하도록 한다. 데이터셋에 대한 설명은 Kaggle에서 확인한다. import pandas as pd print(pd.__version__) 1.0.5 url = &amp;#39;https://raw.githubusercontent.com/chloevan/kaggle2portpolio/master/datasets/german_credit_data.csv&amp;#39; german_credit = pd.read_csv(url) german_credit.head(3) Unnamed: 0 Age Sex Job Housing Saving accounts Checking account Credit amount Duration Purpose 0 0 67 male 2 own NaN little 1169 6 radio/TV 1 1 22 female 2 own little moderate 5951 48 radio/TV 2 2 49 male 1 own little NaN 2096 12 education Pandas DataFrame은 Index와 나머지 열로 구성이 되어 있다.</description>
    </item>
    
    <item>
      <title>Geospatial Analysis Using Python - Basic</title>
      <link>https://dschloe.github.io/python/python_edu/03_datavisualisation/chapter_2_3_1_geospatial_analysis_using_python/</link>
      <pubDate>Sun, 23 Aug 2020 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/03_datavisualisation/chapter_2_3_1_geospatial_analysis_using_python/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 파이썬을 활용한 공간 시각화에 대해 기술하도록 한다. 각 패키지의 쓰임새와 용도를 확인하도록 한다. 예제를 통해 확인한 뒤, 국내 데이터를 적용해보도록 한다. 한글 폰트상의 문제점 외에 다른 문제점은 없는지 확인해본다. 우선 참고한 자료는 아래와 같다.</description>
    </item>
    
    <item>
      <title>Seaborn Visualisation Tutorial - Basic</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/step1_visualisation/seaborn_basic_tutorial/</link>
      <pubDate>Fri, 21 Aug 2020 11:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/step1_visualisation/seaborn_basic_tutorial/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
시각화 기본적 원리 비교, 대조, 차이를 드러내라. 인과관계와 상관관계를 보여라. 한 도표에 여러 변수를 보여라. 텍스트, 숫자, 이미지, 그래프 같은 데이터들을 한 곳에 통합하라. 사용된 데이터의 출처를 그래프 안이나 각주로 밝혀라. 의미 있는 내용을 담아라. 데이터 시각화를 정말 잘하고 싶다면, 책을 구매하는 것을 추천한다.</description>
    </item>
    
    <item>
      <title>입문자를 위한 머신러닝 튜토리얼 - 교차검증</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_2_cross_val/</link>
      <pubDate>Thu, 20 Aug 2020 00:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_2_cross_val/</guid>
      <description>개요 교차검증의 의미를 이해한다. 교차검증을 위한 간단한 실습을 진행한다. 교차검증이란 교차검증은 기본적으로 과적합을 예방하기 위한 방법론 중 하나이다. 교차검증을 쉽게 이해하는 방법은 수능시험을 보기 위해 수능과 비슷한 유형의 모의고사를 보는 것과 같다. (1) K폴드 교차검증 개요 데이터의 수가 적을 때 사용한다. 검증 데이터의 수도 적기 때문에 검증 성능의 신뢰도가 떨어진다. 이 때, K-폴드 방법을 사용한다. 그림을 보며 이해하자. 데이터의 편향을 방지하기 위한 것 데이터를 K개로 나누어 K-1개를 분할하고 나머지는 평가에 사용 모델의 검증 점수는 K개의 검증 점수 평균이 된다.</description>
    </item>
    
    <item>
      <title>입문자를 위한 머신러닝 분류 튜토리얼 - Decision Tree</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_5_understanding_tree/</link>
      <pubDate>Wed, 19 Aug 2020 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_5_understanding_tree/</guid>
      <description>개요 사이킷런(scikit-learn)은 파이썬 머신러닝 라이브러리이다. 파이썬에서 나오는 최신 알고리즘들도 이제는 사이킷런에 통합하는 형태로 취하고 있다. 구글 코랩은 기본적으로 사이킷런까지 설치가 완료되기에 별도의 설치가 필요없는 장점이 있다. Note: 본 포스트는 머신러닝 자체를 처음 접하는 분들을 위한 것이기 때문에, 어느정도 경험이 있으신 분들은 필자의 다른 포스트를 읽어주시기를 바랍니다. 패키지 불러오기 패키지는 시간에 지남에 따라 계속 업그레이드가 되기 때문에 꼭 버전 체크를 하는 것을 권장한다. 필자가 글을 남겼을 때는 2020년 8월 16일에 작성했음을 기억하자.</description>
    </item>
    
    <item>
      <title>입문자를 위한 머신러닝 분류 튜토리얼 - IRIS 분류</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_4_classification_iris_example/</link>
      <pubDate>Mon, 17 Aug 2020 01:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_4_classification_iris_example/</guid>
      <description>개요 사이킷런(scikit-learn)은 파이썬 머신러닝 라이브러리이다. 파이썬에서 나오는 최신 알고리즘들도 이제는 사이킷런에 통합하는 형태로 취하고 있다. 구글 코랩은 기본적으로 사이킷런까지 설치가 완료되기에 별도의 설치가 필요없는 장점이 있다. Note: 본 포스트는 머신러닝 자체를 처음 접하는 분들을 위한 것이기 때문에, 어느정도 경험이 있으신 분들은 필자의 다른 포스트를 읽어주시기를 바랍니다. 패키지 불러오기 패키지는 시간에 지남에 따라 계속 업그레이드가 되기 때문에 꼭 버전 체크를 하는 것을 권장한다. 필자가 글을 남겼을 때는 2020년 8월 16일에 작성했음을 기억하자.</description>
    </item>
    
    <item>
      <title>Data Science Resources</title>
      <link>https://dschloe.github.io/ds-projects/resources/</link>
      <pubDate>Thu, 13 Aug 2020 10:35:28 +0900</pubDate>
      
      <guid>https://dschloe.github.io/ds-projects/resources/</guid>
      <description>개요 제 개인 참조하려고 만든 게시글입니다. 언제나 좋은 글 및 싸이트, 패키지를 만들어 배포하는 모든 Data Scientist, Analyst 분들 존경합니다. (1) Tools R with Google Colab 이미지 다운로더 I. 머신러닝/딥러닝 관련 자료 (1) 머신러닝 XGBoost Lightgbm Documentation: https://lightgbm.readthedocs.io/en/latest/ LightGBM R-Packages Regression metrics review I Weighted Median Evaluation Metrics for Classification Problems: Quick Examples + References Decision Trees: “Gini” vs. “Entropy” criteria Understanding ROC curves Learning to Rank using Gradient Descent Overview of further developments of RankNet RankLib Learning to Rank Overview Clustering Complete Machine Learning Guide to Parameter Tuning in Gradient Boosting (GBM) in Python Matrix Factorization Overview of Matrix Decomposition methods (sklearn) t-SNE Multicore t-SNE implementation Comparison of Manifold Learning methods (sklearn) How to Use t-SNE Effectively (distill.</description>
    </item>
    
    <item>
      <title>NumPy with ndarray</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_8_numpy/</link>
      <pubDate>Tue, 11 Aug 2020 18:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_8_numpy/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 Numpy ndarray 개요 넘파이 array()는 ndarray로 변환 가능 생성된 ndarray배열의 shape변수는 ndarray의 크기, 행과 열의 수를 튜플 형태로 가지고 있으며, 이를 통해 ndarray 배열의 차원까지 알 수 있음 (1) 배열이란? NumPy에서 배열은 동일한 타입의 값을 가짐 shape는 각 차원의 크기를 튜플로 표시한다.</description>
    </item>
    
    <item>
      <title>xgboost and kaggle with R</title>
      <link>https://dschloe.github.io/r/machine_learning/3_6_xgboost/</link>
      <pubDate>Mon, 10 Aug 2020 11:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/machine_learning/3_6_xgboost/</guid>
      <description>개요 R 강의를 진행하면서 xgboost를 R로 구현하고 싶었다. kaggle에 있는 데이터를 불러와서 제출까지 가는 과정을 담았으니 입문자들에게 작은 도움이 되기를 바란다. XGBoost 개요 논문 제목 - XGBoost: A Scalable Tree Boosting System 논문 게재일: Wed, 9 Mar 2016 01:11:51 UTC (592 KB) 논문 저자: Tianqi Chen, Carlos Guestrin 논문 소개 Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges.</description>
    </item>
    
    <item>
      <title>Kaggle with R</title>
      <link>https://dschloe.github.io/kaggle/kaggle_with_r/</link>
      <pubDate>Sat, 08 Aug 2020 21:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/kaggle_with_r/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 개요 R 입문부터 머신러닝까지 가르치게 되었다. R을 활용한 빅데이터 분석 실제 Kaggle 대회 참여 독려를 위해 R에서 Kaggle 데이터를 불러와 머신러닝을 진행하는 것을 기획하였다. pins 패키지를 활용하면 보다 쉽게 할 수 있다. (1) Kaggle API with R 먼저 [Kaggle]에 회원 가입을 한다.</description>
    </item>
    
    <item>
      <title>ch 13 - Reliability</title>
      <link>https://dschloe.github.io/r/thesis/ch_13_reliability/</link>
      <pubDate>Tue, 04 Aug 2020 21:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_13_reliability/</guid>
      <description>Intro PLS-SEM의 분석과정에서 척도(측정변수와 잠재변수)의 신뢰도와 타당도를 확보하는 것은 매우 중요하며, 신뢰도와 타당도가 확보되지 않으면 모델 추정 결과가 의미가 없기 때문임 즉, 구조모델의 추정을 실행하려면 사전에 반드시 측정모델에 대한 평가과정을 통해 신뢰도와 타당도 확보 필요 I. 주요 개념 (1) 신뢰도 잠재변수의 측정에 있어서 얼마나 일관성이 있는가의 정도 의미 검사도구의 일관성을 말하며, 일관성이란 잠재변수를 여러 번에 걸쳐 측정했을 때 매번 같은 결과를 도출할 수 있는 정도. 내적 일관성 신뢰(Internal Consistency Reliability)로 평가 (2) 타당도 타당도의 기본 정의는 실제 측정하고자 하는 잠재변수를 정확하게 측정하고 있는 정도 PLS-SEM에서는 집중타당도(Convergent Validity)와 판별타당도(Discriminant Validity)를 사용한다.</description>
    </item>
    
    <item>
      <title>Global Development Resources</title>
      <link>https://dschloe.github.io/settings/resources/</link>
      <pubDate>Fri, 31 Jul 2020 10:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/resources/</guid>
      <description>공지 제 전공과 관련하여 주요 자료를 정리하였습니다. 데이터과학의 다양한 이론 중에서 국제개발에 적용시킬만한 내용이 무엇인지 고민하며 계속적으로 자료를 업데이트 할 예정입니다.
OECD 자료 DAC Peer Review Reference Guide 대략 5년 마다 한번씩 각 회원국들의 개발협력 정책과 사업들에 대해 면밀히 검토를 하고 있으며, 연간 6개 회원국들을 대상으로 한다. 이 때, 위 문서를 근거로 동료 평가를 시행한다. OECD Development Co-operation Peer Reviews: Korea 2018 한국어: OECD 개발협력 동료검토 Peer Reviews 대한민국 2018 UN 자료 The Sustainable Development Goals Report 2020 Project Management Project Cycle Management Project Design Matrix Logical Framework Approach </description>
    </item>
    
    <item>
      <title>ch 12 - Demographic of Respondent in R</title>
      <link>https://dschloe.github.io/r/thesis/ch_12_demographic_of_respondents_blog/</link>
      <pubDate>Thu, 30 Jul 2020 16:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_12_demographic_of_respondents_blog/</guid>
      <description>Intro 지난 시간에 설문조사 전처리에 대해 배웠다면 이번에는 경영/사회과학 논문에서 필수적으로 기재해야 하는 표본의 특성을 간단한 프로그램으로 요약하는 것을 코딩한다. (1) 주요 패키지 이번 포스트부터 gt 패키지를 사용하려고 한다. gt: ggplot2와 같이 Table를 문법으로 컨트롤 할 수 있도록 구현된 패키지이다. kableExtra: HTML로 출력할 수 있도록 도와주는 패키지이다. library(readr) library(dplyr) library(gt) library(gtsummary) I. 데이터 가져오기 우선 데이터를 불러온다. data &amp;lt;- read_csv(&amp;#39;data/thesis_mater.csv&amp;#39;) %&amp;gt;% distinct() %&amp;gt;% # 중복데이터 제거 rename(Position = founder_employee, # 출력을 위한 변수명 정리 Age = age_of_respondent, Education = Education_Level) glimpse(data %&amp;gt;% select(Firm_Age:Business_Area)) 전체 34개의 변수 중에서, 문자열 관련 데이터만 추출하였다.</description>
    </item>
    
    <item>
      <title>ch05 - Log Scale Visualisation</title>
      <link>https://dschloe.github.io/r/datavisualisation/ch05_logscale_viz/</link>
      <pubDate>Wed, 29 Jul 2020 00:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/datavisualisation/ch05_logscale_viz/</guid>
      <description>공지 본 포스트는 데이터 시각화 교과서 내용의 일부를 요약하였다. 본 포스트를 읽고 가급적 전체 내용 숙지를 위해 구매하는 것을 권유한다. 개요 수치형 자료를 Y축으로 놓는 그래프는 언제나 힘들었다. log Scale을 통해 값의 크기를 줄이기는 하지만, Y축을 어떻게 표현하는 것이 좋을지에 대한 고민은 늘 있어왔다. 시각화 이론 중심의 포스팅이기에 코드 리뷰 및 해석은 생략한다. 문제점 log Scale을 적용했을 때와 그렇지 않을 때의 그래프를 비교해본다. (1) 패키지 불러오기 각각의 패키지를 불러온다. 이 때, 데이터는 dviz.</description>
    </item>
    
    <item>
      <title>ch 11 - Data Import &amp; Label Encoding in R</title>
      <link>https://dschloe.github.io/r/thesis/ch_11_import_data_blog/</link>
      <pubDate>Tue, 28 Jul 2020 12:30:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_11_import_data_blog/</guid>
      <description>Intro 설문조사가 끝났으면 이제 정리를 해야 한다. 일련의 과정은 보통 코딩이라 부른다. (1) 주요 패키지 이번 포스트부터 gt 패키지를 사용하려고 한다. gt: ggplot2와 같이 Table를 문법으로 컨트롤 할 수 있도록 구현된 패키지이다. kableExtra: HTML로 출력할 수 있도록 도와주는 패키지이다. 문제점 SmartPLS 프로그램을 쓴다 하더라도 기본적으로 모든 데이터의 entry는 수치형으로 일단 바뀌어 있어야 한다. 우선 데이터를 불러와서 확인해보자. library(tidyverse) library(gt) library(kableExtra) # 데이터 불러오기 data &amp;lt;- read_csv(&amp;#34;data/thesis_mater.csv&amp;#34;) data %&amp;gt;% head() %&amp;gt;% kable() %&amp;gt;% kable_styling(&amp;#34;striped&amp;#34;) %&amp;gt;% scroll_box(width = &amp;#34;100%&amp;#34;) EI_1 EI_2 EI_3 EP_1 EP_2 EP_3 ER_1 ER_2 ER_3 SS_1 SS_2 SS_3 SC_1 SC_2 SC_3 SR_1 SR_2 SR_3 F1 F2 F3 NF1 NF2 NF3 Firm_Age Firm_Size WE1 WE2 WE3 gender founder_employee age_of_respondent Education_Level Business_Area 2 3 4 3 3 4 3 2 4 1 1 3 3 3 3 2 2 1 2 2 3 3 1 3 5 years above Above 15 members No, I don&#39;t have experience Yes Yes Female Employee 30-39 Undergraduate School Others 5 5 2 3 5 3 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 Less than 2 years Less than 5 members No, I don&#39;t have experience No Yes Male Employee Younger than 30 Undergraduate School Media and Entertainment 1 2 2 1 1 2 1 2 1 2 2 1 1 2 2 1 2 1 2 1 1 1 1 1 5 years above Less than 5 members As founder or employee, I have startup experiences more than 3 times No Yes Female Founder of Company Younger than 30 Undergraduate School Others 3 3 2 1 2 1 2 1 3 2 1 3 1 1 1 2 3 3 3 3 2 3 2 2 Less than 2 years Less than 5 members No, I don&#39;t have experience Yes Yes Male Employee Younger than 30 Undergraduate School Others 5 3 5 2 5 4 4 4 4 4 5 4 5 5 5 5 5 5 4 5 4 4 5 5 3-4 years Less than 5 members As founder or employee, I have startup experiences more than 3 times No Yes Male Founder of Company 30-39 Undergraduate School Others 1 3 3 1 3 3 2 3 1 4 1 2 3 3 1 2 2 1 1 2 3 1 3 1 5 years above 5-9 members As founder or employee, I have startup experience, one time No No Female Employee Younger than 30 Undergraduate School Others 위 데이터에서 보면 알 수 있듯이, WE1 ~ Business_Area 까지의 데이터는 모두 문자로 되어 있다.</description>
    </item>
    
    <item>
      <title>ch 10 - 연구모델 개발과 가설 설정</title>
      <link>https://dschloe.github.io/r/thesis/ch_10_conceptual_model/</link>
      <pubDate>Mon, 27 Jul 2020 09:30:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_10_conceptual_model/</guid>
      <description>I. 연구모델 개발과 가설 설정 교재에서는 스마트폰 프로젝트의 연구모델 데이터를 기반으로 작성하였지만, 이번 포스트 이후 부터는 필자의 학위논문 데이터를 기반으로 책 내용과 병행하려고 한다. (1) 연구모델 개요 학위논문 주제: The Mediating Effect of Entrepreneurial Performance on the Relationship between Entrepre-neurial Orientation and Social Capital: The cases from the Philippines 주요요인은 기업가적지향성, 사회적자본이며, 종속변수는 기업의 성과로 구성되어 있다. 설문지 공개관련: 설문지 Sample이 필요하신 분들은 2021년 2월 이후에 요청하기를 바란다. (졸업이후) 교재는 스마트폰 프로젝트의 연구 모델이라는 주제로 Sample 설문지 문항에 대한 내용이 있다.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 제주 신용카드 데이터 경진대회 피벗테이블 작성</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/02_ml_simple_tutorial/</link>
      <pubDate>Mon, 27 Jul 2020 00:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/02_ml_simple_tutorial/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 본 포스트는 필자의 수업을 듣는 사람들을 위해 작성하였습니다. I. 구글 드라이브와 Colab과 연동 구글 드라이브와 Colab과 연동하면 보다 쉽게 데이터에 접근할 수 있다. 구글 인증만 하면 된다. # Google Drive와 마운트 from google.colab import drive ROOT = &amp;#39;/content/drive&amp;#39; drive.</description>
    </item>
    
    <item>
      <title>ch 09 - PLS-SEM 통계 분석기법(2)</title>
      <link>https://dschloe.github.io/r/thesis/ch_09_2_stat_method_with_pls_sem/</link>
      <pubDate>Sun, 26 Jul 2020 20:30:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_09_2_stat_method_with_pls_sem/</guid>
      <description>I. PLS-SEM 통계 기초 교재를 참고하여 통계 기초에 대한 간단한 설명을 서술한다. 이는 다른 통계 책에도 있는 내용이기는 하다. 지난 시간에, PLS-SEM의 분포, 유의 수준과 신뢰수준의 관계, 신뢰도와 타당도, 탐색적 요인분석과 확인적 요인분석, 회귀분석에 대해 설명함 참조: PLS-SEM 통계 분석기법(1) (1) 추정과 신뢰구간 추정(estimation)이란 모집단에 대한 어떠한 정보도 없는 상태에서 모집단을 대표할 수 있는 표본 추출하여 표본의 통계량을 구한 다음 이를 이용해서 모집단의 모수 예측 점추정(Point Estimation): 추정하고자 하는 모수를 하나의 수치로 추정 신뢰구간 추정(Confidence Interval Estimation): 추정하고자 하는 모수가 존재하리라고 예상되는 신뢰구간을 정하여 추정하는 방법 신뢰구간에서는 보통 t분포 이용.</description>
    </item>
    
    <item>
      <title>ch 09 - PLS-SEM 통계 분석기법(1)</title>
      <link>https://dschloe.github.io/r/thesis/ch_09_1_stat_method_with_pls_sem/</link>
      <pubDate>Sat, 25 Jul 2020 20:30:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_09_1_stat_method_with_pls_sem/</guid>
      <description>I. PLS-SEM 통계 기초 교재를 참고하여 통계 기초에 대한 간단한 설명을 서술한다. 이는 다른 통계 책에도 있는 내용이기는 하다. (1) PLS-SEM의 분포 PLS-SEM은 검증 통계량으로 t분포와 t값을 활용함. t분포는 평균이 0, 표준편차가 1인 종모양의 좌우대칭인 분포 유의수준 확인 지표는 p값을 활용함. (사회과학 분야에서는 유의수준 5% 이내) (2) 유의수준과 신뢰수준의 관계 유의수준이 $\alpha$ 이면 신뢰수준은 $1−\alpha$ 가 됨. 즉, 신뢰수준은 허용오차수준인 유의수준에 따라 결정됨. (3) 신뢰도(Reliability)와 타당도(Validity) PLS-SEM은 측정모델과 구조모델을 동시에 분석함.</description>
    </item>
    
    <item>
      <title>딥러닝 소개 - Object Detection</title>
      <link>https://dschloe.github.io/python/python_edu/07_deeplearning/option_mask_rcnn_camera_demo/</link>
      <pubDate>Fri, 24 Jul 2020 09:22:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/07_deeplearning/option_mask_rcnn_camera_demo/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 본 자료는 강의 수업의 보충 자료로 사용되었습니다. 자세한 내용은 Reference를 확인하시기를 바랍니다. Setup File 외부 설정 파일이 필요하다. 참조: Mask R-CNN for Object Detection and Segmentation shell script에서 작성한다. %%shell # clone Mask_RCNN repo and install packages git clone https://github.</description>
    </item>
    
    <item>
      <title>머신러닝 알고리즘 - 분류 Tutorial</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_4_classification/</link>
      <pubDate>Thu, 23 Jul 2020 10:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_4_classification/</guid>
      <description>개요 Kaggle 대회인 `Titanic&amp;rsquo;대회를 통해 분류 모형을 만들어본다. 본 강의는 수업 자료의 일부로 작성되었다. I. 사전 준비작업 Kaggle API 설치 및 연동해서 GCP에 데이터를 적재하는 것까지 진행한다. (1) Kaggle API 설치 구글 코랩에서 API를 불러오려면 다음 소스코드를 실행한다. !pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6) Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: urllib3&amp;lt;1.25,&amp;gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: python-slugify in /usr/local/lib/python3.</description>
    </item>
    
    <item>
      <title>CNN with Computer Vision</title>
      <link>https://dschloe.github.io/python/python_edu/07_deeplearning/chapter_7_4_cnn_vision/</link>
      <pubDate>Wed, 22 Jul 2020 17:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/07_deeplearning/chapter_7_4_cnn_vision/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 본 Tutorial은 교재 핸즈온 머신러닝 2판를 활용하여 본 강사로부터 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다..
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 분은 반드시 교재를 구매하실 것을 권해드립니다.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 제주 신용카드 데이터 경진대회 Colab with Drive</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/01_ml_simple_tutorial/</link>
      <pubDate>Mon, 20 Jul 2020 18:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/01_ml_simple_tutorial/</guid>
      <description>공지 본 포스트는 필자의 수업을 듣는 사람들을 위해 작성하였습니다. I. 구글 드라이브와 Colab과 연동 구글 드라이브와 Colab과 연동하면 보다 쉽게 데이터에 접근할 수 있다. 구글 인증만 하면 된다. # Google Drive와 마운트 from google.colab import drive ROOT = &amp;#39;/content/drive&amp;#39; drive.mount(ROOT) Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&amp;amp;redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&amp;amp;response_type=code&amp;amp;scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly Enter your authorization code: ·········· Mounted at /content/drive (1) 데이터 다운로드 제주 신용카드 데이터를 다운로드 받는다. (회원가입 필수) 웹사이트: 제주 신용카드 빅데이터 경진대회 (2) 구글 드라이브에 다운로드 받은 폴더를 올린다.</description>
    </item>
    
    <item>
      <title>딥러닝 소개 - 텐서플로 기본</title>
      <link>https://dschloe.github.io/python/python_edu/07_deeplearning/chapter_7_3_1_tensorflow_basic/</link>
      <pubDate>Sat, 18 Jul 2020 17:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/07_deeplearning/chapter_7_3_1_tensorflow_basic/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 본 Tutorial은 교재 핸즈온 머신러닝 2판를 활용하여 본 강사로부터 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 분은 반드시 교재를 구매하실 것을 권해드립니다.</description>
    </item>
    
    <item>
      <title>딥러닝 소개 - 심층 신경망 훈련하기</title>
      <link>https://dschloe.github.io/python/python_edu/07_deeplearning/chapter_7_2_training_deep_neural_network/</link>
      <pubDate>Fri, 17 Jul 2020 18:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/07_deeplearning/chapter_7_2_training_deep_neural_network/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 본 Tutorial은 교재 핸즈온 머신러닝 2판를 활용하여 본 강사로부터 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 분은 반드시 교재를 구매하실 것을 권해드립니다.</description>
    </item>
    
    <item>
      <title>머신러닝 알고리즘 - LightGbm</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_3_lightgbm/</link>
      <pubDate>Thu, 16 Jul 2020 23:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_3_lightgbm/</guid>
      <description>개요 주택가격을 예측하는 데 필요한 Kaggle 데이터를 불러와서 빅쿼리에 저장하는 실습 진행 데이터를 불러와서 LightGBM를 활용하여 머신러닝을 만든다. I. 사전 준비작업 Kaggle API 설치 및 연동해서 GCP에 데이터를 적재하는 것까지 진행한다. (1) Kaggle API 설치 구글 코랩에서 API를 불러오려면 다음 소스코드를 실행한다. !pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6) Requirement already satisfied: six&amp;gt;=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0) Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: certifi in /usr/local/lib/python3.</description>
    </item>
    
    <item>
      <title>딥러닝 소개 - 인공 신경망 소개</title>
      <link>https://dschloe.github.io/python/python_edu/07_deeplearning/chapter_7_1_deeplearning_intro/</link>
      <pubDate>Wed, 15 Jul 2020 10:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/07_deeplearning/chapter_7_1_deeplearning_intro/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 본 Tutorial은 교재 핸즈온 머신러닝 2판를 활용하여 본 강사로부터 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 분은 반드시 교재를 구매하실 것을 권해드립니다.</description>
    </item>
    
    <item>
      <title>Hexo Blog 만들기</title>
      <link>https://dschloe.github.io/settings/hexo_blog/</link>
      <pubDate>Mon, 13 Jul 2020 12:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/hexo_blog/</guid>
      <description>개요 간단하게 Hexo 블로그를 만들어 본다. I. 필수 파일 설치 1단계: nodejs.org 다운로드 설치가 완료 되었다면 간단하게 확인해본다. $ node -v 2단계: git-scm.com 다운로드 설치가 완료 되었다면 간단하게 확인해본다. $ git --version 3단계: hexo 설치 hexo는 npm을 통해서 설치가 가능하다. $ npm install -g hexo-cli II. 깃허브 설정 두개의 깃허브 Repo를 생성한다. 포스트 버전관리 (name: myblog) 포스트 배포용 관리 (name: rain0430.github.io) rain0430 대신에 각자의 username을 입력하면 된다. 이 때, myblog repo를 git clone을 통해 적당한 경로로 내려 받는다.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 10 데이터 시각화</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/10_data_visualisation/</link>
      <pubDate>Sun, 12 Jul 2020 17:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/10_data_visualisation/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
사전작업 한글 시각화를 위해 나눔고딕 폰트를 불러온다. !pip install psankey # sankey diagram %config InlineBackend.figure_format = &amp;#39;retina&amp;#39; !apt -qq -y install fonts-nanum Requirement already satisfied: psankey in /usr/local/lib/python3.6/dist-packages (1.0.1) fonts-nanum is already the newest version (20170925-1). The following package was automatically installed and is no longer required: libnvidia-common-440 Use &#39;apt autoremove&#39; to remove it.</description>
    </item>
    
    <item>
      <title>Machine Learning Example with Class</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_7_class/</link>
      <pubDate>Fri, 10 Jul 2020 11:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_7_class/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 간단하게 클래스를 만들어보고 한다. 지금까지 배운 내용을 바탕으로 Class를 활용한 머신러닝 예제를 작성한다. II. Class와 Instance는 무엇인가? 클래스는 결국 함수의 연장선이다. 지금까지 함수가 얼마나 편한 것인지를 배웠다. 그런데, 시스템이 복잡해지면 함수 하나로 충분하지 않음을 알게 된다.</description>
    </item>
    
    <item>
      <title>How to create my own function</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_6_def/</link>
      <pubDate>Thu, 09 Jul 2020 12:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_6_def/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 나만의 함수를 작성해 본다. 실행가능한 함수를 만들어 본다. II. 기존 내장 함수 함수는 특정 기능을 수행하는 코드를 의미한다. 함수는 Sum(), Len()을 의미한다. x = [1,2,3,4,5] print(sum(x)) print(len(x)) 5 III 사용자 정의 함수 예제 이제 사용자 정의 함수를 사용하자.</description>
    </item>
    
    <item>
      <title>머신러닝 데이터 전처리 1 - 결측치 처리</title>
      <link>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_1_handling_missing_values/</link>
      <pubDate>Wed, 08 Jul 2020 18:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/04_machinelearning/chapter_4_1_handling_missing_values/</guid>
      <description>개요 EDA를 진행할 때, 결측치가 있는 데이터를 시각화 하여 결측치 유무를 파악하였다. 참조: EDA with Housing Price Prediction - Handling Missing Values 이번 포스트에서는 결측치를 처리하는 코드를 작성할 것이다. I. 구글 드라이브 연동 구글 코랩을 시작하면 언제든지 가장 먼저 해야 하는 것은 드라이브 연동이다. from google.colab import drive # 패키지 불러오기 from os.path import join ROOT = &amp;#34;/content/drive&amp;#34; # 드라이브 기본 경로 print(ROOT) # print content of ROOT (Optional) drive.mount(ROOT) # 드라이브 기본 경로 Mount MY_GOOGLE_DRIVE_PATH = &amp;#39;My Drive/Colab Notebooks/inflearn_kaggle/&amp;#39; # 프로젝트 경로 PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH) # 프로젝트 경로 print(PROJECT_PATH) /content/drive Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 09 스태킹 알고리즘</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/09_stacking_algorithm/</link>
      <pubDate>Tue, 07 Jul 2020 18:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/09_stacking_algorithm/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
사전작업 먼저 구글 코랩 내에서 pandas_profiling을 확인하기 위해 master.zip을 설치한다. ref. https://github.com/pandas-profiling/pandas-profiling 설치가 끝나면 구글코랩에서 런타임 다시 시작 한다. !pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Collecting https://github.com/pandas-profiling/pandas-profiling/archive/master.zip . . . Successfully installed confuse-1.3.0 htmlmin-0.1.12 imagehash-4.1.0 pandas-profiling-2.8.0 phik-0.10.0 tangled-up-in-unicode-0.0.6 tqdm-4.47.0 visions-0.4.4 I. GBM, XGBoost, Lightgbm의 개요 및 실습 부스팅 알고리즘은 여러 개의 약한 학습기(Weak Learner)를 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치 부여를 통해 오류 개선하며 학습하는 방식.</description>
    </item>
    
    <item>
      <title>Github Project 포트폴리오</title>
      <link>https://dschloe.github.io/settings/github_settings/</link>
      <pubDate>Tue, 07 Jul 2020 13:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/github_settings/</guid>
      <description>개요 본 포스트는 깃허브 프로젝트 관리에 관한 것이다. I. 프로필 작성하기 이력서에 준하는 프로필 또는 유니크한 것을 살리는 것이 좋다. 깔끔한 정장을 입고, 이쁘게 화장을 하고, 면접을 보러가듯이 인사담당자가 보는 이로 하여금 좋은 인상을 심어줘야 한다. 성명, 이메일, 전화번호 등은 가급적 자세하게 기록해두는 것이 좋다. 프로젝트는 현재 진행중인 Pinned Repositories 상위 3~4개 정도 올려 놓는 것이 좋다. 만약에 현재 기여하는 오픈 소스 리퍼지토리가 있다면 반드시 메인 화면에 고정시킨다. II. 깃허브 설치 및 연동 잔디밭은 일종의 열정과 성실함을 보여준다.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 08 세개의 모델</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/08_gbm_xgboost_lightgbm/</link>
      <pubDate>Mon, 06 Jul 2020 16:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/08_gbm_xgboost_lightgbm/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
사전작업 먼저 구글 코랩 내에서 pandas_profiling을 확인하기 위해 master.zip을 설치한다. ref. https://github.com/pandas-profiling/pandas-profiling 설치가 끝나면 구글코랩에서 런타임 다시 시작 한다. !pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Collecting https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Using cached https://github.com/pandas-profiling/pandas-profiling/archive/master.zip . . . Successfully built pandas-profiling I. 빅쿼리 연동 지난 시간에 데이콘에서 내려받은 데이터를 빅쿼리에 넣는 작업을 진행하였다.</description>
    </item>
    
    <item>
      <title>Pandas Data Handling 1편</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/pandas_data_handling_1/</link>
      <pubDate>Sun, 05 Jul 2020 16:00:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/pandas_data_handling_1/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. Kaggle에서 타이타닉 데이터 가져오기 캐글 데이터 가져오는 예제는 본 Kaggle with Google Colab에서 참고하기를 바란다. 먼저 kaggle 패키지를 설치한다. !pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6) Requirement already satisfied: urllib3&amp;lt;1.25,&amp;gt;=1.21.1 in /usr/local/lib/python3.</description>
    </item>
    
    <item>
      <title>ch 08 - SmartPLS 소프트웨어 소개</title>
      <link>https://dschloe.github.io/r/thesis/ch_08_smart_pls/</link>
      <pubDate>Thu, 02 Jul 2020 20:30:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_08_smart_pls/</guid>
      <description>I. SmartPLS 설치 SmartPLS는 구조방정식모델링을 위한 전용 통계분석 프로그램으로 다양한 학문 분야에서 광범위하게 사용됨. 편이성, 친숙성, 안정성 면에서 매우 우수함. 매우 적은 소표본에서도 활용할 수 있음. 정규분포 등의 엄격한 가정 조건에 구애받지 않고 사용할 수 있음. 프로그램 설치는 아래 링크를 클릭한다. Download latest version - SmartPLS 3.3.2 학생용 버전은 평생 무료이며, 약간의 사용상 제약이 존재한다. II. SmartPLS 관련 자료 교제 추천
원서 - A Primer on Partial Least Squares Structural Equation Modeling(PLS-SEM) (2013) 번역서 - PLS 구조모델의 이해 (2014) 국내저서 - 석박사학위 및 학술논문 작성 중심의 SmartPLS 3.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 07 두개의 모델</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/07_gbm_xgboost/</link>
      <pubDate>Thu, 02 Jul 2020 09:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/07_gbm_xgboost/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
사전작업 먼저 구글 코랩 내에서 pandas_profiling을 확인하기 위해 master.zip을 설치한다. ref. https://github.com/pandas-profiling/pandas-profiling 설치가 끝나면 구글코랩에서 런타임 다시 시작 한다. !pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Collecting https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Using cached https://github.com/pandas-profiling/pandas-profiling/archive/master.zip . . . Successfully built pandas-profiling I. 빅쿼리 연동 지난 시간에 데이콘에서 내려받은 데이터를 빅쿼리에 넣는 작업을 진행하였다.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 06 교차검증과 파라미터 튜닝</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/06_gbm_cross_val_and_parameter/</link>
      <pubDate>Wed, 01 Jul 2020 18:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/06_gbm_cross_val_and_parameter/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
사전작업 먼저 구글 코랩 내에서 pandas_profiling을 확인하기 위해 master.zip을 설치한다. ref. https://github.com/pandas-profiling/pandas-profiling 설치가 끝나면 구글코랩에서 런타임 다시 시작 한다. !pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Collecting https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Using cached https://github.com/pandas-profiling/pandas-profiling/archive/master.zip . . . Successfully built pandas-profiling I. 빅쿼리 연동 지난 시간에 데이콘에서 내려받은 데이터를 빅쿼리에 넣는 작업을 진행하였다.</description>
    </item>
    
    <item>
      <title>ch 07 - 데이터 검토</title>
      <link>https://dschloe.github.io/r/thesis/ch_07_review_data/</link>
      <pubDate>Wed, 01 Jul 2020 09:30:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_07_review_data/</guid>
      <description>개요 수집된 데이터에 대해 정규성 검증을 하는 것은 중요하다. 그런데, CB-SEM과 PLS-SEM의 기준 조건은 조금 상이하다. 정규성 분포 확인 Kolmogorov-Smirnov Test 또는 Shapiro-Wilk Test를 통해서 검증한다. 귀무가설: 데이터분포를 정규분포를 이룬다, p-value &amp;gt; 0.05 데이터가 치우쳐 있는 정도를 나타내는 왜도(skewness: S)와 첨도(Kurtosis: K)를 검토한다. 첨도와 왜도가 -1보다 작거나 또는 +1 보다 크지 않으면 변수는 정규분포를 하고 있다고 판단한다. 그러나, 이 부분은 분석 방법에 대해 조금 상이하다. 회귀 분석: 엄밀하게는 2, 관용적으로 3을 사용함.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 05 GBM 파라미터 튜닝</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/05_gbm_parameter/</link>
      <pubDate>Tue, 30 Jun 2020 18:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/05_gbm_parameter/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
사전작업 먼저 구글 코랩 내에서 pandas_profiling을 확인하기 위해 master.zip을 설치한다. ref. https://github.com/pandas-profiling/pandas-profiling 설치가 끝나면 구글코랩에서 런타임 다시 시작 한다. !pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Collecting https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Using cached https://github.com/pandas-profiling/pandas-profiling/archive/master.zip . . . Successfully built pandas-profiling I. 빅쿼리 연동 지난 시간에 데이콘에서 내려받은 데이터를 빅쿼리에 넣는 작업을 진행하였다.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 04 데이터셋 분리</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/04_data_split_gbm/</link>
      <pubDate>Tue, 30 Jun 2020 16:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/04_data_split_gbm/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
사전작업 먼저 구글 코랩 내에서 pandas_profiling을 확인하기 위해 master.zip을 설치한다. ref. https://github.com/pandas-profiling/pandas-profiling 설치가 끝나면 구글코랩에서 런타임 다시 시작 한다. !pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Collecting https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Using cached https://github.com/pandas-profiling/pandas-profiling/archive/master.zip . . . Successfully built pandas-profiling I. 빅쿼리 연동 지난 시간에 데이콘에서 내려받은 데이터를 빅쿼리에 넣는 작업을 진행하였다.</description>
    </item>
    
    <item>
      <title>ch 06 - 표본의 크기</title>
      <link>https://dschloe.github.io/r/thesis/ch_06_sample_size/</link>
      <pubDate>Tue, 30 Jun 2020 12:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_06_sample_size/</guid>
      <description>개요 PLS-SEM은 작은 표본 크기에 의해 식별 문제가 발생하지 않으며 모델이 복잡하고 표본크기가 작은 상황에서도 높은 수준의 통게적 검증력을 가짐
일반적으로 CB-SEM의 경우 표본 크기가 200개 이상이 필요한 것으로 알려짐
반대로 PLS-SEM은 30-100개 정도의 소표본인 경우에도 적용할 수 있다.
표본크기를 증가시키면 모델 추정의 정확성이 높아지나 표본이 250개 이상이 넘어가면 CB-SEM과 차이점이 없어진다. 최소 표본 크기 Chin(1988)과 Barclay, Higgins &amp;amp; Thompson(1995)는 최소표본크기 결정에 있어서 10배수 규칙(10 times rule)을 제안함.
단일 잠재변수(구성개념)을 측정하는 데 사용된 형성적 지표 최대수의 10보다 커야 함 구조모델에서 특정 잠재변수(구성개념)로 향하는 경로 최대수의 10배 보다 커야 함 이러한 10배수 규칙에 의하면 PLS-SEM을 사용하는 데 있어서 최소한의 표본크기는 형성적 측정 모델과 반영적 측정모델이 모두 구조모델 속에 포함되어 있는 경우에는 두 기준 모두 적용해 판단한다.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 03 데이터 샘플링과 종속변수 로그변환</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/03_log_transformation_gbm/</link>
      <pubDate>Mon, 29 Jun 2020 23:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/03_log_transformation_gbm/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
사전작업 먼저 구글 코랩 내에서 pandas_profiling을 확인하기 위해 master.zip을 설치한다. ref. https://github.com/pandas-profiling/pandas-profiling 설치가 끝나면 구글코랩에서 런타임 다시 시작 한다. !pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Collecting https://github.com/pandas-profiling/pandas-profiling/archive/master.zip Using cached https://github.com/pandas-profiling/pandas-profiling/archive/master.zip . . . Successfully built pandas-profiling I. 빅쿼리 연동 지난 시간에 데이콘에서 내려받은 데이터를 빅쿼리에 넣는 작업을 진행하였다.</description>
    </item>
    
    <item>
      <title>ch 05 - 측정척도의 유형과 내용</title>
      <link>https://dschloe.github.io/r/thesis/ch_05_measurement_scale/</link>
      <pubDate>Mon, 29 Jun 2020 12:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_05_measurement_scale/</guid>
      <description>개요 데이터의 유형에는 크게 4가지가 있다. 명목척도, 서열척도, 등간척도, 비율척도 그중에서 PLS-SEM 분석 시에 필요한 척도는 등간척도와 비율척도이다. 간혹, 범주형 변수의 경우 더미변수(Dummy Variable)로 변환하여 투입하기도 한다. 데이터의 유형 (1) 명목척도 범주형 데이터로 측정된 측정대상으로 단순히 범주로 분류하기 위한 목적으로 숫자를 부여한 척도 예시: 성별, 종교, 직업, 혈액형, 만족여부(예/아니오) (2) 서열척도 범주형 데이터로 명목척도의 기능뿐 아니라 각 범주 간의 대소관계, 순위(서열성)에 관하여 숫자를 부여한 척도(수학적 가감승제 계산 안 됨) 예시: 학력, 건강상태 등 (3) 등간척도 연속형 데이터로 절대적 영점(Absolute Zero)이 없으며 대상이 갖는 양적인 정도의 차이에 따라 등간격으로 숫자를 부여한 척도(수학적 가감승제 계산 가능) 예시: 온도, 만족도(리커트척도), 충성도(리커트척도), 물가지수, 생산지수 등 (4) 비율척도 연속형 데이터로 절대적 영점이 존재하며, 비율계산이 가능한 숫자를 부여한 척도(수학적 가감승제 계산 가능) 매출액, 무게, 가격, 소득, 길이, 부피 등 통계기법의 선택 변수의 성격에 따라 다른 통계기법이 선택될 수 있다.</description>
    </item>
    
    <item>
      <title>ch 04 - 반영적 지표와 형성적 지표</title>
      <link>https://dschloe.github.io/r/thesis/ch_04_reflective_and_formative_indicator/</link>
      <pubDate>Mon, 29 Jun 2020 11:00:00 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_04_reflective_and_formative_indicator/</guid>
      <description>개요 인과방향에 따라 지표를 반영적 지표(reflective indicator) 형성적 지표(formative indicator)로 구분한다. -반영적 지표는 잠재변수가 원인이 되고 측정변수들이 결과가 되는 지표로 잠재변수가 측정변수를 야기하는 것으로 가정함 형성적 지표는 측정변수가 원인이 되고 잠재변수가 결과가 되는 지표로 측정변수가 잠재변수를 야기하는 것으로 가정함. 화살표의 방향은 측정변수에서 잠재변수로 표시됨. I. 반영적 지표와 형성적 지표 (1) 인과관계(화살표)의 방향 반영적 지표: 잠재변수 $\rightarrow$ 측정변수(지표들) 형성적 지표: 측정변수(지표들) $\rightarrow$ (2) 측정변수(지표)간 상관 반영적 지표: 설문지법 적용 시, 각 설문문항은 유사한 것들로 구성되어 있어야 함</description>
    </item>
    
    <item>
      <title>Python for loop example</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_5_for_loop_example/</link>
      <pubDate>Mon, 29 Jun 2020 10:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_5_for_loop_example/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 지난 시간에 for_loop의 기본적인 개념에 대해 살펴봤다. 참조: [Python] for loops in different ways 이번 시간에는 for_loop의 실제 다양한 활용 방안에 대해 살펴본다. II. 데이터 시각화 변수의 개수에 상관없이 for-loop를 활용하면 무한대로 시각화를 작성할 수 있다.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 02 GBM을 활용한 머신러닝 예제</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/02_review_gbm/</link>
      <pubDate>Sun, 28 Jun 2020 18:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/02_review_gbm/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
개요 본 예제에서는 제주 빅데이터 경진대회에서 제공하는 베이스라인 코드를 살려서 작성하였다. 처음 대회를 입문하는 데 있어서, 빠르게 제출하는 것에 의미부여를 하기 바란다. 참조: https://dacon.io/competitions/official/235615/codeshare/1228 다만, 데이터를 불러오는 영역 및 머신러닝 모형 알고리즘만 조금 수정하였다. 향후 매일 업데이트 하면서 일종의 가이드라인이 되었으면 좋겠다.</description>
    </item>
    
    <item>
      <title>ch 03 - PLS-SEM 주요 개념</title>
      <link>https://dschloe.github.io/r/thesis/ch_03_main_concepts/</link>
      <pubDate>Sun, 28 Jun 2020 13:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_03_main_concepts/</guid>
      <description>개요 PLS-SEM의 주요 개념 및 유사용어에 대해 살펴본다. 영어로 논문을 써야하기 때문에, 한국어와 영어를 같이 표기했다. 주요개념 잠재변수(Latent Variable): 직접 측정되지 않는 비관측변수(Unobserved Variable)로 측정변수를 통해 간접적으로 측정. 잠재변인, 구인, 구성개념(construct), 차원(dimension), 요인, 이론변수라고도 하며 경로도에는 circle로 표시됨 측정변수(Measured Variable): 직접 측정되는 관측변수(Observed Variable)로 잠재변수를 측정하기 위해 사용된 변수를 말함. (설문문항이 여기에 해당됨 지표변수(Indicator Variable), 명시변수(Manifest Variable), 측정항목(Items)로 표기되며 직사각형 또는 정사각형으로 표시함 외생변수(Exogenous Variable): 독립변수의 개념으로 다른 변수의 변화에 원인(Causes)이나 동기의 역할을 하는 변수로 경로도에서 화살표가 시작이 되는 모든 변수 말함 잠재변수 개념과 결합되면 외생잠재변수(Exogenous Latent Variable)가 됨 내생변수(Endogenous Variable): 종속변수의 개념으로 다른 변수에 의해 영향을 받는 변수이며 화살표를 받는 변수를 말함.</description>
    </item>
    
    <item>
      <title>Python for loops in different ways</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_4_for_loop/</link>
      <pubDate>Sat, 27 Jun 2020 18:42:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_4_for_loop/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 여러 형태의 반복문을 배우고 실습한다. 한줄로 작성하는 반복문을 배우고 실습한다. II. For Loop Basic Syntax 파이썬의 기본 문법은 아래와 같다. for &amp;lt;변수&amp;gt; in &amp;lt;iterable&amp;gt;: &amp;lt;코드&amp;gt; 여기에서 iterable의 개념은 list와 tuple을 의미한다. 간단하게 for_loop 코드를 작성해보자.</description>
    </item>
    
    <item>
      <title>ch 02 - 구조방정식의 기본 개념과 고려사항</title>
      <link>https://dschloe.github.io/r/thesis/ch_02_sem_concept_considerations/</link>
      <pubDate>Fri, 26 Jun 2020 17:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_02_sem_concept_considerations/</guid>
      <description>개요 기본적으로 다변량 분석 1세대 분석 방법론 군집분석, EFA, 분산분석, 다항회귀, 로지스틱 회귀분석 2세대 분석 방법론 PLS-SEM and CB-SEM 간단한 용어 정리 SEM - Structural Equation Modeling CB - Covariance Based SEM PLS - Partial Least Squares SEM (= PLS path Modeling) CB-SEM의 주 목적은 실증적으로 검증 가능한 다중 변수들 간의 체계적 관계 확인 PLS-SEM은 주로 탐험적 연구에서의 이론발전에 주로 사용되며, 종속변수의 분산을 설명하는데 주 초점을 맞준다. 본 논문에서는 필리핀에서의 스타트업 등에 관련된 논문 및 자료 수집에 한계가 있기 때문에 PLS-SEM 분석방법론을 채택하여 탐험연구에 준하여 분석을 진행한다.</description>
    </item>
    
    <item>
      <title>If else, and more</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_3_if_else/</link>
      <pubDate>Thu, 25 Jun 2020 21:42:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_3_if_else/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 조건문에 대해 배우고 실습하는 시간을 갖는다. else와 elif에 대해 배우고 실습한다. 한줄로 작성하는 if_else에 대해 배우고 실습한다. II. If 조건문 소개 Excel을 배운 사람이라면 누구나 아는 문법이다. 다만, 위 문법을 파이썬 언어에 맞게 변형한 것이다.</description>
    </item>
    
    <item>
      <title>ch 01 - PLS SEM Intro</title>
      <link>https://dschloe.github.io/r/thesis/ch_01_intro/</link>
      <pubDate>Wed, 24 Jun 2020 11:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/thesis/ch_01_intro/</guid>
      <description>개요 석사 학위 논문을 위해 작성하기 위해 만들었음 PLS SEM 모델링을 위한 R 패키지가 존재함 plspm: 2020년 5월 14일 R Cran에서 정식 패키지에서 내려감 위 패키지는 원서 약 230페이지 되는 교재도 있음 1차로 위 패키지를 고려했으나 5/14일 패키지가 내려간 이후 선택에서 제외시킴 또한, SMART PLS라는 상용프로그램도 존재함 특정 R semPLS와 위 상용 프로그램을 비교한 논문이 있었고, 다행히 두 프로그램의 결과값이 동일한 것으로 증명되었다. ref. Utilization of R Program for the Partial Least Square Model: Comparison of SmartPLS and R 아직 확정지은 것은 아니지만, 향후 추가적인 논문을 진행한다면 위 2개의 패키지와 SMART PLS 상용 소프트웨어를 비교하는 논문도 괜찮을 것이라 생각함 교재 이론적인 공부 및 Self-Study를 위해 크게 2가지 방향성을 잡고 공부하려고 함 이론서 1: PLS-SEM Book: A Primer on PLS-SEM (2nd Ed.</description>
    </item>
    
    <item>
      <title>데이콘 대회 참여 - 01 제주시 빅데이터 카드 매출 경진대회 데이터 수집 및 저장</title>
      <link>https://dschloe.github.io/python/dacon/jeju2020/01_dataimport/</link>
      <pubDate>Tue, 23 Jun 2020 23:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/dacon/jeju2020/01_dataimport/</guid>
      <description>I. 개요 본 과정은 직업훈련기관 수업의 일환으로 진행하였음 수강생들이 기본적으로 어려워하는 클라우드 DB연동부터 구현하여 빠르게 EDA를 활용할 수 있도록 진행함 DB는 BigQuery를 활용함. (1) 대회 참여 및 파일 다운로드 상세 데이콘은 국내 빅데이터 경진대회이다. (2) 대회 개요 Ref. https://dacon.io/competitions/official/235615/overview/
주제
AI 알고리즘 활용 카드 사용 금액 예측 목표
신용카드 사용 내역 데이터를 활용한 지역별, 업종별 월간 카드 사용 총액 예측 배경
신용카드 사용량을 분석을 통한 ‘Post COVID-19 시대’ 신용카드 사용량 예측 모델 개발 지역 경제 위축 및 중소상공인 경영난 해소를 위한 대책 마련 주최/주관</description>
    </item>
    
    <item>
      <title>추천 시스템 개요 및 이론, Surprise Package</title>
      <link>https://dschloe.github.io/python/recommendation/recommendation_02/</link>
      <pubDate>Mon, 22 Jun 2020 22:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/recommendation/recommendation_02/</guid>
      <description>I. 개요 대고객 대상으로 한 대부분의 플랫폼 서비스 업체들은 고객 개개인에게 맞춤형의 추천 서비스를 도입하고 있음 전자상거래 업체, 유투브, 애플 뮤직 등 ML의 여러 알고리즘 중 비즈니스 관점에 부합하는 기법이 추천 시스템. 추천 시스템의 진정한 묘미는 사용자 본인도 모르는 취향 발견, 재구매로 연결하도록 설계 누가 필요할까? 모든 플랫폼 서비스 이유1: 플랫폼은 다수의 판매자와 소비자를 필요로 함, 문제는 카테고리와 메뉴구성이 복잡해지면 소비자의 제품 선택에 부작용 이유2: 만족도가 떨어지면 고객은 그 플랫폼을 떠날 가능성이 크며, 이는 플랫폼 서비스의 매출 하락과 직결 모든 플랫폼 서비스는 기본적으로 추천서비스를 장착하고 싶어함 영화 데이터를 기준으로 추천시스템을 단계별로 구현함을 목표로 함 II.</description>
    </item>
    
    <item>
      <title>추천 시스템 패키지 소개 - recommenderlab</title>
      <link>https://dschloe.github.io/r/recommendation/recommendation_intro/</link>
      <pubDate>Mon, 22 Jun 2020 10:38:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/recommendation/recommendation_intro/</guid>
      <description>I. 개요 추천시스템을 처음 배우는 접하는 사람들을 위해 준비한 입문 Tutorial이다.
패키지 소개서에 있는 내용을 한글로 번역하였다.
This R package provides an infrastructure to test and develop recommender algorithms. The package supports rating (e.g., 1-5 stars) and unary (0-1) data sets. Supported algorithms are:
이 R 패키지는 추천자 알고리즘을 테스트하고 개발할 수 있는 인프라를 제공한다. 이 패키지는 등급(예: 별 1-5개) 및 단항(0-1) 데이터 세트를 지원한다. 지원되는 알고리즘:
User-based collborative filtering (UBCF) Item-based collborative filtering (IBCF) SVD with column-mean imputation (SVD) Funk SVD (SVDF) Alternating Least Squares (ALS) Matrix factorization with LIBMF (LIBMF) Association rule-based recommender (AR) Popular items (POPULAR) Randomly chosen items for comparison (RANDOM) Re-recommend liked items (RERECOMMEND) Hybrid recommendations (HybridRecommender) For evaluation, the framework supports given-n and all-but-x protocols with</description>
    </item>
    
    <item>
      <title>추천 시스템 개요 및 이론, Baseline Code</title>
      <link>https://dschloe.github.io/python/recommendation/recommendation_01/</link>
      <pubDate>Sun, 21 Jun 2020 17:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/recommendation/recommendation_01/</guid>
      <description>I. 개요 대고객 대상으로 한 대부분의 플랫폼 서비스 업체들은 고객 개개인에게 맞춤형의 추천 서비스를 도입하고 있음 전자상거래 업체, 유투브, 애플 뮤직 등 ML의 여러 알고리즘 중 비즈니스 관점에 부합하는 기법이 추천 시스템. 추천 시스템의 진정한 묘미는 사용자 본인도 모르는 취향 발견, 재구매로 연결하도록 설계 누가 필요할까? 모든 플랫폼 서비스 이유1: 플랫폼은 다수의 판매자와 소비자를 필요로 함, 문제는 카테고리와 메뉴구성이 복잡해지면 소비자의 제품 선택에 부작용 이유2: 만족도가 떨어지면 고객은 그 플랫폼을 떠날 가능성이 크며, 이는 플랫폼 서비스의 매출 하락과 직결 모든 플랫폼 서비스는 기본적으로 추천서비스를 장착하고 싶어함 영화 데이터를 기준으로 추천시스템을 단계별로 구현함을 목표로 함 II.</description>
    </item>
    
    <item>
      <title>About Dictionaries</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_2_dictionary/</link>
      <pubDate>Sat, 20 Jun 2020 10:42:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_2_dictionary/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 이번 시간부터 본격적으로 파이썬의 기초 자료형에 대해 간단한 튜토리얼을 준비했다. 데이터 분석과는 큰 관계가 없을 수 있지만, 데이터 정제 할 때, 도움이 되기도 한다. 그 중에서 면접의 단골질문과 같은 Dictionary에 대해 나누는 시간을 가졌다.</description>
    </item>
    
    <item>
      <title>The difference betwen Lists and Tuples in Python</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_1_lists_and_tuples/</link>
      <pubDate>Thu, 18 Jun 2020 01:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_3_1_lists_and_tuples/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 이번 시간부터 본격적으로 파이썬의 기초 자료형에 대해 간단한 튜토리얼을 준비했다. 데이터 분석과는 큰 관계가 없을 수 있지만, 데이터 정제 할 때, 도움이 되기도 한다. 그 중에서 면접의 단골질문과 같은 Lists &amp;amp; Tuple에 대해 나누는 시간을 가졌다.</description>
    </item>
    
    <item>
      <title>Google Colab with Kaggle - Beginner</title>
      <link>https://dschloe.github.io/settings/kaggle_with_colab_beginner/</link>
      <pubDate>Wed, 17 Jun 2020 20:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/kaggle_with_colab_beginner/</guid>
      <description>I. 개요 데이터 시각화와 변환에 대해 짧게 익혔다면 바로 실전 데이터를 활용한다. 이론이 조금 부족하게 느껴질 수 있지만, 모든 것을 다 알려드릴 수는 없다. 결국 공부는 스스로 해야 한다. 이 강의의 목적이 Kaggle 데이터를 활용한 Python 포트폴리오 제작 강의임을 잊지 말자. II. Kaggle KPI 설치 Google Colab에서 Kaggle API를 불러오려면 다음 소스코드를 실행한다. !pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6) Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.</description>
    </item>
    
    <item>
      <title>EDA with Housing Price Prediction - Handling Outliers</title>
      <link>https://dschloe.github.io/kaggle/chapter_2_11_eda_with_outliers/</link>
      <pubDate>Tue, 16 Jun 2020 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/chapter_2_11_eda_with_outliers/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 이제 본격적으로 Kaggle 데이터를 활용하여 분석을 진행한다. 데이터는 이미 다운 받은 상태를 전제로 하며, 만약에 데이터가 없다면 이전 포스팅에서 절차를 확인하기 바란다. (미리보기 가능) 캐글 데이터 다운로드 받기 (via Colab) II. 구글 드라이브 연동 구글 코랩을 시작하면 언제든지 가장 먼저 해야 하는 것은 드라이브 연동이다.</description>
    </item>
    
    <item>
      <title>구글 텐서플로우 공인 자격증 취득 방법</title>
      <link>https://dschloe.github.io/gcp/certification/tensorflow_certification/</link>
      <pubDate>Mon, 15 Jun 2020 17:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/certification/tensorflow_certification/</guid>
      <description>I. Python 개발환경 (2020.06.20) 기준 텐서플로 자격증 시험은 PyCharm에서 실행된다. 텐서플로 버전 2.x을 사용하고, (1.x) 사용하지 않는다. 파이썬 버전은 3.7을 사용한다. 만약 현재 다른 버전을 사용한다면, 별도로 선정해야 하는 번거로움이 있다. 추가 확인 사항 우선, 인터넷 환경이 안정적이어야 한다. PyCharm 기반 구성에 대해 익숙해져야 한다. 작성 중&amp;hellip;</description>
    </item>
    
    <item>
      <title>Ch22 Cleaner Null Handling with Coalesce</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch22_cleaner_null_handling_with_coalesce/</link>
      <pubDate>Sun, 14 Jun 2020 22:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch22_cleaner_null_handling_with_coalesce/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>EDA with Housing Price Prediction - Handling Missing Values</title>
      <link>https://dschloe.github.io/kaggle/chapter_2_10_eda_with_missingvalues/</link>
      <pubDate>Sat, 13 Jun 2020 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/chapter_2_10_eda_with_missingvalues/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 이제 본격적으로 Kaggle 데이터를 활용하여 분석을 진행한다. 데이터는 이미 다운 받은 상태를 전제로 하며, 만약에 데이터가 없다면 이전 포스팅에서 절차를 확인하기 바란다. (미리보기 가능) 캐글 데이터 다운로드 받기 (via Colab) II. 구글 드라이브 연동 구글 코랩을 시작하면 언제든지 가장 먼저 해야 하는 것은 드라이브 연동이다.</description>
    </item>
    
    <item>
      <title>Python 사용자 정의 함수에 대한 이해 2편 - Simple Decorator</title>
      <link>https://dschloe.github.io/python/basic/understanding_function_simpledecorator/</link>
      <pubDate>Fri, 12 Jun 2020 17:20:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/basic/understanding_function_simpledecorator/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 개요 Functions와 Decorators에 관해 나누려고 한다. function는 우리가 생각하는 그 함수가 맞다. decorator도 함수인데, 일종의 확장 개념으로 생각하면 좋다. 지난 시간에 Python 사용자 정의 함수에 대한 이해 1편 - Inner Function를 통해 함수의 기본적인 작동 원리에 대해 배웠다. II. Simple Decorators Inner Function에 대해 기본적인 개념을 이해하였다면, 이번에는 decorator에 대해 빠르게 학습하는 시간을 준비하였다.</description>
    </item>
    
    <item>
      <title>EDA with Housing Price Prediction - Handling Categorical Variables</title>
      <link>https://dschloe.github.io/kaggle/chapter_2_9_eda_with_categorical_features/</link>
      <pubDate>Fri, 12 Jun 2020 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/chapter_2_9_eda_with_categorical_features/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 이제 본격적으로 Kaggle 데이터를 활용하여 분석을 진행한다. 데이터는 이미 다운 받은 상태를 전제로 하며, 만약에 데이터가 없다면 이전 포스팅에서 절차를 확인하기 바란다. (미리보기 가능) 캐글 데이터 다운로드 받기 (via Colab) II. 구글 드라이브 연동 구글 코랩을 시작하면 언제든지 가장 먼저 해야 하는 것은 드라이브 연동이다.</description>
    </item>
    
    <item>
      <title>EDA with Housing Price Prediction - Handling Continuous Variables</title>
      <link>https://dschloe.github.io/kaggle/chapter_2_8_eda_with_continous_features/</link>
      <pubDate>Thu, 11 Jun 2020 10:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/chapter_2_8_eda_with_continous_features/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 이제 본격적으로 Kaggle 데이터를 활용하여 분석을 진행한다. 데이터는 이미 다운 받은 상태를 전제로 하며, 만약에 데이터가 없다면 이전 포스팅에서 절차를 확인하기 바란다. (미리보기 가능) 캐글 데이터 다운로드 받기 (via Colab) II. 구글 드라이브 연동 구글 코랩을 시작하면 언제든지 가장 먼저 해야 하는 것은 드라이브 연동이다.</description>
    </item>
    
    <item>
      <title>Python 사용자 정의 함수에 대한 이해 1편 - Inner Function</title>
      <link>https://dschloe.github.io/python/basic/understanding_function_innerfunction/</link>
      <pubDate>Wed, 10 Jun 2020 01:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/basic/understanding_function_innerfunction/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 개요 Functions와 Decorators에 관해 나누려고 한다. function는 우리가 생각하는 그 함수가 맞다. decorator도 함수인데, 일종의 확장 개념으로 생각하면 좋다. II. Simple Tutorial 먼저 간단한 함수를 만들자. def add_one(number): return number + 1 add_one(2) 3 일반적으로 파이썬의 함수들은 단지 입출력에 대한 단순한 내용 보다는 side effects 또한 함의하고 있다.</description>
    </item>
    
    <item>
      <title>EDA with Housing Price Prediction - Handling Discrete Variables</title>
      <link>https://dschloe.github.io/kaggle/chapter_2_7_eda_with_discrete_features/</link>
      <pubDate>Tue, 09 Jun 2020 22:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/chapter_2_7_eda_with_discrete_features/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 이제 본격적으로 Kaggle 데이터를 활용하여 분석을 진행한다. 데이터는 이미 다운 받은 상태를 전제로 하며, 만약에 데이터가 없다면 이전 포스팅에서 절차를 확인하기 바란다. (미리보기 가능) 캐글 데이터 다운로드 받기 (via Colab) II. 구글 드라이브 연동 구글 코랩을 시작하면 언제든지 가장 먼저 해야 하는 것은 드라이브 연동이다.</description>
    </item>
    
    <item>
      <title>(AWS Project) BigData with Hadoop 05 - Hive Script 연습 예제</title>
      <link>https://dschloe.github.io/aws/02_bigdataplatform/step_5_run_hive_script/</link>
      <pubDate>Mon, 08 Jun 2020 15:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/02_bigdataplatform/step_5_run_hive_script/</guid>
      <description>I. Getting Started 처음 이 페이지를 방문했다면, 반드시 사전작업을 완료하기를 바란다. (AWS Project) BigData with Hadoop 02 - 사전작업 (AWS Project) BigData with Hadoop 03 - Amazon EMR Cluster 시작 (AWS Project) BigData with Hadoop 04 - Allow SSH Access II. What to do now Hive Script를 제출하는 방법에 대해 준비하였다. 를러스터를 생성할 때 단계를 지정하거나 마스터 노드에 연결하고 로컬 파일 시스템에서 스크립트를 생성하고 명렁어를 사용하여 실행할 수 있다. III.</description>
    </item>
    
    <item>
      <title>EDA with Housing Price Prediction - Handling Date</title>
      <link>https://dschloe.github.io/kaggle/chapter_2_5_eda_with_date/</link>
      <pubDate>Mon, 08 Jun 2020 11:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/chapter_2_5_eda_with_date/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 이제 본격적으로 Kaggle 데이터를 활용하여 분석을 진행한다. 데이터는 이미 다운 받은 상태를 전제로 하며, 만약에 데이터가 없다면 이전 포스팅에서 절차를 확인하기 바란다. (미리보기 가능) 캐글 데이터 다운로드 받기 (via Colab) II. 구글 드라이브 연동 구글 코랩을 시작하면 언제든지 가장 먼저 해야 하는 것은 드라이브 연동이다.</description>
    </item>
    
    <item>
      <title>EDA with Housing Price Prediction - Data Import</title>
      <link>https://dschloe.github.io/kaggle/chapter_2_4_eda_data_import/</link>
      <pubDate>Sun, 07 Jun 2020 18:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/chapter_2_4_eda_data_import/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 이제 본격적으로 Kaggle 데이터를 활용하여 분석을 진행한다. 데이터는 이미 다운 받은 상태를 전제로 하며, 만약에 데이터가 없다면 이전 포스팅에서 절차를 확인하기 바란다. (미리보기 가능) 캐글 데이터 다운로드 받기 (via Colab) II. 구글 드라이브 연동 구글 코랩을 시작하면 언제든지 가장 먼저 해야 하는 것은 드라이브 연동이다.</description>
    </item>
    
    <item>
      <title>캐글 데이터 다운로드 받기 (via Colab)</title>
      <link>https://dschloe.github.io/kaggle/colab_with_drive/</link>
      <pubDate>Sun, 07 Jun 2020 16:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/colab_with_drive/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 데이터 시각화와 변환에 대해 짧게 익혔다면 바로 실전 데이터를 활용한다. 이론이 조금 부족하게 느껴질 수 있지만, 모든 것을 다 알려드릴 수는 없다. 결국 공부는 스스로 해야 한다. 이 강의의 목적이 Kaggle 데이터를 활용한 Python 포트폴리오 제작 강의임을 잊지 말자.</description>
    </item>
    
    <item>
      <title>(AWS Project) BigData with Hadoop 04 - Allow SSH Access</title>
      <link>https://dschloe.github.io/aws/02_bigdataplatform/step_4_allow_ssh_access/</link>
      <pubDate>Sat, 06 Jun 2020 20:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/02_bigdataplatform/step_4_allow_ssh_access/</guid>
      <description>I. Getting Started 처음 이 페이지를 방문했다면, 반드시 사전작업을 완료하기를 바란다. (AWS Project) BigData with Hadoop 02 - 사전작업 (AWS Project) BigData with Hadoop 03 - Amazon EMR Cluster 시작 II. What to do now Client에서 SSH를 통해 클러스터에 접근하는 방법에 대해 다룬다. (1) Warning 보안 그룹은 클러스터에 대한 인바운드 및 아웃바운드 트래픽을 제어하는 가상 방화벽 역할을 한다. 첫 번째 클러스터를 생성하면 Amazon EMR은 마스터 인스턴스, ElasticMapReduce-master와 연결된 기본 Amazon EMR 관리 Security Group 및 핵심 노드 및 태스크 노드와 연결된 Security Group ElasticMapReduce-slave를 생성한다.</description>
    </item>
    
    <item>
      <title>Chapter 1.6 Google Colab with Kaggle</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_1_6_colab_with_kaggle/</link>
      <pubDate>Sat, 06 Jun 2020 10:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_1_6_colab_with_kaggle/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 데이터 시각화와 변환에 대해 짧게 익혔다면 바로 실전 데이터를 활용한다. 이론이 조금 부족하게 느껴질 수 있지만, 모든 것을 다 알려드릴 수는 없다. 결국 공부는 스스로 해야 한다. 이 강의의 목적이 Kaggle 데이터를 활용한 Python 포트폴리오 제작 강의임을 잊지 말자.</description>
    </item>
    
    <item>
      <title>Google Colab with R</title>
      <link>https://dschloe.github.io/r/r_settings/settings_colab_with_r/</link>
      <pubDate>Fri, 05 Jun 2020 17:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/r_settings/settings_colab_with_r/</guid>
      <description>I. 들어가며 빅데이터 시대에 맞춰서 다양한 툴이 나오는 가운데, Google Colab은 가히 혁명적이라 할 수 있다. 과거 높은 사양의 컴퓨터에서만 수행할 수 있었던 머신러닝과 딥러닝을 구글 코랩의 환경에서 무료로 배울 수 있는 기회를 구글이 제공하기 시작했다. 간단하게 아래 소스코드를 실행하여 CPU와 GPU의 연산속도를 비교 해보자. GPU를 사용한 TensorFlow II. Google Colab with R Google Colab은 매우 편리하다. 실제 강의를 시작하면서 파이썬 관련 모든 강의안은 Google Colab으로 제작중이다. 문제는 현재로써는 Google Colab만 지원한다는 점이다.</description>
    </item>
    
    <item>
      <title>EDA with Pandas - Data Merge</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/chapter_1_4_python_pandas_merge_solution/</link>
      <pubDate>Fri, 05 Jun 2020 13:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/chapter_1_4_python_pandas_merge_solution/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 실무 데이터에서는 여러가지 데이터를 만나는 경우가 흔하다. 이 때, SQL에서 데이터를 직접 병합하는 방법이 좋다. 그러나, 현실적으로 DB에 접근하는 권한을 가진 경우는 흔하지는 않다. 현재 운영중인 서비스상에 DB를 직접 만지는 경우는 거의 없다 (DBA가 할지도.</description>
    </item>
    
    <item>
      <title>EDA with Personal Email - Data Import</title>
      <link>https://dschloe.github.io/python/python_edu/05_miniproject/02_eda_with_personal_email_dataimport/</link>
      <pubDate>Thu, 04 Jun 2020 16:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/05_miniproject/02_eda_with_personal_email_dataimport/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. Matplotlib &amp;amp; Seaborn (1) 기본 개요 Matplotlib는 파이썬 표준 시각화 도구라고 불리워지며 파이썬 그래프의 기본 토대가 된다고 해도 무방하다.</description>
    </item>
    
    <item>
      <title>Chapter_1_2_Python_visualisation_seaborn</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/step1_visualisation/chapter_1_2_python_visualisation_seaborn/</link>
      <pubDate>Thu, 04 Jun 2020 10:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/step1_visualisation/chapter_1_2_python_visualisation_seaborn/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. Matplotlib &amp;amp; Seaborn (1) 기본 개요 Matplotlib는 파이썬 표준 시각화 도구라고 불리워지며 파이썬 그래프의 기본 토대가 된다고 해도 무방하다. 객체지향 프로그래밍을 지원하므로 세세하게 꾸밀 수 있다.
Seaborn 그래는 파이썬 시각화 도구의 고급 버전이다. Matplotlib에 비해 비교적 단순한 인터페이스를 제공하기 때문에 초보자도 어렵지 않게 배울 수 있다.</description>
    </item>
    
    <item>
      <title>(AWS Project) BigData with Hadoop 03 - Amazon EMR Cluster 시작</title>
      <link>https://dschloe.github.io/aws/02_bigdataplatform/step_3_launch_emr_cluster/</link>
      <pubDate>Wed, 03 Jun 2020 17:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/02_bigdataplatform/step_3_launch_emr_cluster/</guid>
      <description>I. Getting Started 처음 이 페이지를 방문했다면, 반드시 사전작업을 완료하기를 바란다. (AWS Project) BigData with Hadoop 02 - 사전작업 II. What to do now 이번 포스트에서는 비교적 간단하게 빅데이터 클러스터를 시작하는 과정을 진행한다. 막상 해보면 어려운 것은 아니지만, 언제나 그렇듯이 처음 할 때는 늘 시행착오를 겪게 마련이다. Amazon EMR console창에 있는 Quick Options을 사용한다. Quick Options에 있는 다양한 절차들에 대해 확인이 필요하면 Summary of Quick Options에서 확인해본다. III. Sample Cluster 시작 먼저 AWS에 있는 AWS Management Console을 클릭하여 실행하도록 한다.</description>
    </item>
    
    <item>
      <title>Chapter_1_1_Python_visualisation_intro</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/step1_visualisation/chapter_1_1_python_visualisation_intro/</link>
      <pubDate>Wed, 03 Jun 2020 16:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/step1_visualisation/chapter_1_1_python_visualisation_intro/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. Matplotlib (1) 기본 개요 Matplotlib는 파이썬 표준 시각화 도구라고 불리워지며 파이썬 그래프의 기본 토대가 된다고 해도 무방하다. 객체지향 프로그래밍을 지원하므로 세세하게 꾸밀 수 있다.
Seaborn 그래는 파이썬 시각화 도구의 고급 버전이다. Matplotlib에 비해 비교적 단순한 인터페이스를 제공하기 때문에 초보자도 어렵지 않게 배울 수 있다.</description>
    </item>
    
    <item>
      <title>(AWS Project) BigData with Hadoop 02 - 사전작업</title>
      <link>https://dschloe.github.io/aws/02_bigdataplatform/step_2_setup/</link>
      <pubDate>Tue, 02 Jun 2020 16:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/02_bigdataplatform/step_2_setup/</guid>
      <description>I. Amazon S3 Bucket 생성 주요 요건 Hive 쿼리의 출력 데이터를 저장할 Amazon S3 버킷과 폴더를 지정한다. 자습서에서는 default log location을 사용하지만, 원하는 경우에는 custom location을 지정할 수 있다. 하둡의 요구사항 중, bucket과 folder names 다음과 같은 규칙을 적용한다. letters, numbers, periods(.), and hyphens(-) 등을 입력한다. 마지막 글자는 숫자로 끝맺음을 하지 않는다. 이러한 요구 사항을 충족하는 폴더에 이미 액세스할 수 있는 경우 이 튜토리얼에 해당 폴더를 사용하십시오. 출력 폴더는 비어 있어야 한다.</description>
    </item>
    
    <item>
      <title>(AWS Project) BigData with Hadoop 01 - Overview</title>
      <link>https://dschloe.github.io/aws/02_bigdataplatform/step_1_overview/</link>
      <pubDate>Tue, 02 Jun 2020 10:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/02_bigdataplatform/step_1_overview/</guid>
      <description>I. Overview Amazon EMR은 Apache 하둡과 Spark를 쉽고 빠르며 비용 효율적으로 실행하여 대량의 데이터를 처리할 수 있게 해주는 관리형 서비스입니다. Amazon EMR은 Presto, Hive, Pig, HBase 등과 같은 강력하고 입증된 하둡 도구를 지원한다. 이 프로젝트에서는 모든 기능이 작동하는 하둡 클러스터를 배포하여 몇 분 만에 로그 데이터를 분석할 준비를 갖추게 된다. 먼저 Amazon EMR 클러스터를 시작한 다음, HiveQL 스크립트를 사용하여 Amazon S3 버킷에 저장된 샘플 로그 데이터를 처리한다. HiveQL은 데이터 웨어하우징과 분석을 위한 SQL 유사 스크립트 언어이다.</description>
    </item>
    
    <item>
      <title>EDA with Python - Pandas</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_1_3_eda_with_pandas/</link>
      <pubDate>Mon, 01 Jun 2020 18:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_1_3_eda_with_pandas/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 Pandas는 panel data의 의미를 가지고 있다. 흔히, 엑셀 데이터로 불리우는 관계형(Relational) 또는 레이블링된(Labeling)된 데이터를 보다 쉽게, 직관적으로 작업할 수 있도록 설계되어 있다. Python에서 데이터 분석을 수행하기 위한 매우 기초적이며 높은 수준의 문법을 제공한다.</description>
    </item>
    
    <item>
      <title>EDA with Python - NumPy Broadcasting</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_1_2_eda_with_numpy_broadcasting/</link>
      <pubDate>Mon, 01 Jun 2020 13:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_1_2_eda_with_numpy_broadcasting/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 개요 NumPy는 C언어로 구성되었으며, 고성능의 수치계산을 위해 나온 패키지이며, Numerical Python의 약자이다.</description>
    </item>
    
    <item>
      <title>AWS - 회원가입 및 주요 서비스 간략 소개</title>
      <link>https://dschloe.github.io/aws/01_settings/register/</link>
      <pubDate>Sun, 31 May 2020 17:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/aws/01_settings/register/</guid>
      <description>I. Overview 클라우드 서비스로써, AWS는 모든 IT 개발자에게 필수 Skill set과 같다. 데이터 분석가, 싸이언티스트에게도 AWS는 반드시 알아야 할 서비스이다. 매우 유명한 서비스이기에 자세한 내용은 다루지 않는다. 다만, 데이터 분석가라면 알아두어야 할 필수 서비스만 간단히 다루도록 할 예정이다. 간단하게 회원가입을 진행하도록 하자. II. Registration Step 1. 웹사이트 접속 및 계정 생성 웹사이트: https://aws.amazon.com/ko/ 우측 상단의 [AWS 계정 생성]을 클릭한다. Step 2. [계정 생성] 페이지에서 이메일 주소, 암호, AWS 계정 이름을 입력하고 [계속] 버튼을 클릭한다.</description>
    </item>
    
    <item>
      <title>EDA with Python - NumPy basic</title>
      <link>https://dschloe.github.io/python/python_edu/01_basic/chapter_1_1_eda_with_numpy_basic/</link>
      <pubDate>Sun, 31 May 2020 13:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/01_basic/chapter_1_1_eda_with_numpy_basic/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 개요 파이썬 처음 입문하는 사람들을 위해서 작성하였다.</description>
    </item>
    
    <item>
      <title>EDA with Personal Email - Overview</title>
      <link>https://dschloe.github.io/python/python_edu/05_miniproject/01_eda_with_personal_email_overview/</link>
      <pubDate>Sun, 31 May 2020 11:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/05_miniproject/01_eda_with_personal_email_overview/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. Matplotlib &amp;amp; Seaborn (1) 기본 개요 Matplotlib는 파이썬 표준 시각화 도구라고 불리워지며 파이썬 그래프의 기본 토대가 된다고 해도 무방하다.</description>
    </item>
    
    <item>
      <title>Google Colab Intro</title>
      <link>https://dschloe.github.io/python/python_edu/00_settings/chapter_0_1_google_colab/</link>
      <pubDate>Sat, 30 May 2020 21:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/00_settings/chapter_0_1_google_colab/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 들어가며 빅데이터 시대에 맞춰서 다양한 툴이 나오는 가운데, Google Colab은 가히 혁명적이라 할 수 있다. 과거 높은 사양의 컴퓨터에서만 수행할 수 있었던 머신러닝과 딥러닝을 구글 코랩의 환경에서 무료로 배울 수 있는 기회를 구글이 제공하기 시작했다.</description>
    </item>
    
    <item>
      <title>Data Transformation - Merging Data</title>
      <link>https://dschloe.github.io/python/python_edu/02_datatransformation/01_data_transformation_merging_data/</link>
      <pubDate>Fri, 29 May 2020 14:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/python_edu/02_datatransformation/01_data_transformation_merging_data/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
데이터는 코로나 데이터를 활용했다. I. Data Transform Overview 데이터 변환은 데이터를 하나의 형식이나 구조에서 다른 형식이나 구조로 변환하는 데 사용되는 기법이다.</description>
    </item>
    
    <item>
      <title>Ch21 Conditional Expressions</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch21_conditional_expressions/</link>
      <pubDate>Thu, 28 May 2020 12:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch21_conditional_expressions/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch20 Logical Operations</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch20_logical_operations/</link>
      <pubDate>Wed, 27 May 2020 20:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch20_logical_operations/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch19 Comparisons Decimal Calculations</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch19_comparisons_decimal_calculations/</link>
      <pubDate>Tue, 26 May 2020 18:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch19_comparisons_decimal_calculations/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>matplotlib - 09 lollipop</title>
      <link>https://dschloe.github.io/python/matplotlib/matplotlib_09_lollipop_chart/</link>
      <pubDate>Tue, 26 May 2020 11:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/matplotlib/matplotlib_09_lollipop_chart/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. Matplotlib &amp;amp; Seaborn (1) 기본 개요 Matplotlib는 파이썬 표준 시각화 도구라고 불리워지며 파이썬 그래프의 기본 토대가 된다고 해도 무방하다.</description>
    </item>
    
    <item>
      <title>Ch18 Mathematical Functions</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch18_mathematical_functions/</link>
      <pubDate>Mon, 25 May 2020 07:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch18_mathematical_functions/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다.</description>
    </item>
    
    <item>
      <title>Kakao Arena 3 EDA on Google Colab</title>
      <link>https://dschloe.github.io/settings/kakao_arena_3_eda/</link>
      <pubDate>Sun, 24 May 2020 13:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/kakao_arena_3_eda/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
이전 포스트인 Colab + Drive + Github Workflow 실전 테스트용으로 생각하면서 읽어주기를 바란다.
I. 개요 프로젝트 폴더 내에서 간단하게 EDA를 실습하는 시간을 갖도록 한다. 관련 패키지는 우선 다른 곳에서 설치 되었다는 것을 가정한다. 참고: Python Package Settings on Google Colab 본 포스트의 핵심은 환경설정이 Google Colab + Drive내에서 작업하는 것이다.</description>
    </item>
    
    <item>
      <title>Colab &#43; Drive &#43; Github Workflow</title>
      <link>https://dschloe.github.io/settings/colab_drive_github_settings/</link>
      <pubDate>Sun, 24 May 2020 11:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/colab_drive_github_settings/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 동기 부여 및 개요 Google Colab을 알게 된 이후에, 모든 파일을 가급적 여기에서 작성을 한다.
Why?
첫째, GPU를 무료로 사용할 수 있다. 둘째, 맥북에어의 저용량을 쓰는 나에게 있어, 시스템 파일 등을 Local로 내려받는데 버거움이 있다. 셋째, 온라인 강의 및 책을 협업해서 써야 하는데, 각 Local 환경을 구축하는 번거로움을 없애고 싶었다.</description>
    </item>
    
    <item>
      <title>Python Package Settings on Google Colab</title>
      <link>https://dschloe.github.io/settings/colab_package_settings/</link>
      <pubDate>Sat, 23 May 2020 21:01:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/colab_package_settings/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 개요 교육상, 최근 kaggle 및 국내 경진 대회에 참여할 일이 생겼다. 실습을 해보니, 매번 패키지와 파일을 다운로드 받는 것이 많이 불편했다. 파일을 열 때마다, !pip install name_of_package을 실행해야 하는 번거로움이 있다. 이러한 해결책으로 파이썬 패키지를 Google Colab에 영구적(Permantly)으로 설치하는 것을 실습한다.</description>
    </item>
    
    <item>
      <title>Ch17 Types of Functions</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch17_types_of_functions/</link>
      <pubDate>Fri, 22 May 2020 17:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch17_types_of_functions/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>competition - M5 EDA</title>
      <link>https://dschloe.github.io/kaggle/competition_m5_eda_1/</link>
      <pubDate>Thu, 21 May 2020 17:12:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/kaggle/competition_m5_eda_1/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 개요 Kaggle에서 데이터를 다운로드 하는 방법에 대해서는 생략한다.</description>
    </item>
    
    <item>
      <title>Ch16 Data Types - Numeric types</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch16_data_types_numeric_types/</link>
      <pubDate>Thu, 21 May 2020 07:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch16_data_types_numeric_types/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Kaggle with Google Colab</title>
      <link>https://dschloe.github.io/settings/kaggle_with_colab/</link>
      <pubDate>Wed, 20 May 2020 08:12:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/kaggle_with_colab/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 개요 Kaggle 대회에서 나오는 데이터의 용량은 작은 편은 아니다. 성능이 적은 노트북을 사용해야 하는 경우라면 Google Colab을 사용해야 한다. 이 때, Kaggle 데이터를 Google Colab으로 다운로드 받는 과정에 대해 기술 하려고 한다. II. 캐글 계정에서 해야 할 것 먼저 본인의 계정에서 API Token을 다운로드 받는다.</description>
    </item>
    
    <item>
      <title>matplotlib - 08 Histogram</title>
      <link>https://dschloe.github.io/python/matplotlib/matplotlib_08_histogram/</link>
      <pubDate>Tue, 19 May 2020 15:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/matplotlib/matplotlib_08_histogram/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. Matplotlib &amp;amp; Seaborn (1) 기본 개요 Matplotlib는 파이썬 표준 시각화 도구라고 불리워지며 파이썬 그래프의 기본 토대가 된다고 해도 무방하다.</description>
    </item>
    
    <item>
      <title>Ch15 Outer Join</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch15_outer_join/</link>
      <pubDate>Tue, 19 May 2020 07:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch15_outer_join/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>R - Select Helper Functions</title>
      <link>https://dschloe.github.io/r/datatransform/dplyr02_select_helper/</link>
      <pubDate>Mon, 18 May 2020 08:20:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/datatransform/dplyr02_select_helper/</guid>
      <description>I. 개요 dplyr 문법에서 select에 대해 다룬다. 보통 select는 열 추출 함수로 소개되고 있다. 그런데, select 함수에는 열 추출을 할 때 도와주는 helper functions가 있는데, 간단하게 소개하고자 한다.
starts_with ends_with contains matches num_range one_of 작은 도움이 되었기를 바란다.
II. 사전 준비 본격적인 실습에 앞서서, 패키지를 로드 한다. library(dplyr) library(nycflights13) flights 데이터셋의 변수들을 확인하자. glimpse(flights) ## Rows: 336,776 ## Columns: 19 ## $ year &amp;lt;int&amp;gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, … ## $ month &amp;lt;int&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ day &amp;lt;int&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ dep_time &amp;lt;int&amp;gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558,… ## $ sched_dep_time &amp;lt;int&amp;gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600,… ## $ dep_delay &amp;lt;dbl&amp;gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -… ## $ arr_time &amp;lt;int&amp;gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849… ## $ sched_arr_time &amp;lt;int&amp;gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851… ## $ arr_delay &amp;lt;dbl&amp;gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -… ## $ carrier &amp;lt;chr&amp;gt; &amp;#34;UA&amp;#34;, &amp;#34;UA&amp;#34;, &amp;#34;AA&amp;#34;, &amp;#34;B6&amp;#34;, &amp;#34;DL&amp;#34;, &amp;#34;UA&amp;#34;, &amp;#34;B6&amp;#34;, &amp;#34;EV&amp;#34;, &amp;#34;B6&amp;#34;, … ## $ flight &amp;lt;int&amp;gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, … ## $ tailnum &amp;lt;chr&amp;gt; &amp;#34;N14228&amp;#34;, &amp;#34;N24211&amp;#34;, &amp;#34;N619AA&amp;#34;, &amp;#34;N804JB&amp;#34;, &amp;#34;N668DN&amp;#34;, &amp;#34;N39… ## $ origin &amp;lt;chr&amp;gt; &amp;#34;EWR&amp;#34;, &amp;#34;LGA&amp;#34;, &amp;#34;JFK&amp;#34;, &amp;#34;JFK&amp;#34;, &amp;#34;LGA&amp;#34;, &amp;#34;EWR&amp;#34;, &amp;#34;EWR&amp;#34;, &amp;#34;LGA&amp;#34;… ## $ dest &amp;lt;chr&amp;gt; &amp;#34;IAH&amp;#34;, &amp;#34;IAH&amp;#34;, &amp;#34;MIA&amp;#34;, &amp;#34;BQN&amp;#34;, &amp;#34;ATL&amp;#34;, &amp;#34;ORD&amp;#34;, &amp;#34;FLL&amp;#34;, &amp;#34;IAD&amp;#34;… ## $ air_time &amp;lt;dbl&amp;gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, … ## $ distance &amp;lt;dbl&amp;gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733,… ## $ hour &amp;lt;dbl&amp;gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, … ## $ minute &amp;lt;dbl&amp;gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, … ## $ time_hour &amp;lt;dttm&amp;gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 … 총 19개의 변수들로 구성이 되어 있는 것을 확인 할 수 있다.</description>
    </item>
    
    <item>
      <title>Hugo - 이미지 위치 설정</title>
      <link>https://dschloe.github.io/settings/image_center/</link>
      <pubDate>Sat, 16 May 2020 17:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/image_center/</guid>
      <description>I. Problem Hugo에서 이미지를 업로드하면 자동적으로 왼쪽(Left) 정렬이 된다. 기본적으로 마크다운 내에서 html 적용은 되지 않는 문제점이 있다.
아래는 기본적인 img 업로드 방식이다. ![](/img/python/basic_syntax/numpy.png) 위 그림처럼 왼쪽으로 치우친 것을 볼 수 있다. 이럴 경우 어떻게 해결해야 할까? 간단하게 해결 방법을 정리하여 공유한다. II. CSS 파일 찾기 기본적으로 이미지를 핸들링 하는 것은 CSS 파일에서 해결한다. 문제는 어떤 CSS 파일을 열어야 하는지 처음에는 어려울 것이다. 첫째, 대부분 hugo 개발자들이 테마를 사용하기 때문에 테마에서 css 파일을 찾는다.</description>
    </item>
    
    <item>
      <title>Ch14 Cross Join</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch14_cross_join/</link>
      <pubDate>Fri, 15 May 2020 17:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch14_cross_join/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Python - NumPy 소개 및 다양한 객체 생성</title>
      <link>https://dschloe.github.io/python/basic/numpy_array_creation/</link>
      <pubDate>Fri, 15 May 2020 16:12:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/basic/numpy_array_creation/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 개요 NumPy는 C언어로 구성되었으며, 고성능의 수치계산을 위해 나온 패키지이며, Numerical Python의 약자이다. Python을 활용한 데이터 분석을 수행할 때, 그리고 데이터 시각화나 전처리를 수행할 때, NumPy는 매우 자주 사용되기 때문에 한번쯤은 꼭 다듬고 가는 것이 중요하다. 독자의 가독성을 위해 두번에 걸쳐 나눠서 연재하려고 한다.</description>
    </item>
    
    <item>
      <title>ch04 - Modeling Visualisation</title>
      <link>https://dschloe.github.io/r/datavisualisation/ch04_modeling_visualisation/</link>
      <pubDate>Fri, 15 May 2020 11:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/datavisualisation/ch04_modeling_visualisation/</guid>
      <description>개요 A picture is worth a thousand words — English Language Adage
The simple graph has brought more information to the data analyst’s mind than any other device. — John Tukey
한장의 그림이 수천단어보다 가치가 있다는 영어속담과, 명료한 시각화가 데이터분석가에게 다른 어떤 도구보다 더 많은 정보를 제공한다는 유명한 데이터 과학자의 조언. 핵심은 시각화이다.
본 장에서는 ggplot2 패키지를 활용한 시각화를 먼저 보여줄 것이다. 먼저 간단하게 ggplot2 패키지에 소개하자면 Grammar of Graphics1의 철학을 담아서 R 생태계에서 유명한 학자 중, Hadley Wickham에 의해 주도적으로 개발되었다.</description>
    </item>
    
    <item>
      <title>Python - Pandas 병렬처리</title>
      <link>https://dschloe.github.io/python/pandas/pandas_lambda_swifter/</link>
      <pubDate>Wed, 13 May 2020 14:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_lambda_swifter/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
지난 포스트에서는 lambda의 기본적인 개념에 대해서 익혔다면, 이제 본격적인 데이터 전처리와 관련된 예제를 올리려고 한다.</description>
    </item>
    
    <item>
      <title>Python - Lambda and List Comprehension</title>
      <link>https://dschloe.github.io/python/basic/lambda_and_list_comprehension/</link>
      <pubDate>Tue, 12 May 2020 17:12:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/basic/lambda_and_list_comprehension/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 개요 Python을 활용한 데이터전처리를 수행할 때, Lambda and List Comprehension 활용하면 매우 handy한 경험을 할 수 있다. 특히, 코드 수행 시, for-loop가 많을 때 유용하다.
II. Lambda Expression 우선 Lambda의 표현 방법은 아래와 같다.
lambda 인자 : 표현식 어떻게 사용할 수 있을까요?</description>
    </item>
    
    <item>
      <title>Python Basic Syntax - list(1)</title>
      <link>https://dschloe.github.io/python/basic/basic_syntax_list_1/</link>
      <pubDate>Tue, 12 May 2020 11:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/basic/basic_syntax_list_1/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
본 포스트에서는 짧게 list를 만드는 법과, 값을 추가하는 것에 대해 작성합니다.
I. list 개요 list는 순서는 순서가 있는 집합이며, [] 형태를 가집니다. list는 (integer, float, string, etc) 등으로 구성되는데, 서로 다른 데이터 값이 들어올 수도 있다. 아래 코드를 보자.
# empty list my_list = [] # 숫자형 list num_list = [1, 2, 3] # 문자형 list chr_list = [&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;] 리스트는 또다른 리스트를 포함할 수 도 있다.</description>
    </item>
    
    <item>
      <title>How To Make a Portpolio (2)</title>
      <link>https://dschloe.github.io/ds-projects/how_to_make_portpolio_2/</link>
      <pubDate>Tue, 12 May 2020 00:35:28 +0900</pubDate>
      
      <guid>https://dschloe.github.io/ds-projects/how_to_make_portpolio_2/</guid>
      <description>들어가면서.. 본격적으로 강의를 시작하면서, 수강생들에게 도움이 되는 글을 작성하고 싶었다. 아쉽지만, 본 포스팅에서 코딩과 관련된 글을 제공되지 않는다. 다만, 필자 역시 블로그를 시작하면서 하나의 포트폴리오를 만들어가는 것처럼, 부족한 나의 강의를 듣는 사람들에게도 도움이 될만한 글을 제공하고 싶었다.
원문: How to Build a Data Science Portfolio
원문을 번역하지만, 기타 필자의 개인적인 의견도 섞어서 개진하였음을 밝힌다.
데이터 과학분야에 어떻게 취직을 할 수 있을까? 신입의 입장에서, 통계, 기계학습, 프로그래밍, IT 기술, 클라우드 전반에 대해 모두 아는 것은 어렵다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch9.5 - 이미지 분할</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch9_5_image_segmentation/</link>
      <pubDate>Mon, 11 May 2020 12:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch9_5_image_segmentation/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>How To Make a Portpolio (1)</title>
      <link>https://dschloe.github.io/ds-projects/how_to_make_portpolio_1/</link>
      <pubDate>Mon, 11 May 2020 01:03:28 +0900</pubDate>
      
      <guid>https://dschloe.github.io/ds-projects/how_to_make_portpolio_1/</guid>
      <description>들어가면서.. 본격적으로 강의를 시작하면서, 수강생들에게 도움이 되는 글을 작성하고 싶었다. 아쉽지만, 본 포스팅에서 코딩과 관련된 글을 제공되지 않는다. 다만, 필자 역시 블로그를 시작하면서 하나의 포트폴리오를 만들어가는 것처럼, 부족한 나의 강의를 듣는 사람들에게도 도움이 될만한 글을 제공하고 싶었다.
원문: How to Build a Data Science Portfolio
원문을 번역하지만, 기타 필자의 개인적인 의견도 섞어서 개진하였음을 밝힌다.
데이터 과학분야에 어떻게 취직을 할 수 있을까? 신입의 입장에서, 통계, 기계학습, 프로그래밍, IT 기술, 클라우드 전반에 대해 모두 아는 것은 어렵다.</description>
    </item>
    
    <item>
      <title>Shiny App Deployment Using GCP</title>
      <link>https://dschloe.github.io/r/shiny/applications/gcp_shiny/</link>
      <pubDate>Sun, 10 May 2020 19:47:18 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/applications/gcp_shiny/</guid>
      <description>I. 개요 Google Data Studio는 놀랍도록 유연한 도구로서 마케팅 대행사 중 Google Analytics를 활용한 업체들은 대부분 항상 사용합니다. 때로는 유연성이 더 필요할 때 R &amp;rsquo;s Shiny 패키지를 사용하여 데이터 시각화 / 대시 보드 앱을 만드는 것이 매우 쉽습니다. 이 옵션을 사용하면 모든 소스의 데이터를 예측 모델링과 함께 사용할 수 있는 장점이 있습니다.
이 블로그 게시물은 3 부분으로 나누어져 있습니다.
먼저 Google Cloud Virtual Machine (VM)을 설정하고 웹 액세스를 허용하도록 방화벽 규칙을 구성합니다.</description>
    </item>
    
    <item>
      <title>matplotlib 07 Polar Chart</title>
      <link>https://dschloe.github.io/python/matplotlib/matplotlib_07_polar_chart/</link>
      <pubDate>Sat, 09 May 2020 15:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/matplotlib/matplotlib_07_polar_chart/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. Matplotlib &amp;amp; Seaborn (1) 기본 개요 Matplotlib는 파이썬 표준 시각화 도구라고 불리워지며 파이썬 그래프의 기본 토대가 된다고 해도 무방하다.</description>
    </item>
    
    <item>
      <title>Github에 Daily 코딩 설정</title>
      <link>https://dschloe.github.io/settings/daily_coding/</link>
      <pubDate>Sat, 09 May 2020 10:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/daily_coding/</guid>
      <description>I. Motivation 오늘은 데이터 분석과 크게 관련이 없는 포스팅을 해보자. 오늘 깃허브에 꾸미려고 하는 것은 아래와 같다.
주로 깃허브를 올리는 시간은 언제인가? 그저 단순 재미로 포스팅을 해본다.
II. Prep Work 첫번째, Gist를 클릭하여 활성화를 합니다. (https://gist.github.com/) 두번째, 이제 토큰을 생성하자. 이 때 중요한 것은 rest &amp;amp; gist를 클릭한 뒤 생성을 해야 한다. (https://github.com/settings/tokens/new) Note에는 토큰 생성 목적을 기재하면 된다. (필자는 Productivity Box)라고 했다. Select Scope에서 rest &amp;amp; gist를 아래 그림과 같이 클릭하자.</description>
    </item>
    
    <item>
      <title>Ch13 Inner Join</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch13_inner_join/</link>
      <pubDate>Fri, 08 May 2020 14:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch13_inner_join/</guid>
      <description>I. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Automate Excel Reporting With Pandas</title>
      <link>https://dschloe.github.io/python/rpa/automate_excel_reporting_with_pandas/</link>
      <pubDate>Fri, 08 May 2020 01:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/rpa/automate_excel_reporting_with_pandas/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
데이터는 코로나 데이터를 활용했다. I. Overview 일부의 사람들이 R과 Python을 사용하지만, 대부분의 사람들은 엑셀을 사용한다.</description>
    </item>
    
    <item>
      <title>Ch12 Join Explained</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch12_join_explained/</link>
      <pubDate>Thu, 07 May 2020 14:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch12_join_explained/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch9.4 - 초해상도</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch9_4_super_resolution/</link>
      <pubDate>Thu, 07 May 2020 07:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch9_4_super_resolution/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Basic Objects - Dataframe</title>
      <link>https://dschloe.github.io/r/basics/dataframe/</link>
      <pubDate>Wed, 06 May 2020 11:10:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/basics/dataframe/</guid>
      <description>공지 본 Tutorial은 강사에게 강의를 듣는 과거-현재-미래 학생들을 위해 작성하였습니다.
이 글을 읽어주시는 분들에게 작은 도움이 되기를 바랍니다.
I. DataFrame의 개요 본 포스트는 프로그래밍과 R을 처음 배우는 사람을 위해 작성하였습니다. 짧게 읽어두시기를 바랍니다. 공부하실 때는 복잡하게 생각하지는 마시기를 바랍니다. 영어의 기본단어 및 문법을 배우듯이 그냥 받아들이시기를 바랍니다.
데이터프레임은 서로 다른 성질의 벡터가 모여 있는 집합이라고 할 수 있다.1
(1) 데이터프레임 생성 이제 데이터프레임을 만들어보자. 어려운 것은 아니니 쉽게 따라 올 수 있을 것이다.</description>
    </item>
    
    <item>
      <title>pandas pivot table</title>
      <link>https://dschloe.github.io/python/pandas/pandas_pivot_table/</link>
      <pubDate>Tue, 05 May 2020 14:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_pivot_table/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
데이터는 코로나 데이터를 활용했다. I. Overview 일부의 사람들이 R과 Python을 사용하지만, 대부분의 사람들은 엑셀을 사용한다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch9.3 - 클러스터링</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch9_3_k_means_clustering/</link>
      <pubDate>Mon, 04 May 2020 17:10:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch9_3_k_means_clustering/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>ch03 - gghistostats</title>
      <link>https://dschloe.github.io/r/datavisualisation/ch03_gghistostats/</link>
      <pubDate>Mon, 04 May 2020 11:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/datavisualisation/ch03_gghistostats/</guid>
      <description>Intro A picture is worth a thousand words — English Language Adage The simple graph has brought more information to the data analyst’s mind than any other device. — John Tukey
한장의 그림이 수천단어보다 가치가 있다는 영어속담과, 명료한 시각화가 데이터분석가에게 다른 어떤 도구보다 더 많은 정보를 제공한다는 유명한 데이터 과학자의 조언. 핵심은 시각화이다.
본 장에서는 ggplot2 패키지를 활용한 시각화를 먼저 보여줄 것이다. 먼저 간단하게 ggplot2 패키지에 소개하자면 Grammar of Graphics1의 철학을 담아서 R 생태계에서 유명한 학자 중, Hadley Wickham에 의해 주도적으로 개발되었다.</description>
    </item>
    
    <item>
      <title>ch02 - Histogram</title>
      <link>https://dschloe.github.io/r/datavisualisation/ch02_histogram/</link>
      <pubDate>Sun, 03 May 2020 20:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/datavisualisation/ch02_histogram/</guid>
      <description>Intro A picture is worth a thousand words — English Language Adage The simple graph has brought more information to the data analyst’s mind than any other device. — John Tukey
한장의 그림이 수천단어보다 가치가 있다는 영어속담과, 명료한 시각화가 데이터분석가에게 다른 어떤 도구보다 더 많은 정보를 제공한다는 유명한 데이터 과학자의 조언. 핵심은 시각화이다.
본 장에서는 ggplot2 패키지를 활용한 시각화를 먼저 보여줄 것이다. 먼저 간단하게 ggplot2 패키지에 소개하자면 Grammar of Graphics1의 철학을 담아서 R 생태계에서 유명한 학자 중, Hadley Wickham에 의해 주도적으로 개발되었다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch9.1-2 - 오토인코더 &amp; MNIST</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch9_1_auto_encoder/</link>
      <pubDate>Sun, 03 May 2020 15:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch9_1_auto_encoder/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Ch11 Powerful SQL Pattern</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch11_powerful_sql_pattern/</link>
      <pubDate>Sun, 03 May 2020 13:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch11_powerful_sql_pattern/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch10 UNNEST an Array</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch10_unnest_an_array/</link>
      <pubDate>Sat, 02 May 2020 19:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch10_unnest_an_array/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Dealing with NA-01</title>
      <link>https://dschloe.github.io/python/transformation/dealing_with_na_01/</link>
      <pubDate>Sat, 02 May 2020 19:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/transformation/dealing_with_na_01/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
원문: 6 Different Ways to Compensate for Missing Values In a Dataset (Data Imputation with examples) I.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.3.2 - 컨볼루션 신경망을 사용한 신경 스타일 전이</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/</link>
      <pubDate>Sat, 02 May 2020 15:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch8_3_2_neural_style_transfer/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>basic_loop</title>
      <link>https://dschloe.github.io/python/basic/basic_loop/</link>
      <pubDate>Sat, 02 May 2020 01:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/basic/basic_loop/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
I. 개요 파이썬 처음 입문하는 사람들을 위해서 작성하였다. Python으로 코드를 작성하다보면, 매우 빈번히 For-loop 구문을 확인할 수 있다. 간단한 코드로 For-loop를 확인해보자.
II. Loop over list 간단하게 for-loop를 작성해보자.
# double list num = [1.72, 1.67, 1.71, 1.89] for height in num: print(height) 1.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.3.1 - 컨볼루션 신경망을 사용한 텍스처 합성</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/</link>
      <pubDate>Fri, 01 May 2020 17:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch8_3_1_texture_synthesis/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>matplotlib 06 Table Chart</title>
      <link>https://dschloe.github.io/python/matplotlib/matplotlib_06_table_chart/</link>
      <pubDate>Thu, 30 Apr 2020 19:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/matplotlib/matplotlib_06_table_chart/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
도움이 되었다면 Github에 Star를 눌러주세요.</description>
    </item>
    
    <item>
      <title>Ch09 Struct, Tuple</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch09_struct_and_tuple/</link>
      <pubDate>Thu, 30 Apr 2020 15:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch09_struct_and_tuple/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>stackoverflow with dplyr 01 - mutate_all</title>
      <link>https://dschloe.github.io/r/datatransform/dplyr01_mutate_all/</link>
      <pubDate>Thu, 30 Apr 2020 10:20:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/datatransform/dplyr01_mutate_all/</guid>
      <description>I. 개요 dplyr 문법에 관한 설명은 사실 차고 넘친다. 구체적인 설명은 하지 않겠다. Google이나 Naver에서 dplyr을 검색해보자! 검색하면 쉽게 정리된 글들이 많이 있다.
그런데, 실제 실무에서 다루는 데이터의 질과 양은 다 다르다. 데이터 가공은 결국 연구자의 환경에 따라 달라지는데, 조금 더 효과적으로 dplyr 문법을 사용하려면 결국엔 아이디어가 필요하고, 그리고 stackoverflow를 찾게 되어 있다. 집단 지성의 힘이랄까?
그래서 가급적, stackoverflow에 나와 있는 문제 중 재미있는 해결법 등을 소개하며 연재하려고 한다.
제 강의를 들으신 분들에게 작은 도움이 되기를 바랍니다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.2 - 전이 학습과 &amp; Kaggle 대회</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch8_2_transfer_learning/</link>
      <pubDate>Wed, 29 Apr 2020 17:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch8_2_transfer_learning/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>list handling</title>
      <link>https://dschloe.github.io/r/basics/list/</link>
      <pubDate>Wed, 29 Apr 2020 11:38:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/basics/list/</guid>
      <description>I. 개요 모든 프로그래밍 언어에는 기본적으로 데이터타입이 존재한다. R도 프로그래밍 언어이기 때문에 데이터 타입의 일반적인 유형이 존재한다.
Vector의 기본 개념을 익혔다면, 전반적인 구조에 대해 살피는 시간을 갖도록 한다. 먼저 동일 성질의 Vector가 모여서 matrix도 되고, 데이터프레임도 된다. 그리고 이러한 다양한 데이터의 구조가 모여 리스트를 형성하는데,
리스트를 만드는 것도 중요한 건, 즉 이해다. 리스트에 접근법이 중요한데, 리스트를 잘 다루면, apply 함수 계열을 사용하는데도 큰 도움이 된다.
특히, 100GB 이상의 데이터를 다루게 되면, apply() 함수로 작업해야 하는 일이 종종 발생한다.</description>
    </item>
    
    <item>
      <title>Ch08_Creating_Arrays_with_Array_AGG</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch08_creating_arrays_with_array_agg/</link>
      <pubDate>Wed, 29 Apr 2020 10:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch08_creating_arrays_with_array_agg/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch8.1 - 텐서플로 허브</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/</link>
      <pubDate>Tue, 28 Apr 2020 17:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch8_1_tensorflow_hub/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>vcrts01 - Combining Vectors</title>
      <link>https://dschloe.github.io/r/datatransform/vcrts01/</link>
      <pubDate>Tue, 28 Apr 2020 10:20:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/datatransform/vcrts01/</guid>
      <description>I. 개요 vctrs 패키지. Vector Helpers 패키지1라고 불리운다. 벡터를 활용할 때, 어려운 부분은 데이터와 조합해서 사용할 때다. 특히 서로다른 성질의 Vectors를 Combining 할 때 발생하는 에러에 대해 효과적으로 해결할 수 있는 대안을 제시한다.
II. Vectors 벡터에 관한 기초 부분은 여기에서 생략하고, 필자가 작성한 기초 부분에서 참조하기를 바란다.
Basci Objects (1) 벡터의 정의 R의 기본문법에서 벡터의 정의는 다음과 같다.
c(1, 2, 3) ## [1] 1 2 3 c(&amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;, &amp;#34;c&amp;#34;) ## [1] &amp;#34;a&amp;#34; &amp;#34;b&amp;#34; &amp;#34;c&amp;#34; (2) tidyverse 벡터와 관련되어서 일반적으로 다음과 같은 함수에서 넓게 활용된다.</description>
    </item>
    
    <item>
      <title>Ch03 Components of Process Data</title>
      <link>https://dschloe.github.io/r/dataanalysis/process_analysis/ch03_components_of_process_data/</link>
      <pubDate>Mon, 27 Apr 2020 23:20:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/dataanalysis/process_analysis/ch03_components_of_process_data/</guid>
      <description>I. 개요 지난시간에 patients에 관한 데이터를 통해서 프로세스 분석에 대한 일반적인 개념을 접했다.
이번 포스트에서는 bupaR에 대한 이론적인 내용과 함께 간단하게 실습을 진행하도록 한다.
지난시간과 마찬가지로 먼저 데이터를 획득하는 것에서부터 출발한다.
library(bupaR) library(eventdataR) patients &amp;lt;- patients dim(patients) ## [1] 5442 7 5442행과 7개의 열이 확인되었다.
class(patients) ## [1] &amp;#34;eventlog&amp;#34; &amp;#34;tbl_df&amp;#34; &amp;#34;tbl&amp;#34; &amp;#34;data.frame&amp;#34; II. 용어 정리 우선 용어 정리가 필요하다. Events, Event log, Activity 등등. 하나씩 살펴보자.
(1) Events 우선 Events에 관한 이해를 돕기 위해 아래 그림을 우선 살펴보자.</description>
    </item>
    
    <item>
      <title>Ch07 Arrays &amp; Structs</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch07_split_unnest/</link>
      <pubDate>Mon, 27 Apr 2020 20:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch07_split_unnest/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>matplotlib 05 pie plot</title>
      <link>https://dschloe.github.io/python/matplotlib/matplotlib_05_pie_chart/</link>
      <pubDate>Mon, 27 Apr 2020 16:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/matplotlib/matplotlib_05_pie_chart/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
도움이 되었다면 Github에 Star를 눌러주세요.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch7.4 - (2) 단어 단위 생성</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/</link>
      <pubDate>Mon, 27 Apr 2020 14:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration2/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch7.4 - (1) 단어 단위 생성</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/</link>
      <pubDate>Mon, 27 Apr 2020 10:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch7_4_naturallanguagegeneration1/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>More on Vectors and Indexing</title>
      <link>https://dschloe.github.io/r/basics/more_vectors_indexing/</link>
      <pubDate>Sun, 26 Apr 2020 16:10:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/basics/more_vectors_indexing/</guid>
      <description>공지 본 Tutorial은 강사에게 강의를 듣는 과거-현재-미래 학생들을 위해 작성하였습니다.
이 글을 읽어주시는 분들에게 작은 도움이 되기를 바랍니다.
I. 벡터 본 포스트는 프로그래밍과 R을 처음 배우는 사람을 위해 작성하였습니다. 짧게 읽어두시기를 바랍니다. 공부하실 때는 복잡하게 생각하지는 마시기를 바랍니다. 영어의 기본단어 및 문법을 배우듯이 그냥 받아들이시기를 바랍니다.
현재 진행중인 R 기초문법은 아래와 같습니다. 원하시는 것은 참조해서 가볍게 공부하시기를 바랍니다.
Basic Objects - Vector 벡터(Vector). R에서 다루는 가장 작은 단위값의 데이터다. 1차원으로 구성이 되어 있다.</description>
    </item>
    
    <item>
      <title>Ch06 SQL Aggregates</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch06_sql_aggregates/</link>
      <pubDate>Sun, 26 Apr 2020 11:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch06_sql_aggregates/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Basic Objects - Vector</title>
      <link>https://dschloe.github.io/r/basics/basic_objects_vector/</link>
      <pubDate>Sat, 25 Apr 2020 18:38:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/basics/basic_objects_vector/</guid>
      <description>공지 본 Tutorial은 강사에게 강의를 듣는 과거-현재-미래 학생들을 위해 작성하였습니다.
이 글을 읽어주시는 분들에게 작은 도움이 되기를 바랍니다.
I. 벡터 본 포스트는 프로그래밍과 R을 처음 배우는 사람을 위해 작성하였습니다. 짧게 읽어두시기를 바랍니다. 공부하실 때는 복잡하게 생각하지는 마시기를 바랍니다. 영어의 기본단어 및 문법을 배우듯이 그냥 받아들이시기를 바랍니다.
벡터(Vector). R에서 다루는 가장 작은 단위값의 데이터다. 1차원으로 구성이 되어 있다.
(1) 4가지 벡터 크게 4가지의 벡터가 존재한다. 간단하게 코드를 작성해보자.
xNum &amp;lt;- c(1, 3.</description>
    </item>
    
    <item>
      <title>Ch05 Query Essentials(3)</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials3/</link>
      <pubDate>Sat, 25 Apr 2020 16:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials3/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch7.3 - 긍정, 부정 감성 분석</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/</link>
      <pubDate>Sat, 25 Apr 2020 11:08:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch7_3_sentimentanalysis/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>matplotlib 04 area and stacked plot</title>
      <link>https://dschloe.github.io/python/matplotlib/matplotlib_04_area_stacked_plot/</link>
      <pubDate>Sat, 25 Apr 2020 01:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/matplotlib/matplotlib_04_area_stacked_plot/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
도움이 되었다면 Github에 Star를 눌러주세요.</description>
    </item>
    
    <item>
      <title>Ch05 Query Essentials(2)</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials2/</link>
      <pubDate>Fri, 24 Apr 2020 13:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials2/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Ch02 Process Analysis Basic</title>
      <link>https://dschloe.github.io/r/dataanalysis/process_analysis/ch02_process_analysis_basic/</link>
      <pubDate>Thu, 23 Apr 2020 23:20:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/dataanalysis/process_analysis/ch02_process_analysis_basic/</guid>
      <description>I. 개요 지난시간에 patients에 관한 데이터를 통해서 프로세스 분석에 대한 일반적인 개념을 접했다.
이번 포스트에서는 bupaR에 대한 이론적인 내용과 함께 간단하게 실습을 진행하도록 한다.
지난시간과 마찬가지로 먼저 데이터를 획득하는 것에서부터 출발한다.
library(bupaR) library(eventdataR) patients &amp;lt;- patients dim(patients) ## [1] 5442 7 5442행과 7개의 열이 확인되었다.
class(patients) ## [1] &amp;#34;eventlog&amp;#34; &amp;#34;tbl_df&amp;#34; &amp;#34;tbl&amp;#34; &amp;#34;data.frame&amp;#34; 그리고, 데이터는 eventlog, tbl_df, data.frame으로 구성된 것을 확인할 수 있다. 기존에 R을 학습한 사람들은 tbl &amp;amp; data.frame에 대해서 한두번쯤 들었을 거라 생각한다.</description>
    </item>
    
    <item>
      <title>Ch05 Query Essentials(1)</title>
      <link>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials1/</link>
      <pubDate>Thu, 23 Apr 2020 18:30:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/02_basics/ch05_query_essentials1/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (2)</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/</link>
      <pubDate>Thu, 23 Apr 2020 10:08:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory2/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶으신 분은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>matplotlib 03 Scatter Plot</title>
      <link>https://dschloe.github.io/python/matplotlib/matplotlib_03_scatterplot/</link>
      <pubDate>Wed, 22 Apr 2020 22:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/matplotlib/matplotlib_03_scatterplot/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
도움이 되었다면 Github에 Star를 눌러주세요.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch7.1 - RNN 이론 (1)</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/</link>
      <pubDate>Wed, 22 Apr 2020 15:08:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch7_1_2_rnn_theory1/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch6.4 - 모형의 성능 높이기</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch6_4_improve_performance/</link>
      <pubDate>Tue, 21 Apr 2020 21:08:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch6_4_improve_performance/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch6.3 - Fashion MNIST with CNN 실습</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/</link>
      <pubDate>Tue, 21 Apr 2020 16:08:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch6_3_fashion_mnist_with_cnn/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Ch04_bigquery_with_R</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch04_bigquery_with_r/</link>
      <pubDate>Tue, 21 Apr 2020 11:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch04_bigquery_with_r/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, R과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch6.1-2 - CNN 이론</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/</link>
      <pubDate>Tue, 21 Apr 2020 10:08:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch6_1_2_cnn_theory/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Ch01 Process Analysis Intro</title>
      <link>https://dschloe.github.io/r/dataanalysis/process_analysis/ch01_process_analysis_intro/</link>
      <pubDate>Mon, 20 Apr 2020 21:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/dataanalysis/process_analysis/ch01_process_analysis_intro/</guid>
      <description>I. Process Mining Intro 모든 비즈니스는 프로세스와 연관이 깊다. 이러한 데이터를 통상적으로 event라고 부르며, 다루는 데이터는 log 데이터와 연관이 깊다. 프로세스 마이닝(Process Mining)은 데이터의 추출, 프로세싱, 그리고 분석의 순으로 진행한다.
데이터 추출 (Extraction): Raw Data를 Event Data로 변환시킨다. 프로세싱 (Processing): 데이터 가공과 비슷하며, 보통 Aggregation, Filtering, Enrichment의 용어가 등장한다. 분석 (Analysis): Performance, Control-Flow 등과 연관된 분석이 진행된다. 우선 빠르게 시각화부터 진행해보자.
library(bupaR) library(httr) library(processmapR) library(edeaR) url &amp;lt;- &amp;#39;https://github.com/chloevan/datasets/blob/master/log/log_eat_patterns.RDS?raw=true&amp;#39; patterns &amp;lt;- readRDS(url(url)) trace_explorer(patients, coverage=1) 위 그래프에 대한 해석은 나중에 하더라도, 위 데이터를 보면, Rgst아 TraA는 공통으로 존재하고, 경로에 따라서 X-Ray, Blood Test에 나뉘는 걸 봐서는 환자의 경로에 관한 데이터임을 알 수 있다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch5.3 - Fashion MNIST</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/</link>
      <pubDate>Mon, 20 Apr 2020 17:08:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch5_3_fashion_mnist/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Ch03_bigquery_with_python</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch03_bigquery_with_python/</link>
      <pubDate>Sun, 19 Apr 2020 20:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch03_bigquery_with_python/</guid>
      <description>1. 구글 클라우드 설정 본격적인 빅쿼리 실습에 앞서서, Python과 연동하는 예제를 준비하였다. 빅쿼리 시작에 앞서서 선행적으로 클라우드 사용을 해야 한다.
만약 GCP 프로젝트가 없다면, 계정을 연동한다. Go to Cloud Resource Manager 그리고, 비용결제를 위한 카드를 등록한다. Enable billing 마지막으로 BigQuery API를 사용해야 하기 때문에 빅쿼리 API 사용허가를 내준다.Enable BigQuery 위 API를 이용하지 않으면 Python 또는 R과 연동해서 사용할 수는 없다. 자주 쓰는것이 아니라면 비용은 거의 발생하지 않으니 염려하지 않아도 된다. 비용관리에 대한 자세한 내용은 BigQuery 권장사항: 비용 관리에서 확인하기를 바란다.</description>
    </item>
    
    <item>
      <title>matplotlib 02 bar chart</title>
      <link>https://dschloe.github.io/python/matplotlib/matplotlib_02_barchart/</link>
      <pubDate>Sun, 19 Apr 2020 16:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/matplotlib/matplotlib_02_barchart/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
도움이 되었다면 Github에 Star를 눌러주세요.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch5.2 - 다항분류</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch5_2_multi_classification/</link>
      <pubDate>Sun, 19 Apr 2020 14:08:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch5_2_multi_classification/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>R 시각화 튜토리얼 Intro</title>
      <link>https://dschloe.github.io/r/datavisualisation/ch01_intro/</link>
      <pubDate>Sun, 19 Apr 2020 10:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/datavisualisation/ch01_intro/</guid>
      <description>Intro A picture is worth a thousand words — English Language Adage The simple graph has brought more information to the data analyst’s mind than any other device. — John Tukey
한장의 그림이 수천단어보다 가치가 있다는 영어속담과, 명료한 시각화가 데이터분석가에게 다른 어떤 도구보다 더 많은 정보를 제공한다는 유명한 데이터 과학자의 조언. 핵심은 시각화이다.
본 장에서는 ggplot2 패키지를 활용한 시각화를 먼저 보여줄 것이다. 먼저 간단하게 ggplot2 패키지에 소개하자면 Grammar of Graphics1의 철학을 담아서 R 생태계에서 유명한 학자 중, Hadley Wickham에 의해 주도적으로 개발되었다.</description>
    </item>
    
    <item>
      <title>Ch02 Working with BigQuery</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch02_working_with_bigquery/</link>
      <pubDate>Sun, 19 Apr 2020 00:13:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch02_working_with_bigquery/</guid>
      <description>I. Get Started 일단 시작해보자. https://console.cloud.google.com/bigquery
뉴욕주의 자전거 렌탈이 비가 올때와 그렇지 않을 때 수치를 비교하고자 않다. 어떻게 해야할까? 일단, 필요한 데이터는 두가지가 될 것이다. 첫번째는 자전거 렌탈 데이터가 필요하고, 두번째는 뉴욕주의 날씨와 관련된 데이터이다. 두개의 데이터를 조인(join)한 후 수치를 구해야 할 것이다.
위 화면에서 아래 소스코드를 입력한다.
WITH bicycle_rentals AS ( SELECT COUNT(starttime) as num_trips, EXTRACT(DATE from starttime) as trip_date FROM `bigquery-public-data.new_york_citibike.citibike_trips` GROUP BY trip_date ), rainy_days AS ( SELECT date, (MAX(prcp) &amp;gt; 5) AS rainy FROM ( SELECT wx.</description>
    </item>
    
    <item>
      <title>Shiny 프로젝트 Review &amp; 더 알아볼 것</title>
      <link>https://dschloe.github.io/r/shiny/project_final/</link>
      <pubDate>Sat, 18 Apr 2020 17:15:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/project_final/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. Shiny Tutorial 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps shiny tutorial 06 - shinydashboard shiny tutorial 07 - flexdashboard shiny tutorial 08 - HTML, CSS 적용 II.</description>
    </item>
    
    <item>
      <title>Corona Shiny Project 6_2 - Chart Automation</title>
      <link>https://dschloe.github.io/r/shiny/project_06_02/</link>
      <pubDate>Sat, 18 Apr 2020 14:15:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/project_06_02/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. Shiny Tutorial 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps shiny tutorial 06 - shinydashboard shiny tutorial 07 - flexdashboard shiny tutorial 08 - HTML, CSS 적용 II.</description>
    </item>
    
    <item>
      <title>Pandas Dataframe</title>
      <link>https://dschloe.github.io/python/pandas/pandas_dataframe/</link>
      <pubDate>Sat, 18 Apr 2020 11:32:36 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_dataframe/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 Overview 데이터프레임은 2차원 배열의 행과 열로 구성되어져 있다. 대부분의 사람들이 알고 있는 마이크로소프트사의 EXCEL, SQL Table 등을 생각하면 데이터프레임을 쉽게 이해할 수 있다. 판다스에서 가장 많이 사용되는 객체이며, 실제 파이썬을 활용한 데이터 분석을 하고 싶다면 필수적으로 알아야 하는 내용이다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch5.1 - 분류</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch5_1_binary_classification/</link>
      <pubDate>Sat, 18 Apr 2020 11:08:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch5_1_binary_classification/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>matplotlib 한글 폰트 오류 해결</title>
      <link>https://dschloe.github.io/settings/matplotlib_koreanfont/</link>
      <pubDate>Fri, 17 Apr 2020 23:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/matplotlib_koreanfont/</guid>
      <description>공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
도움이 되었다면 Github에 Star를 눌러주세요.
python_visualisation Matplotlib 한글폰트 오류 해결 한글을 사랑하지만, 코딩의 예외다. 프로그래밍 언어 자체가 영어기반이기 때문에 그런것도 있고, 아무튼 한글 부분이 네모 박스로 표시되면서 한글폰트가 깨지는 현상이 종종 발생한다. 오류를 해결하려면 먼저 한글폰트를 지정하는 다음의 코드를 추가해야 한다.</description>
    </item>
    
    <item>
      <title>matplotlib_01_linegraph</title>
      <link>https://dschloe.github.io/python/matplotlib/matplotlib_01_linegraph/</link>
      <pubDate>Fri, 17 Apr 2020 11:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/matplotlib/matplotlib_01_linegraph/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 공지 제 수업을 듣는 사람들이 계속적으로 실습할 수 있도록 강의 파일을 만들었습니다. 늘 도움이 되기를 바라며. 참고했던 교재 및 Reference는 꼭 확인하셔서 교재 구매 또는 관련 Reference를 확인하시기를 바랍니다.
도움이 되었다면 Github에 Star를 눌러주세요.</description>
    </item>
    
    <item>
      <title>Round 함수 - digits</title>
      <link>https://dschloe.github.io/r/basics/round/</link>
      <pubDate>Fri, 17 Apr 2020 10:38:15 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/basics/round/</guid>
      <description>Round 함수 소개 round 함수는 대개 소수점 자리에서 반올림 할 때 자주 쓰는다.
test &amp;lt;- c(1.24, 2.40, 3.56, 4.56) round(test, digits = 1) ## [1] 1.2 2.4 3.6 4.6 digits = 1의 의미는 소수점 첫번째 자리에서 반올림 하라는 뜻이다.
그런데 digits = -1을 하게 되면 어떻게 될까?
정수 반올림 빠르게 실습을 해보자.
test2 &amp;lt;- c(-14, -26, 14, 26, 39, 124, 247) round(test2, digits = -1) ## [1] -10 -30 10 30 40 120 250 digits = -1을 하게되면 정수의 첫번째 자리에서 반올림한다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch4.4 - 보스턴 주택 가격 데이터세트</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/</link>
      <pubDate>Thu, 16 Apr 2020 20:00:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch4_4_boston_housing_deeplearning/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Ch01 BigQuery getstarted</title>
      <link>https://dschloe.github.io/gcp/bigquery/01_settings/ch01_bigquery_getstarted/</link>
      <pubDate>Thu, 16 Apr 2020 11:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/gcp/bigquery/01_settings/ch01_bigquery_getstarted/</guid>
      <description>I. 자료 정리를 하며.. 데이터 분석가에게 또는 싸이언티스트들에게 SQL문법은 매우 중요하다. 지금도 어딘가에는 데이터는 쌓이고 있고, 문제는 쌓여 있는 데이터를 활용해서 어떤 비즈니스 문제를 해결할지가 가장 큰 이슈이기 때문이다.
그동안 SQL은 MySQL과 RDB 문법, MongoDB와 NoSQL과 같은 문법으로 나누어서 볼 수 있다. 강사가 과거 프로젝트에서 사용했던 SQL은 MySQL, MSSQL, MongoDB가 있었는데, 각각의 문법이 다르다는 측면이 있어서 조금 애를 많이 먹었다. 특히 MongoDB문법은 JSON 형태로 되어 있기 때문에, 별도의 문법이라 보는게 더 낫다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch4.3 - 딥러닝 네트워크를 이용한 회귀</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/</link>
      <pubDate>Wed, 15 Apr 2020 20:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch4_3_regression_with_deeplearning/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Hugo &#43; Mathjax 설정</title>
      <link>https://dschloe.github.io/settings/mathjax/</link>
      <pubDate>Wed, 15 Apr 2020 13:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/mathjax/</guid>
      <description>I. 인라인 수식 에러 한동안 수식 에러를 많나 고생하였다. $$ ... $$ 코드는 잘 적용이 되었다. 그런데, 글 중간에 수식을 넣는 건 잘 되지 않았다. $ ... $ 표현하면 수식문법이 그대로 나와서 글의 가독성이 조금 떨어져 있었다. 통계수식을 넣어주면, 그냥 무언가 전문가스럽다! 전문가도 아니지만 ㅎㅎ
$x_{i}$ 내가 표현하고자 하는 것 Vs. x_{i} 실제로 화면에 나오는 것 그리고, 한동안 헤매었다. 길은 알고 있었으나, 역시 적용이 쉽지 않았다. 아래는 해결 방안을 공유한다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch4.2 - 다항 회귀</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/</link>
      <pubDate>Wed, 15 Apr 2020 13:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch4_2_multiple_linear_regression/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다.
강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다.
본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch4.1 - 선형회귀</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch4_1_linear_regression/</link>
      <pubDate>Tue, 14 Apr 2020 22:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch4_1_linear_regression/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다. 강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다. 본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Corona Shiny Project 6_1 - 데이터 전처리</title>
      <link>https://dschloe.github.io/r/shiny/project_06_01/</link>
      <pubDate>Tue, 14 Apr 2020 10:15:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/project_06_01/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. Shiny Tutorial 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps shiny tutorial 06 - shinydashboard shiny tutorial 07 - flexdashboard shiny tutorial 08 - HTML, CSS 적용 II.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch3.3.5 - 세번째 신경망 네트워크 - XOR</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch3_3_5_network_xor/</link>
      <pubDate>Mon, 13 Apr 2020 21:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch3_3_5_network_xor/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다. 강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다. 본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>GT 패키지 소개</title>
      <link>https://dschloe.github.io/r/newpkgs/gt_intro/</link>
      <pubDate>Mon, 13 Apr 2020 00:21:01 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/newpkgs/gt_intro/</guid>
      <description>공지 본 블로그는 2020-04-08에 소개된 Great Looking Tables: gt(v0.2) by Richard Iannone 글을 번역한 것이다. 함수와 관련된 설명은 가급적 원어를 직접 인용 했으니, 영어로 직접 함수의 사용처를 음미하시길 바란다.
I. Intro gt라는 이름은 grammar of tables즉 &amp;ldquo;테이블의 문법&amp;quot;의 줄임말이며 gt의 목표는 ggplot2와 비슷하게 운영하는 것이다. 특정 테이블을 쉽게 만들 수 있을 뿐만 아니라 다양한 문제를 해결하기 위해 서로 다른 방법으로 재결합할 수 있는 기본 구성요소 집합을 기술하는 역할을 한다.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch3.3.4 - 두번째 신경망 네트워크: OR</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch3_3_4_network_or/</link>
      <pubDate>Sun, 12 Apr 2020 23:40:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch3_3_4_network_or/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다. 강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다. 본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch3.3.3 - 첫번째 신경망 네트워크, AND</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch3_3_3_network_and/</link>
      <pubDate>Sat, 11 Apr 2020 11:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch3_3_3_network_and/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다. 강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다. 본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Corona Shiny Project 5 - Chart with DateInput</title>
      <link>https://dschloe.github.io/r/shiny/project_05/</link>
      <pubDate>Sat, 11 Apr 2020 10:15:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/project_05/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. Shiny Tutorial 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps shiny tutorial 06 - shinydashboard shiny tutorial 07 - flexdashboard shiny tutorial 08 - HTML, CSS 적용 II.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch3.3.2 - 난수 생성 및 시그모이드 함수 편향성</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/</link>
      <pubDate>Fri, 10 Apr 2020 10:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch3_3_2_random_signoid_bias/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다. 강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다. 본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. Tutorial 이전 강의가 궁금하신 분들은 아래에서 선택하여 추가 학습 하시기를 바랍니다.
Google Colab Tensorflow 2.0 Installation Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수 Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Corona Shiny Project 4 - Visusalization (Map Chart)</title>
      <link>https://dschloe.github.io/r/shiny/project_04/</link>
      <pubDate>Thu, 09 Apr 2020 10:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/project_04/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. Shiny Tutorial 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps shiny tutorial 06 - shinydashboard shiny tutorial 07 - flexdashboard shiny tutorial 08 - HTML, CSS 적용 II.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Tutorial ch3.3.1 - 난수 생성 및 시그모이드 함수</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/</link>
      <pubDate>Wed, 08 Apr 2020 11:20:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/ch3_3_1_random_signoid/</guid>
      <description>공지 본 Tutorial은 교재 시작하세요 텐서플로 2.0 프로그래밍의 강사에게 국비교육 강의를 듣는 사람들에게 자료 제공을 목적으로 제작하였습니다. 강사의 주관적인 판단으로 압축해서 자료를 정리하였기 때문에, 자세하게 공부를 하고 싶은 반드시 교재를 구매하실 것을 권해드립니다. 본 교재 외에 강사가 추가한 내용에 대한 Reference를 확인하셔서, 추가적으로 학습하시는 것을 권유드립니다. I. 퍼셉트론의 한계 극복 AI는 과거부터 존재하였지만, 여러가지 한계로 인해 연구의 흥망성쇠가 계속적으로 있어왔다. 퍼셉트론의 한계를 지적하는 데 사용됐던, AND, OR, XOR 연산을 할 수 있는 신경망 네트워크를 직접 만들어보자.</description>
    </item>
    
    <item>
      <title>Corona Shiny Project 3 - Visusalization (Bubble Chart)</title>
      <link>https://dschloe.github.io/r/shiny/project_03/</link>
      <pubDate>Wed, 08 Apr 2020 10:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/project_03/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. Shiny Tutorial 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps shiny tutorial 06 - shinydashboard shiny tutorial 07 - flexdashboard shiny tutorial 08 - HTML, CSS 적용 II.</description>
    </item>
    
    <item>
      <title>Corona Shiny Project 2 - Visusalization (Time Series)</title>
      <link>https://dschloe.github.io/r/shiny/project_02/</link>
      <pubDate>Tue, 07 Apr 2020 10:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/project_02/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. Shiny Tutorial 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps shiny tutorial 06 - shinydashboard shiny tutorial 07 - flexdashboard shiny tutorial 08 - HTML, CSS 적용 II.</description>
    </item>
    
    <item>
      <title>Corona Shiny Project I - Get Data</title>
      <link>https://dschloe.github.io/r/shiny/project_01/</link>
      <pubDate>Mon, 06 Apr 2020 09:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/project_01/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. Shiny Tutorial 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps shiny tutorial 06 - shinydashboard shiny tutorial 07 - flexdashboard shiny tutorial 08 - HTML, CSS 적용 II.</description>
    </item>
    
    <item>
      <title>shiny tutorial 08 - HTML, CSS 적용</title>
      <link>https://dschloe.github.io/r/shiny/tutorial_08/</link>
      <pubDate>Sun, 05 Apr 2020 11:30:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/tutorial_08/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. 이전 글 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps shiny tutorial 06 - shinydashboard shiny tutorial 07 - flexdashboard II.</description>
    </item>
    
    <item>
      <title>Connecting Jupyter Notebook to VS Code</title>
      <link>https://dschloe.github.io/settings/settings02_vscode2jupyter/</link>
      <pubDate>Sun, 05 Apr 2020 00:30:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/settings/settings02_vscode2jupyter/</guid>
      <description>I. 개요 VS Code에 Jupyter Notebook을 연동해본다. 강사는 R &amp;amp; Python을 연동해서 작업할 일이 많다. 특히 블로그를 쓰다보면 더욱 그러한 일이 많은데, IDE가 많으면 많을수록 무언가 복잡스러워 보일 때가 많다. 이 때 좀 더 효율적으로 일하고자 하는 마음에 VS Code에 Jupyter Notebook을 추가 및 연동하는 작업을 진행해본다.
II. Installation 내용의 간결화를 위해, VS Code 및 Jupyter Notebook 설치 방법은 본 포스트에서는 생략한다.
VS Code 설치방법: https://code.visualstudio.com/download Jupyter Notebook 설치 방법: https://jupyter.</description>
    </item>
    
    <item>
      <title>Google Colab Tensorflow 2.0 Installation</title>
      <link>https://dschloe.github.io/python/tensorflow2.0/googlecolab/</link>
      <pubDate>Sat, 04 Apr 2020 11:03:30 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/tensorflow2.0/googlecolab/</guid>
      <description>I. 공지 이번 포스트부터 강사의 과거-기존-미래 수강생들이 보다 효율적으로 공부할 수 있도록 구글코랩에서 진행하는 텐서플로 2.0 Tutorial을 준비한다.
II. 개요 GPU를 활용하여, 딥러닝을 연습하고 공부하고 싶지만, 쉽지많은 않다. 구글 코랩의 존재는 예전부터 알고 있었지만, 마땅히 정리를 하지 못하던 찰나에, 이제 본격적으로 강의 준비를 하며 2020년은 구글 코랩과 함께 하기로 결정하였다. 특히 텐서플로 Tutorial을 준비하면서 개인적으로 많이 성장하기를 바라며..
III. Why Tensorflow 2.0? 비즈니스적으로 접근을 해보자. 앱의 경우, 2007년쯤 IOS가 출시된 이후, 경쟁자로 Andorid가 등장했다.</description>
    </item>
    
    <item>
      <title>Pandas Filtering</title>
      <link>https://dschloe.github.io/python/pandas/filter/</link>
      <pubDate>Fri, 03 Apr 2020 22:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/filter/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 Overview 필터링은 특정 조건식을 만족하는 행을 따로 추출하는 개념이다. 특정 행의 값에 조건식 True/False을 판별하여 값을 추출하는 방법이다. 이 때, 비교 연산자 또는 조건식 (&amp;gt;, &amp;lt;, ==, ...)을 적용하면 행을 추출할 수 있다.
우선 데이터부터 확인한다.</description>
    </item>
    
    <item>
      <title>Pandas sort_values()</title>
      <link>https://dschloe.github.io/python/pandas/sort_values/</link>
      <pubDate>Fri, 03 Apr 2020 20:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/sort_values/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. Overview sort_values() 함수는 일종의 데이터의 정렬과 연관이 있다. 어려운 내용은 아니기 때문에 빠르게 소스 코드 구현 및 확인 하도록 한다.
II. Sample Tutorial 엑셀로 된 ticket_sales 데이터에서 ticket_quantity가 가장 많이 팔린 영화 Top3를 구하는 소스코드를 구해본다.</description>
    </item>
    
    <item>
      <title>shiny tutorial 07 - flexdashboard package</title>
      <link>https://dschloe.github.io/r/shiny/tutorial_07/</link>
      <pubDate>Thu, 02 Apr 2020 21:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/tutorial_07/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. 이전 글 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps shiny tutorial 06 - shinydashboard II.</description>
    </item>
    
    <item>
      <title>shiny tutorial 06 - shinydashboard package</title>
      <link>https://dschloe.github.io/r/shiny/tutorial_06/</link>
      <pubDate>Wed, 01 Apr 2020 17:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/tutorial_06/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. 이전 글 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts shiny tutorial 05 - Sharing Apps II.</description>
    </item>
    
    <item>
      <title>shiny tutorial 05 - Sharing Apps</title>
      <link>https://dschloe.github.io/r/shiny/tutorial_05/</link>
      <pubDate>Tue, 31 Mar 2020 01:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/tutorial_05/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. 이전 글 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content shiny tutorial 04 - Shiny Layouts II. Shiny Deployment의 개요 이 영역은 웹개발자에게는 매우 쉬운 영역일 수도 있다.</description>
    </item>
    
    <item>
      <title>Pandas With Excel</title>
      <link>https://dschloe.github.io/python/pandas/pandas_with_excel/</link>
      <pubDate>Mon, 30 Mar 2020 11:15:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/pandas_with_excel/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. Overview 이번 포스트는 기존의 엑셀 사용자를 위해 준비했다. 엑셀에 익숙한 사람들에게 파이썬을 분석 용도로 사용하고자 하는 분들에게는 작은 도움이 되기를 바란다.
II. 데이터 입출력 판다스는 다양한 형태의 외부 파일을 읽을 수 있다. CSV, MS Excel, SQL, HDF5 Format과 같은 파일 포맷을 읽을 수 있다.</description>
    </item>
    
    <item>
      <title>shiny tutorial 04 - Layouts</title>
      <link>https://dschloe.github.io/r/shiny/tutorial_04/</link>
      <pubDate>Sun, 29 Mar 2020 23:50:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/tutorial_04/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. 이전 글 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure shiny tutorial 03 - HTML content II. Layouts의 개요 이번 시간에는 Shiny Layouts 개요에 대한 간략적인 소개를 하려고 한다.</description>
    </item>
    
    <item>
      <title>shiny tutorial 03 - HTML content</title>
      <link>https://dschloe.github.io/r/shiny/tutorial_03/</link>
      <pubDate>Fri, 27 Mar 2020 23:50:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/tutorial_03/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. 이전 글 소개 처음 shiny를 접하거나 shiny의 전체 튜토리얼이 궁금한 사람들을 위해 이전 글을 소개한다.
shiny tutorial 01 - get started shiny tutorial 02 - Shiny Structure II. HTML Content 개요 이번 시간에는 HTML Content 개요에 대한 간략적인 소개를 하려고 한다. 영어가 편하거나 중고급 개발자 분들은 Customize your UI with HTML를 참고하기를 바란다.</description>
    </item>
    
    <item>
      <title>Pandas Lambda Apply 함수 활용</title>
      <link>https://dschloe.github.io/python/pandas/apply/</link>
      <pubDate>Mon, 23 Mar 2020 20:10:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/apply/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. Iterrows, Itertuples 복습 이번 포스팅은 For-loop의 대안에 관한 함수 apply에 관한 내용이다. 본 포스트를 보고 학습하시기 전에 Pandas Iterrows 함수 활용과 Pandas Itertuples 함수 활용에서 학습 하기를 바란다.
지난시간과 마찬가지로 데이터는 동일한 것을 쓰도록 한다.</description>
    </item>
    
    <item>
      <title>Pandas Itertuples 함수 활용</title>
      <link>https://dschloe.github.io/python/pandas/itertuples/</link>
      <pubDate>Sun, 22 Mar 2020 20:36:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/itertuples/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. Iterrows 이번 포스팅은 Iterrows()의 확장개념입니다. 본 포스트를 보고 학습하시기 전에 Pandas Iterrows 함수 활용에서 학습 하기를 바란다.
II. Itertuples의 개념 itertuples()는 기본적으로 iterrows() 함수보다는 빠르다.
import pandas as pd import io import requests import pprint url = &amp;#39;https://raw.</description>
    </item>
    
    <item>
      <title>shiny tutorial 02 - Shiny Structure</title>
      <link>https://dschloe.github.io/r/shiny/tutorial_02/</link>
      <pubDate>Sun, 22 Mar 2020 12:33:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/tutorial_02/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. Shiny 소개 지난시간에 Shiny에 관한 대략적인 소개를 했다. 처음 이 페이지를 방문한 사람들 위해 shiny tutorial 01 - get started 에서 짧게 확인하기를 바란다.
II. Shiny App Structure 아래 샘플 코드를 확인하자.
# load the shiny package library(shiny) # 화면 구성 (UI) - 프론트엔드 ui &amp;lt;- fluidPage( numericInput(inputId = &amp;#34;n&amp;#34;, label = &amp;#34;Sample size&amp;#34;, value = 25), plotOutput(outputId = &amp;#34;hist&amp;#34;) ) # 서버 구성 - 벡엔드 server &amp;lt;- function(input, output) { output$hist &amp;lt;- renderPlot({ hist(rnorm(input$n)) # 결과물을 만들어내는 코드 작성 }) } # shiny app 호출 # 프로젝트 진행 시, 폴더 안에 # 파일명은 app.</description>
    </item>
    
    <item>
      <title>shiny tutorial 01 - get started</title>
      <link>https://dschloe.github.io/r/shiny/tutorial_01/</link>
      <pubDate>Sat, 21 Mar 2020 12:33:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/shiny/tutorial_01/</guid>
      <description>공지 이번에 준비한 튜토리얼은 제 강의를 듣는 과거-현재-미래 수강생분들을 위해 준비한 자료이다. 많은 도움이 되기를 바란다
이번에 준비한 Tutorial 코로나 세계현황을 Shiny Dashboard로 만들어 가는 과정을 담았다.
I. Shiny 소개 Shiny는 R에서 제공하는 일종의 Web Framework이다. 기존 웹사이트와 다르게, 주요 목적은 데이터를 활용해서 대시보드를 만드는 것에 초점이 맞춰져 있다.
가장 큰 장점은 무료로 빠른 프로토타입을 만들 수 있고, HTML, CSS, Javascript와 직접적으로 호환이 되기 때문에 무한한 확장성이 있다. 바로 중급 레벨에서 배우고 싶으시다면 Intermediate Level을 클릭한다.</description>
    </item>
    
    <item>
      <title>Pandas Iterrows 함수 활용</title>
      <link>https://dschloe.github.io/python/pandas/iterrows/</link>
      <pubDate>Fri, 20 Mar 2020 20:32:10 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/pandas/iterrows/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. Iterrows의 개념 데이터 전처리를 진행할 때, 데이터프레임에서 행에 반복적으로 접근을 하면서 값을 추출하거나 또는 그 값을 조작하는 일이 발생한다. 예를 들면, 특정 컬럼 A의 값에서 대문자 A를 찾아내 소문자 b로 변경한다고 가정해보자. 이런 경우에는 언제나 For-loop를 통한 반복문 코드 작성을 만들어야 한다.</description>
    </item>
    
    <item>
      <title>Machine Learning Tutorial 02 - Regression (2)</title>
      <link>https://dschloe.github.io/python/machin_learning/scikit_regression/ml01_regression2/</link>
      <pubDate>Fri, 20 Mar 2020 13:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/machin_learning/scikit_regression/ml01_regression2/</guid>
      <description>I. 지도 학습 VS 비지도 학습 머신러닝은 크게 두 가지 유형으로 분류한다. 우선 아래 표를 보자.
구분 지도학습(Supervised Learning) 비지도 학습(Unsupervised Learning) 알고리즘(분석모형) 회귀분석분류모형 군집분석 특징 정답을 알고 있는 상태에서 학습모형 평가 방법이 다양한 편 정답이 없는 상태에서 서로 비슷한 데이터를 찾아서 그룹화모형 평가 방법이 제한적 지도학습(Supervised Learning)은 종속변수(Dependent Variable) 선정이 매우 중요하며. 종속변수 선정과 함께 데이터 분석도 같이 병행이 된다. 그러나 비지도학습(Unsupervised Learning)은 데이터가 많은데, 어떻게 분류하면 좋을지 모를 때 서로 비슷한 특징끼리 결합 및 그룹화 하는 것을 말한다.</description>
    </item>
    
    <item>
      <title>Machine Learning Tutorial 01 - Regression (1)</title>
      <link>https://dschloe.github.io/python/machin_learning/scikit_regression/ml01_regression/</link>
      <pubDate>Thu, 19 Mar 2020 18:11:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/machin_learning/scikit_regression/ml01_regression/</guid>
      <description>I 지도 학습 VS 비지도 학습 머신러닝은 크게 두 가지 유형으로 분류한다. 우선 아래 표를 보자.
구분 지도학습(Supervised Learning) 비지도 학습(Unsupervised Learning) 알고리즘(분석모형) 회귀분석분류모형 군집분석 특징 정답을 알고 있는 상태에서 학습모형 평가 방법이 다양한 편 정답이 없는 상태에서 서로 비슷한 데이터를 찾아서 그룹화모형 평가 방법이 제한적 지도학습(Supervised Learning)은 종속변수(Dependent Variable) 선정이 매우 중요하며. 종속변수 선정과 함께 데이터 분석도 같이 병행이 된다. 그러나 비지도학습(Unsupervised Learning)은 데이터가 많은데, 어떻게 분류하면 좋을지 모를 때 서로 비슷한 특징끼리 결합 및 그룹화 하는 것을 말한다.</description>
    </item>
    
    <item>
      <title>R Markdown Introduction</title>
      <link>https://dschloe.github.io/r/rmarkdown/rmarkdownintro/</link>
      <pubDate>Wed, 18 Mar 2020 13:10:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/rmarkdown/rmarkdownintro/</guid>
      <description>R Markdown 소개 및 환경설정 데이터 분석가의 주요 업무 중의 하나는 향후에 참고자료로 활용하기 위해 작업결과를 문서화 해야 하는데, 상당량의 보고서를 작성해서 분석과정과 출력결과를 기술해야만 합니다.
보통의 과정은 아래과 같을 것입니다.
1단계: 본인의 작업을 위해서 R 스크립트 작성 2단계: 다양한 그래프가 첨부된 분석결과를 Word, PPT 분석결과를 기술해서 동료 또는 메신저로 분석결과 전송 3단계: 분석결과 토의 4단계: 각각의 그래프 결과 코드를 매칭하기 위한 작업이 토의 중 발생 5단계: 혼란 및 불필요한 시간 소요 발생 그런데, 해당 작업물을 그 때 마다 웹페이지(HTML)을 생성하여 자체 서버내 구축할 수 있다면, 그러면 위 5단계의 과정을 3단계(소스코드 작성 -&amp;gt; 웹 게시 -&amp;gt; 분석결과 토의)로 축소할 수가 있을 것이며 특히, 연구자가 분석 당시의 고민과 문제점들을 스크롤링과 함께 같이 고민할 수 있는 시간으로 빠져들 수 있도록 유도할 수 있습니다.</description>
    </item>
    
    <item>
      <title>Leaflet for R</title>
      <link>https://dschloe.github.io/r/graph01_leaflet/</link>
      <pubDate>Tue, 17 Mar 2020 20:33:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/graph01_leaflet/</guid>
      <description>1. Introduction Leaflet 패키지는 동적 지도 시각화를 위한 자바스크립트-오픈소스 기반 라이브러리입니다. 일반적인 기업 회사 뿐만 아니라 GIS 전문 회사인 OpenStreetMap, Mapbox, 그리고 CartoDB에서도 이 패키지를 사용하고 있습니다.
R의 leaflet 패키지는 일종의 자바스크립트의 Leaflet을 쉽게 연동(Integrate) 할 수 있도록 도와 주는 패키지입니다.
2. Features 패키지의 주요 특징은 아래와 같습니다. 오역 방지를 위해 원문에 있는 내용을 그대로 사용했습니다.
Interactive panning/zooming
Compose maps using arbitrary combinations of:
Map tiles Markers Polygons Lines Popups GeoJSON Create maps right from the R console or RStudio</description>
    </item>
    
    <item>
      <title>Tensorflow For R - Quick Start</title>
      <link>https://dschloe.github.io/r/settings01_installation/</link>
      <pubDate>Mon, 16 Mar 2020 20:33:39 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/settings01_installation/</guid>
      <description>1. 개요 (Overview) tensorflow(텐서플로) R 패키지를 사용하기 전에 시스템에 TensorFlow 버전을 설치해야 한다. 아래에서는 TensorFlow 설치 방법과 설치 사용자 정의에 사용할 수 있는 다양한 옵션에 대해 설명 한다.
이번 포스트에서는 주로 R install_tensorflow() 함수의 사용을 다루며, 이는 TensorFlow를 설치하는 데 필요한 다양한 단계에서 wrapper 쉽게 사용할 수 있도록 도와 준다.
Tensorflow(텐서플로)는 아래와 같은 OS 환경에서 구동이 된다.
Ubuntu 16.04 or later Windows 7 or later macOS 10.12.6 (Sierra) or later (no GPU support) 2.</description>
    </item>
    
    <item>
      <title>Tensorflow 2.0 Installation</title>
      <link>https://dschloe.github.io/python/settings01_installation/</link>
      <pubDate>Sun, 15 Mar 2020 21:32:47 +0900</pubDate>
      
      <guid>https://dschloe.github.io/python/settings01_installation/</guid>
      <description>강의 홍보 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다. 스타벅스 아이스 아메리카노를 선물로 보내드리겠습니다. [비전공자 대환영] 제로베이스도 쉽게 입문하는 파이썬 데이터 분석 - 캐글입문기 I. 개요 pip를 사용하여 TensorFlow 설치를 해본다.
II. 시스템 요구사항 Python 3.5-3.7 pip 19.0 이상(manylinux2010 지원 필요) Ubuntu 16.04 이상(64비트) macOS 10.12.6(Sierra) 이상(64비트)(GPU 지원 없음) Windows 7 이상(64비트)(Python 3만 해당) Raspbian 9.0 이상 GPU 지원에는 CUDA® 지원 카드 필요(Ubuntu 및 Windows) 참고: TensorFlow2를 설치하려면 최신 버전의 pip가 필요하다.</description>
    </item>
    
    <item>
      <title>PLS-SEM에서 중요 용어 비교</title>
      <link>https://dschloe.github.io/r/stat01_hypothesis/</link>
      <pubDate>Sun, 15 Mar 2020 21:23:58 +0900</pubDate>
      
      <guid>https://dschloe.github.io/r/stat01_hypothesis/</guid>
      <description>개요 PLS-SEM에서의 가설 설정은 선행연구의 검토과정을 통해서 이루어지며 귀무가설은 기술하지 않고 대립가설을 중심으로 설정한다. 연구가설은 방향적 검증(Directional Test)와 비방향적 검증(Non-Directional Test)으로 구분한다. R 강의 소개 필자의 강의: 왕초보 데이터 분석 with R 쿠폰 유효일은 2021년 10월 30일까지입니다. 링크: https://www.udemy.com/course/beginner_with_r/?couponCode=5BF397C9A1E46079627D 현재 강의를 계속 찍고 있고, 가격은 한 Section이 끝날 때마다 조금씩 올릴 예정입니다. Python 강의 소개 취준생을 위한 강의를 제작하였습니다. 본 블로그를 통해서 강의를 수강하신 분은 게시글 제목과 링크를 수강하여 인프런 메시지를 통해 보내주시기를 바랍니다.</description>
    </item>
    
    <item>
      <title>About DSChloe</title>
      <link>https://dschloe.github.io/about/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dschloe.github.io/about/</guid>
      <description>데이터 분석을 좋아하고 사랑하는 DSChloe 개인 블로그입니다. 데이터 과학과 관련한 다양한 글을 여기에서 집필할 예정이며, 강의 관련 자료나, 새로나운 모듈 또는 패키지 소개글을 올릴 예정입니다.
30대 초반에 통계/컴공 비전공자이며, 경력을 전환하면서, 쉽지는 않았습니다. 그러나, 지금은 프로젝트 및 강의, 스스로 독학하며 개발블로그까지 만들정도가 되었습니다. 개발 블로그를 구글링하며, 구축한 것도 하루가 걸리지 않았습니다. (구글 Analytics, Search Console, Adsense까지 모두 작업 완료!)
어려운 시기에, 동종업계로 이직 및 전환을 하고 싶은 사람들에게 좋은 글과 영감을 주는 사람이고 있습니다.</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>https://dschloe.github.io/settings/privacy/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dschloe.github.io/settings/privacy/</guid>
      <description>Who we are
Suggested text: Our website address is: https://dschloe.github.io/
​ Comments
Suggested text: When visitors leave comments on the site we collect the data shown in the comments form, and also the visitor’s IP address and browser user agent string to help spam detection.
An anonymized string created from your email address (also called a hash) may be provided to the Gravatar service to see if you are using it.</description>
    </item>
    
    <item>
      <title>개인정보처리방침</title>
      <link>https://dschloe.github.io/privacyinfo/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://dschloe.github.io/privacyinfo/</guid>
      <description>개인정보처리방침 1. 개인정보 수집 및 이용 &amp;lsquo;Yuna Learn English&amp;rsquo; 앱은 사용자의 어떠한 개인정보도 수집하거나 저장하지 않습니다.
2. 데이터 저장 앱 내의 모든 학습 데이터는 사용자의 기기에만 저장됩니다. 외부 서버로 어떠한 데이터도 전송되지 않습니다. 3. 문의사항 개인정보 처리방침에 관한 문의사항이 있으시면 아래 이메일로 연락주시기 바랍니다.
이메일: [j2hoon85@gmail.com] 4. 개인정보처리방침 변경 본 개인정보처리방침은 법률이나 서비스의 변경사항을 반영하기 위해 수정될 수 있습니다.
최종 수정일: 2025년 1월 3일</description>
    </item>
    
  </channel>
</rss>
